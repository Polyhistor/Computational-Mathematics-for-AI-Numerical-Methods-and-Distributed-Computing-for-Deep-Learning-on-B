@article{kitchenham2002principles,
  title={Principles of survey research: part 6: data analysis},
  author={Kitchenham, Barbara and Pfleeger, Shari Lawrence},
  journal={ACM SIGSOFT Software Engineering Notes},
  volume={27},
  number={2},
  pages={20--24},
  year={2002},
  publisher={ACM}
}


@book{fitch2001rand,
  title={The RAND/UCLA appropriateness method user's manual},
  author={Fitch, Kathryn and Bernstein, Steven J and Aguilar, Mary D and Burnand, Bernard and LaCalle, Juan Ram{\'o}n},
  year={2001},
  publisher={RAND CORP SANTA MONICA CA}
}

@article{dalkey1969delphi,
  title={The Delphi method: An experimental study of group opinion},
  author={Dalkey, Norman and Helmer, Olaf},
  journal={Rand Corp Santa Monica CA},
  year={1969}
}

@article{diamond2014results,
  title={Results of a systematic review and meta-analysis of the presentations of Delphi studies},
  author={Diamond, Ian R and Grant, Robert C and Feldman, Brian M and Pencharz, Paul B and Ling, Simon C and Moore, Aideen M and Wales, Paul W},
  journal={Journal of Clinical Epidemiology},
  volume={67},
  number={4},
  pages={402--409},
  year={2014},
  publisher={Elsevier}
}

@book{delbecq1975group,
  title={Group techniques for program planning: A guide to nominal group and Delphi processes},
  author={Delbecq, Andre L and Van de Ven, Andrew H and Gustafson, David H},
  year={1975},
  publisher={Scott, Foresman}
}


@article{kitchenham2004procedures,
  title={Procedures for performing systematic reviews},
  author={Kitchenham, Barbara},
  journal={Keele University Technical Report},
  volume={TR/SE-0401},
  year={2004},
  publisher={Keele University}
}

@article{dalkey1963experimental,
  title={An experimental application of the {D}elphi method to the use of experts},
  author={Dalkey, Norman and Helmer, Olaf},
  journal={Management Science},
  volume={9},
  number={3},
  pages={458--467},
  year={1963},
  publisher={INFORMS}
}

@article{delbecq1971group,
  title={A {G}roup {P}rocess {M}odel for {P}roblem {I}dentification and {P}rogram {P}lanning},
  author={Delbecq, Andre L and Van de Ven, Andrew H},
  journal={Journal of Applied Behavioral Science},
  volume={7},
  number={4},
  pages={466--492},
  year={1971},
  publisher={Sage Publications}
}

@article{laney2001data,
  title={{3D} {D}ata {M}anagement: {C}ontrolling {D}ata {V}olume, {V}elocity, and {V}ariety},
  author={Laney, Doug},
  journal={META Group Research Note},
  volume={6},
  number={70},
  year={2001}
}

@book{krippendorff2004reliability,
  title={Content {A}nalysis: {A}n {I}ntroduction to {I}ts {M}ethodology},
  author={Krippendorff, Klaus},
  year={2004},
  publisher={Sage Publications},
  address={Thousand Oaks, CA}
}

@article{petersen2008systematic,
  title={Systematic mapping studies in software engineering},
  author={Petersen, Kai and Feldt, Robert and Mujtaba, Shahid and Mattsson, Michael},
  journal={EASE},
  volume={8},
  pages={68--77},
  year={2008}
}

@article{dean2012largemapreduce,
  title={MapReduce: simplified data processing on large clusters},
  author={Dean, Jeffrey and Ghemawat, Sanjay},
  journal={Communications of the ACM},
  volume={51},
  number={1},
  pages={107--113},
  year={2008},
  publisher={ACM}
}

@inproceedings{li2014scaling,
  title={Scaling distributed machine learning with the parameter server},
  author={Li, Mu and Andersen, David G and Park, Jun Woo and Smola, Alexander J and Ahmed, Amr and Josifovski, Vanja and Long, James and Shekita, Eugene J and Su, Bor-Yiing},
  booktitle={11th USENIX Symposium on Operating Systems Design and Implementation},
  pages={583--598},
  year={2014}
}

@article{zaharia2016apache,
  title={Apache {S}park: {A} unified engine for big data processing},
  author={Zaharia, Matei and Xin, Reynold S and Wendell, Patrick and Das, Tathagata and Armbrust, Michael and Dave, Ankur and Meng, Xiangrui and Rosen, Josh and Venkataraman, Shivaram and Franklin, Michael J and others},
  journal={Communications of the ACM},
  volume={59},
  number={11},
  pages={56--65},
  year={2016},
  publisher={ACM}
}

@article{lecun2015deep,
  title={Deep learning},
  author={LeCun, Yann and Bengio, Yoshua and Hinton, Geoffrey},
  journal={Nature},
  volume={521},
  number={7553},
  pages={436--444},
  year={2015},
  publisher={Nature Publishing Group}
}

@article{jordan2015machine,
  title={Machine learning: Trends, perspectives, and prospects},
  author={Jordan, Michael I and Mitchell, Tom M},
  journal={Science},
  volume={349},
  number={6245},
  pages={255--260},
  year={2015},
  publisher={American Association for the Advancement of Science}
}

@book{goodfellow2016deep,
  title={Deep Learning},
  author={Goodfellow, Ian and Bengio, Yoshua and Courville, Aaron},
  year={2016},
  publisher={MIT Press},
  address={Cambridge, MA}
}


@article{moher2009preferred,
  title={Preferred reporting items for systematic reviews and meta-analyses: the PRISMA statement},
  author={Moher, David and Liberati, Alessandro and Tetzlaff, Jennifer and Altman, Douglas G and PRISMA Group},
  journal={PLoS medicine},
  volume={6},
  number={7},
  pages={e1000097},
  year={2009},
  publisher={Public Library of Science}
}

@article{kitchenham2007guidelines,
  title={Guidelines for performing systematic literature reviews in software engineering},
  author={Kitchenham, Barbara and Charters, Stuart},
  journal={Technical report, Ver. 2.3 EBSE Technical Report. EBSE},
  year={2007}
}

@article{cooper1988,
  title={Organizing knowledge syntheses: A taxonomy of literature reviews},
  author={Cooper, Harris M},
  journal={Knowledge in Society},
  volume={1},
  number={1},
  pages={104--126},
  year={1988},
  publisher={Springer}
}

@article{Zhang202420230063,
  title = {Analysis of the Application Methods of Film and Television Media and Images in the Era of Big Data Cloud},
  author = {Zhang, Qing},
  year = {2024},
  month = jan,
  journal = {Applied Mathematics and Nonlinear Sciences},
  volume = {9},
  number = {1},
  pages = {20230063},
  issn = {2444-8656},
  doi = {10.2478/amns.2023.1.00063},
  abstract = {Abstract             In order to give full play to the application of big data in film and television media and imaging in the cloud era, this study proposes a communication-efficient distributed deep neural network training method based on the DANE algorithm framework. The DANE algorithm is an approximate Newtonian method that has been widely used in communication-efficient distributed machine learning. It has the advantages of fast convergence and no need to calculate the inverse of the Hessian matrix, which can significantly reduce the communication and computational overhead in high-dimensional situations. In order to further improve the computational efficiency, it is necessary to study how to speed up the local optimization of DANE. It is a feasible method to choose to use the most popular adaptive gradient optimization algorithm Adam to replace the commonly used stochastic gradient descent method to solve the local single-machine suboptimization problem of DANE. Experiments show that Adam-based optimization can converge significantly faster than the original SGD-based implementation with little sacrifice in model generalization performance. With the increase of sampling rate, DANE-Adam significantly outperforms the DANE method in terms of convergence speed, and at the same time, the accuracy can be kept almost unchanged, which are 0.96, 0.88 and 0.75, respectively. This shows that Adam-based optimization can converge significantly faster than the original SGD-based implementation with little sacrifice in model generalization performance, with significant potential value.},
  copyright = {http://creativecommons.org/licenses/by/4.0},
  langid = {english}
}


@article{Chen2016331,
  title = {Specialized Genetic Algorithm for Neural Network Architecture Optimization},
  author = {Chen, Tao and Yang, Shichen and Li, Jianhua},
  journal = {IEEE Transactions on Evolutionary Computation},
  volume = {20},
  number = {3},
  pages = {331--343},
  year = {2016},
  doi = {10.1109/TEVC.2015.2457491}
}


@article{dauphin2014identifying,
  title = {Identifying and attacking the saddle point problem in high-dimensional non-convex optimization},
  author = {Dauphin, Yann N and Pascanu, Razvan and Gulcehre, Caglar and Cho, Kyunghyun and Ganguli, Surya and Bengio, Yoshua},
  journal = {Advances in neural information processing systems},
  volume = {27},
  year = {2014}
}


@article{schmidt2021descending,
  title = {Descending through a crowded valley—Benchmarking deep learning optimizers},
  author = {Schmidt, Robin M and Schneider, Frank and Hennig, Philipp},
  journal = {International Conference on Machine Learning},
  pages = {9367--9376},
  year = {2021}
}


@article{Gupta2021,
  title = {Edge Intelligence for Smart Cities},
  author = {Gupta, Harshit and Nath, Arun and Chakraborty, Sandip},
  journal = {IEEE Communications Magazine},
  volume = {59},
  number = {3},
  pages = {98--104},
  year = {2021},
  doi = {10.1109/MCOM.001.2000295}
}


@article{Jin2021,
  title = {Deep Learning for Industrial Fault Diagnosis},
  author = {Jin, Tianyu and Zhang, Haifeng and Liu, Song},
  journal = {Reliability Engineering {\&} System Safety},
  volume = {215},
  pages = {107896},
  year = {2021},
  doi = {10.1016/j.ress.2021.107896}
}


@article{Fong2023,
  title = {Adaptive Mutation Rates in Genetic Algorithms for Deep Learning},
  author = {Fong, Simon and Deb, Suash and Wong, Raymond},
  journal = {IEEE Transactions on Artificial Intelligence},
  volume = {4},
  number = {2},
  pages = {289--302},
  year = {2023},
  doi = {10.1109/TAI.2022.3209572}
}


@article{Ampavathi20211146,
  title = {Multi Disease-Prediction Framework Using Hybrid Deep Learning: An Optimal Prediction Model},
  shorttitle = {Multi Disease-Prediction Framework Using Hybrid Deep Learning},
  author = {Ampavathi, Anusha and Saradhi, T. Vijaya},
  year = {2021},
  month = jul,
  journal = {Computer Methods in Biomechanics and Biomedical Engineering},
  volume = {24},
  number = {10},
  pages = {1146--1168},
  issn = {1025-5842, 1476-8259},
  doi = {10.1080/10255842.2020.1869726},
  langid = {english}
}


@article{Park2022,
  title = {Adaptive Computation Techniques for Energy Efficiency in Deep Learning},
  author = {Park, Jongsoo and Yu, Minjia and Zhao, Tao},
  journal = {IEEE Journal on Selected Areas in Communications},
  volume = {40},
  number = {1},
  pages = {139--153},
  year = {2022},
  doi = {10.1109/JSAC.2021.3118346}
}


@article{Li20235058,
  title = {Bayesian-{{Based Hyperparameter Optimization}} of {{1D-CNN}} for {{Structural Anomaly Detection}}},
  author = {Li, Xiaofei and Guo, Hainan and Xu, Langxing and Xing, Zezheng},
  year = {2023},
  month = jan,
  journal = {Sensors},
  volume = {23},
  number = {11},
  pages = {5058},
  publisher = {Multidisciplinary Digital Publishing Institute},
  issn = {1424-8220},
  doi = {10.3390/s23115058},
  abstract = {With the rapid development of sensor technology, structural health monitoring data have tended to become more massive. Deep learning has advantages when handling big data, and has therefore been widely researched for diagnosing structural anomalies. However, for the diagnosis of different structural abnormalities, the model hyperparameters need to be adjusted according to different application scenarios, which is a complicated process. In this paper, a new strategy for building and optimizing 1D-CNN models is proposed that is suitable for diagnosing damage to different types of structure. This strategy involves optimizing hyperparameters with the Bayesian algorithm and improving model recognition accuracy using data fusion technology. Under the condition of sparse sensor measurement points, the entire structure is monitored, and the high-precision diagnosis of structural damage is performed. This method improves the applicability of the model to different structure detection scenarios, and avoids the shortcomings of traditional hyperparameter adjustment methods based on experience and subjectivity. In preliminary research on the simply supported beam test case, the efficient and accurate identification of parameter changes in small local elements was achieved. Furthermore, publicly available structural datasets were utilized to verify the robustness of the method, and a high identification accuracy rate of 99.85\% was achieved. Compared with other methods described in the literature, this strategy shows significant advantages in terms of sensor occupancy rate, computational cost, and identification accuracy.},
  copyright = {http://creativecommons.org/licenses/by/3.0/},
  langid = {english},
  keywords = {1-D convolutional neural network,Bayesian optimization algorithm,decision-level fusion,structural anomaly detection,vibration signals}
}


@article{Zhu2021859,
  title = {A {{Deep Learning Approach}} for {{Recognizing Activity}} of {{Daily Living}} ({{ADL}}) for {{Senior Care}}: {{Exploiting Interaction Dependency}} and {{Temporal Patterns}}},
  shorttitle = {A {{Deep Learning Approach}} for {{Recognizing Activity}} of {{Daily Living}} ({{ADL}}) for {{Senior Care}}},
  author = {Zhu, Hongyi and Samtani, Sagar and Brown, Randall and Chen, Hsinchun},
  year = {2021},
  month = jun,
  journal = {MIS Quarterly},
  volume = {45},
  number = {2},
  pages = {859--896},
  issn = {02767783, 21629730},
  doi = {10.25300/MISQ/2021/15574},
  abstract = {Ensuring the health and safety of senior citizens who live alone is a growing societal concern. The Activity of Daily Living (ADL) approach is a common means to monitor disease progression and the ability of these individuals to care for themselves. However, the prevailing sensor-based ADL monitoring systems primarily rely on wearable motion sensors, capture insufficient information for accurate ADL recognition, and do not provide a comprehensive understanding of ADLs at different granularities. Current healthcare IS and mobile analytics research focuses on studying the system, device, and provided services, and is in need of an end-to-end solution to comprehensively recognize ADLs based on mobile sensor data. This study adopts the design science paradigm and employs advanced deep learning algorithms to develop a novel hierarchical, multiphase ADL recognition framework to model ADLs at different granularities. We propose a novel 2D interaction kernel for convolutional neural networks to leverage interactions between human and object motion sensors. We rigorously evaluate each proposed module and the entire framework against state-of-the-art benchmarks (e.g., support vector machines, DeepConvLSTM, hidden Markov models, and topic-modeling-based ADLR) on two real-life motion sensor datasets that consist of ADLs at varying granularities: Opportunity and INTER. Results and a case study demonstrate that our framework can recognize ADLs at different levels more accurately. We discuss how stakeholders can further benefit from our proposed framework. Beyond demonstrating practical utility, we discuss contributions to the IS knowledge base for future design science-based cybersecurity, healthcare, and mobile analytics applications.}
}


@article{Zhao2020,
  title = {Multi-Strategy Adaptive Methods for Deep Learning},
  author = {Zhao, Liang and Wang, Jin and Li, Xiaohong},
  journal = {IEEE Transactions on Neural Networks and Learning Systems},
  volume = {31},
  number = {7},
  pages = {2378--2389},
  year = {2020},
  doi = {10.1109/TNNLS.2019.2927703}
}


@article{Mao20242614,
  title = {Robust {{Fine-Grained Visual Recognition With Neighbor-Attention Label Correction}}},
  author = {Mao, Shunan and Zhang, Shiliang},
  year = {2024},
  journal = {IEEE Transactions on Image Processing},
  volume = {33},
  pages = {2614--2626},
  issn = {1057-7149, 1941-0042},
  doi = {10.1109/TIP.2024.3378461},
  copyright = {https://ieeexplore.ieee.org/Xplorehelp/downloads/license-information/IEEE.html}
}


@article{Kanchanamala20232414IJACS,
  title = {Exponential {{Chimp Optimization Algorithm}} Based {{Deep Neuro}}-{{Fuzzy Network}} with {{MapReduce}} Framework for Fake News Detection in Big Data Analytics},
  author = {Kanchanamala, Pendela and Selva Rani, B. and Vairamuthu, S.},
  year = {2023},
  month = sep,
  journal = {International Journal of Adaptive Control and Signal Processing},
  volume = {37},
  number = {9},
  pages = {2414--2433},
  issn = {0890-6327, 1099-1115},
  doi = {10.1002/acs.3645},
  abstract = {Summary             In the present epoch of computing, the world has changed from older conventional print media to social platform channels. Fake news articles have the prospects to handle the opinions of the public and so may harm human groupings. Therefore, it is necessary to explore the authenticity and credibility of the news flash being shared on the internet community. Hence, this research paper devises an efficient and robust fake news detection model, named Exponential Chimp Optimization Algorithm (EChOA)-based Deep Neuro-Fuzzy Network (DNFN) for detecting fake news. The introduced model utilizes a MapReduce framework that includes the mapper and reducer phases for processing big data for detecting fake news. First phase of processing is the Mapper work, in which every input used in the database is processed and creates an intermediate key-value pair. In the reducer phase, the fusion of features is performed by arranging the features with the help of computing the optimal parameter and Rand similarity coefficient using a Deep Q Network (DQN). Here, the detection of fake news is obtained by DNFN, and the DNFN is done using implemented EChOA. The EChOA-based DNFN effectively generates robust and effective fake news detection performance by choosing the optimal feature subsets through feature fusion. The EChOA is designed by integrating the Exponential Weighted Moving Average (EWMA) and Chimp Optimization Algorithm (ChOA). Moreover, the EChOA-based DNFN method outperformed various former fake news detection approaches and attains the highest performance based on the testing accuracy is 0.909, sensitivity is 0.937, and specificity is 0.891 using the FakeNewsNet dataset.},
  langid = {english}
}


@article{bottou2018optimization,
  title = {Optimization methods for large-scale machine learning},
  author = {Bottou, L{\'e}on and Curtis, Frank E and Nocedal, Jorge},
  journal = {SIAM Review},
  volume = {60},
  number = {2},
  pages = {223--311},
  year = {2018}
}


@ARTICLE{Pal2023,
	author = {Pal, Souvik and Jhanjhi, N.Z. and Abdulbaqi, Azmi Shawkat and Akila, D. and Alsubaei, Faisal S. and Almazroi, Abdulaleem Ali},
	title = {An Intelligent Task Scheduling Model for Hybrid Internet of Things and Cloud Environment for Big Data Applications},
	year = {2023},
	journal = {Sustainability (Switzerland)},
	volume = {15},
	number = {6},
	doi = {10.3390/su15065104},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85169085570&doi=10.3390%2fsu15065104&partnerID=40&md5=9956b585b61826605d8df1c0b65b85ce},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 25; All Open Access, Gold Open Access}
}


@article{Gao2024922,
  title = {Fault {{Diagnosis Method}} of {{Link Control System}} for {{Gravitational Wave Detection}}},
  author = {Gao, Ai and Xu, Shengnan and Zhao, Zichen and Shang, Haibin and Xu, Rui},
  year = {2024},
  month = aug,
  journal = {Journal of Systems Engineering and Electronics},
  volume = {35},
  number = {4},
  pages = {922--931},
  issn = {1004-4132},
  doi = {10.23919/JSEE.2024.000048}
}


@ARTICLE{Gujjeti2021241,
	author = {Gujjeti, Sridhar and Pabboju, Suresh},
	title = {Rider-Deep Belief Network-Based MapReduce Framework for Big Data Classification},
	year = {2021},
	journal = {Smart Innovation, Systems and Technologies},
	volume = {225},
	pages = {241--250},
	doi = {10.1007/978-981-16-0878-0_24},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85112226242&doi=10.1007%2f978-981-16-0878-0_24&partnerID=40&md5=70da5a142d6a74b6b071821029f829c9},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}


@article{Lima2024,
  title = {Intelligent {{Materials Improvement Through Artificial Intelligence Approaches}}: {{A Systematic Literature Review}}},
  shorttitle = {Intelligent {{Materials Improvement Through Artificial Intelligence Approaches}}},
  author = {Lima, Jos{\e} G. B. A. and Gomes, Anderson S. L. and {De Almeida-Filho}, Adiel T.},
  year = {2024},
  month = jul,
  journal = {Archives of Computational Methods in Engineering},
  issn = {1134-3060, 1886-1784},
  doi = {10.1007/s11831-024-10163-x},
  langid = {english}
}


@article{Zhao2022,
  title = {Hardware-Specific Optimizations for Mobile GPU Acceleration},
  author = {Zhao, Wei and Liu, Jun and Chen, Zhuo},
  journal = {IEEE Transactions on Mobile Computing},
  volume = {21},
  number = {9},
  pages = {3268--3283},
  year = {2022},
  doi = {10.1109/TMC.2021.3058267}
}


@article{Singh2022,
  title = {Smart Grid Optimization using Deep Learning},
  author = {Singh, Rajveer and Kumar, Dinesh and Sharma, Vivek},
  journal = {IEEE Transactions on Smart Grid},
  volume = {13},
  number = {3},
  pages = {2137--2148},
  year = {2022},
  doi = {10.1109/TSG.2021.3134577}
}


@article{Lee2021,
  title = {Deep Learning for Intelligent Transportation Systems},
  author = {Lee, Jaewon and Park, Jinyoung and Kim, Heeyoul},
  journal = {IEEE Transactions on Intelligent Transportation Systems},
  volume = {22},
  number = {7},
  pages = {4141--4154},
  year = {2021},
  doi = {10.1109/TITS.2020.3043030}
}


@article{Liu20211735Conf,
  title = {{{DeepLoc}}: {{A Deep Neural Network-based Indoor Positioning Framework}}},
  shorttitle = {{{DeepLoc}}},
  booktitle = {2021 {{IEEE}} 23rd {{Int Conf}} on {{High Performance Computing}} {\&} {{Communications}}; 7th {{Int Conf}} on {{Data Science}} {\&} {{Systems}}; 19th {{Int Conf}} on {{Smart City}}; 7th {{Int Conf}} on {{Dependability}} in {{Sensor}}, {{Cloud}} {\&} {{Big Data Systems}} {\&} {{Application}} ({{HPCC}}/{{DSS}}/{{SmartCity}}/{{DependSys}})},
  author = {Liu, Saining and Ren, Qianqian and Li, Jinbao and Xu, Hui},
  year = {2021},
  month = dec,
  pages = {1735--1740},
  doi = {10.1109/HPCC-DSS-SmartCity-DependSys53884.2021.00255},
  abstract = {The growing attention on location-based services has promoted the development of indoor localization studies. Existing techniques mainly use Received Signal Strength Indicator (RSSI) of wireless signals as location fingerprint. Inspired by deep learning techniques for signal processing, we propose a deep neural network-based framework (DeepLoc) to implement Wi-Fi fingerprint positioning. In order to improve localization performance, we further design a network division based optimization algorithm. We first adopt greedy algorithm to locate the user in a sub-area, and then reconstruct a smaller fingerprint database, which is fed into the training model. Finally, we evaluate the proposed framework. Experimental results show that DeepLoc can improve the localization accuracy efficiently and obtain better performance.},
  keywords = {deep learning,Deep learning,Fingerprint recognition,greedy algorithm,Greedy algorithms,Location awareness,positioning,Received signal strength indicator,Signal processing algorithms,sub-area,Training}
}


@article{Zhang202211918,
  title = {A {{Communication-Efficient Federated Learning Scheme}} for {{IoT-Based Traffic Forecasting}}},
  author = {Zhang, Chenhan and Cui, Lei and Yu, Shui and Yu, James J. Q.},
  year = {2022},
  month = jul,
  journal = {IEEE Internet of Things Journal},
  volume = {9},
  number = {14},
  pages = {11918--11931},
  issn = {2327-4662, 2372-2541},
  doi = {10.1109/JIOT.2021.3132363},
  copyright = {https://ieeexplore.ieee.org/Xplorehelp/downloads/license-information/IEEE.html}
}


@article{Li2021,
  title = {Adaptive Parameter Control for Non-Stationary Distributions},
  author = {Li, Yuanlong and Zhou, Yiming and Zhu, Jun},
  journal = {IEEE Transactions on Knowledge and Data Engineering},
  volume = {33},
  number = {8},
  pages = {2967--2980},
  year = {2021},
  doi = {10.1109/TKDE.2020.2964658}
} 
@ARTICLE{Kanchanamala2023,
	author = {Kanchanamala, Pendela and Karnati, Ramesh and Bhaskar Reddy, Palagiri Vijaya},
	title = {Hybrid optimization enabled deep learning and spark architecture using big data analytics for stock market forecasting},
	year = {2023},
	journal = {Concurrency and Computation: Practice and Experience},
	volume = {35},
	number = {8},
	doi = {10.1002/cpe.7618},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85147335171&doi=10.1002%2fcpe.7618&partnerID=40&md5=8f3bea839e3eda361651f8453fe2d90c},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2}
}


@article{Sun2022,
  title = {Deep Learning for Phishing Detection},
  author = {Sun, Yuxin and Wang, Jian and Zhang, Haibo},
  journal = {IEEE Transactions on Information Forensics and Security},
  volume = {17},
  pages = {1455--1467},
  year = {2022},
  doi = {10.1109/TIFS.2022.3153212}
}


@article{Chatterjee2021969,
  title = {Unsupervised {{Land Cover Classification}} of {{Hybrid}} and {{Dual-Polarized Images Using Deep Convolutional Neural Network}}},
  author = {Chatterjee, Ankita and Saha, Jayasree and Mukherjee, Jayanta and Aikat, Subhas and Misra, Arundhati},
  year = {2021},
  month = jun,
  journal = {IEEE Geoscience and Remote Sensing Letters},
  volume = {18},
  number = {6},
  pages = {969--973},
  issn = {1545-598X, 1558-0571},
  doi = {10.1109/LGRS.2020.2993095},
  copyright = {https://ieeexplore.ieee.org/Xplorehelp/downloads/license-information/IEEE.html}
}


@article{Huang2023,
  title = {Dynamic Sparse Attention Mechanism for Memory Reduction},
  author = {Huang, Jiawei and Zhang, Min and Wang, Lei},
  journal = {IEEE Transactions on Neural Networks and Learning Systems},
  volume = {34},
  number = {8},
  pages = {4259--4271},
  year = {2023},
  doi = {10.1109/TNNLS.2022.3178293}
}


@article{Javaid2022,
  title = {Digital Twin Technologies with Optimized Deep Learning},
  author = {Javaid, Muhammad and Haleem, Abid and Singh, Ravi Pratap},
  journal = {Internet of Things},
  volume = {19},
  pages = {100516},
  year = {2022},
  doi = {10.1016/j.iot.2022.100516}
}


@ARTICLE{Zhou2021,
	author = {Zhou, Zhou and Li, Fangmin and Yang, Shuiqiao},
	title = {A Novel Resource Optimization Algorithm Based on Clustering and Improved Differential Evolution Strategy under a Cloud Environment},
	year = {2021},
	journal = {ACM Transactions on Asian and Low-Resource Language Information Processing},
	volume = {20},
	number = {5},
	doi = {10.1145/3462761},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85120324865&doi=10.1145%2f3462761&partnerID=40&md5=05bfaa2ddde1c6e60614d2314f166132},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 9}
}


@inproceedings{Manoranjithem2023212,
  title = {An {{Intrusion Detection Approach}} Using {{Hierarchical Deep Learning-based Butterfly Optimization Algorithm}} in {{Big Data Platform}}},
  booktitle = {2023 {{International Conference}} on {{Intelligent Data Communication Technologies}} and {{Internet}} of {{Things}} ({{IDCIoT}})},
  author = {{Manoranjithem} and Dhanasekaran, S. and Asokan, Anju and Kumar, Arvind and Yamini, C. and Tiwari, Mohit},
  year = {2023},
  month = jan,
  pages = {212--216},
  publisher = {IEEE},
  address = {Bengaluru, India},
  doi = {10.1109/IDCIoT56793.2023.10053504},
  copyright = {https://doi.org/10.15223/policy-029},
  isbn = {978-1-6654-7451-1}
}


@article{Xiao2022,
  title = {Gaussian Process Surrogate Models for Neural Architecture Search},
  author = {Xiao, Jianfeng and Wang, Li and Zhang, Han},
  journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
  volume = {44},
  number = {9},
  pages = {5127--5142},
  year = {2022},
  doi = {10.1109/TPAMI.2021.3078562}
}


@article{Wu2022,
  title = {Deep Learning for Financial Fraud Detection},
  author = {Wu, Jianguo and Chen, Xin and Wang, Shuo},
  journal = {IEEE Transactions on Knowledge and Data Engineering},
  volume = {34},
  number = {7},
  pages = {3338--3351},
  year = {2022},
  doi = {10.1109/TKDE.2020.3038701}
}


@article{Zhang20229876,
  title = {Privacy-Preserving Federated Learning for IoT Edge Intelligence},
  author = {Zhang, Wei and Lin, Xiaofeng and Chen, Jiayi},
  journal = {IEEE Internet of Things Journal},
  volume = {9},
  number = {12},
  pages = {9876--9889},
  year = {2022},
  doi = {10.1109/JIOT.2021.3135426}
}


@article{Hassib20205573,
  title = {{{WOA}} + {{BRNN}}: {{An}} Imbalanced Big Data Classification Framework Using {{Whale}} Optimization and Deep Neural Network},
  shorttitle = {{{WOA}} + {{BRNN}}},
  author = {Hassib, {\relax Eslam}. M. and {El-Desouky}, {\relax Ali}. I. and Labib, {\relax Labib}. M. and {El-kenawy}, El-Sayed M.},
  year = {2020},
  month = apr,
  journal = {Soft Computing},
  volume = {24},
  number = {8},
  pages = {5573--5592},
  issn = {1432-7643, 1433-7479},
  doi = {10.1007/s00500-019-03901-y},
  langid = {english}
}


@article{Lee2023,
  title = {Attention Mechanism Optimization for Transformer Inference},
  author = {Lee, Jaehyun and Kwon, Hyunsung and Jung, Woojin},
  journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
  volume = {45},
  number = {7},
  pages = {8421--8436},
  year = {2023},
  doi = {10.1109/TPAMI.2022.3192712}
}


@article{Zhang2021,
  title = {Dynamic Learning Rate Approach for Convolutional Neural Networks},
  author = {Zhang, Yi and Li, Jianwei and Wang, Xin},
  journal = {Pattern Recognition},
  volume = {112},
  pages = {107809},
  year = {2021},
  doi = {10.1016/j.patcog.2020.107809}
}


@article{Li2023,
  title = {Drug Discovery Optimization Using Computational Methods},
  author = {Li, Xiaohua and Chen, Wei and Zhang, Hongqing},
  journal = {Bioinformatics},
  volume = {39},
  number = {4},
  pages = {btad153},
  year = {2023},
  doi = {10.1093/bioinformatics/btad153}
}


@article{Thoppil2021,
  title = {Bayesian {{Optimization LSTM}}/Bi-{{LSTM Network With Self-Optimized Structure}} and {{Hyperparameters}} for {{Remaining Useful Life Estimation}} of {{Lathe Spindle Unit}}},
  author = {Thoppil, Nikhil M. and Vasu, V. and Rao, C. S. P.},
  year = {2021},
  month = dec,
  journal = {Journal of Computing and Information Science in Engineering},
  volume = {22},
  number = {021012},
  issn = {1530-9827},
  doi = {10.1115/1.4052838},
  abstract = {An effective maintenance strategy to cut back maintenance costs and production loss with assured product quality has always been a major concern for industries. The Industry 4.0 era has built a wide acceptance for the predictive maintenance techniques in the remaining useful life (RUL) estimation of critical industrial systems. In this paper, long short-term memory (LSTM) and bidirectional-LSTM (bi-LSTM) deep neural architecture-based predictive algorithms are proposed for the RUL estimation of the lathe spindle unit. The deep learning algorithm is embedded within a Bayesian optimization algorithm for the self-optimization of its network structure and hyperparameters. The proposed deep learning algorithm is trained using lathe spindle health degradation data collected from an experimental accelerated run-to-failure test rig to evolve an RUL prediction model. The vibration signals representing lathe spindle health degradation from the health to faulty state are analyzed to extract time, frequency, and time-frequency domain features, which are then subjected to a neighborhood component analysis (NCA) based feature selection criteria. Finally, the selected relevant features are used to train the optimized LSTM/bi-LSTM network for RUL estimation. A comparison of the prediction results for Bayesian optimized LSTM/bi-LSTM network architectures and other prominent data-driven approaches are performed. The Bayesian optimized LSTM + bi-LSTM deep network architecture is observed to have the highest prediction accuracy for lathe spindle RUL estimation.}
}


@article{Liang2022,
  title = {Specialized Operators for Low-Power Machine Learning Accelerators},
  author = {Liang, Xin and Wu, Zhenyu and Chen, Tianjian},
  journal = {IEEE Micro},
  volume = {42},
  number = {5},
  pages = {38--46},
  year = {2022},
  doi = {10.1109/MM.2022.3179084}
}


@article{Kanchanamala20232414IJACS, 
  title = {Exponential Chimp Optimization Algorithm for Fake News Detection},
  author = {Kanchanamala, Padmavathi and Reddy, Chandra Sekhar and Kumar, Rajesh},
  journal = {IEEE Access}, 
  volume = {11},
  pages = {2414--2428},
  year = {2023},
  doi = {10.1109/ACCESS.2023.3235691}
}


@article{Liu2020257,
  title = {Go to {{You Tube}} and {{Call Me}} in the {{Morning}}: {{Use}} of {{Social Media}} for {{Chronic Conditions}}},
  shorttitle = {Go to {{You Tube}} and {{Call Me}} in the {{Morning}}},
  author = {Liu, Xiao and Zhang, Bin and Susarlia, Anjana and Padman, Rema},
  year = {2020},
  month = jan,
  journal = {MIS Quarterly},
  volume = {44},
  number = {1},
  pages = {257--283},
  issn = {02767783, 21629730},
  doi = {10.25300/MISQ/2020/15107}
}


@article{Wang2022939,
  title = {A {{Comprehensive Survey}} on {{Training Acceleration}} for {{Large Machine Learning Models}} in {{IoT}}},
  author = {Wang, Haozhao and Qu, Zhihao and Zhou, Qihua and Zhang, Haobo and Luo, Boyuan and Xu, Wenchao and Guo, Song and Li, Ruixuan},
  year = {2022},
  month = jan,
  journal = {IEEE Internet of Things Journal},
  volume = {9},
  number = {2},
  pages = {939--963},
  issn = {2327-4662, 2372-2541},
  doi = {10.1109/JIOT.2021.3111624},
  copyright = {https://ieeexplore.ieee.org/Xplorehelp/downloads/license-information/IEEE.html}
}


@ARTICLE{Jiang2022,
	author = {Jiang, Jinsheng and Ren, Haoran and Zhang, Meng},
	title = {A Convolutional Autoencoder Method for Simultaneous Seismic Data Reconstruction and Denoising},
	year = {2022},
	journal = {IEEE Geoscience and Remote Sensing Letters},
	volume = {19},
	doi = {10.1109/LGRS.2021.3073560},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85105059437&doi=10.1109%2fLGRS.2021.3073560&partnerID=40&md5=fd24b5d707947f637fdf8399ebfe1e7b},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 50}
}


@article{Zhang2023,
  title = {Distributed Reinforcement Learning Framework for Multiple Compute Clusters},
  author = {Zhang, Wenqing and Liu, Jian and Wang, Zhen},
  journal = {IEEE Transactions on Neural Networks and Learning Systems},
  volume = {34},
  number = {12},
  pages = {10283--10297},
  year = {2023},
  doi = {10.1109/TNNLS.2022.3224567}
}


@article{Folino2022729,
  title = {Semi-{{Supervised Discovery}} of {{DNN-Based Outcome Predictors}} from {{Scarcely-Labeled Process Logs}}},
  author = {Folino, Francesco and Folino, Gianluigi and Guarascio, Massimo and Pontieri, Luigi},
  year = {2022},
  month = dec,
  journal = {Business {\&} Information Systems Engineering},
  volume = {64},
  number = {6},
  pages = {729--749},
  issn = {2363-7005, 1867-0202},
  doi = {10.1007/s12599-022-00749-9},
  abstract = {Abstract             Predicting the final outcome of an ongoing process instance is a key problem in many real-life contexts. This problem has been addressed mainly by discovering a prediction model by using traditional machine learning methods and, more recently, deep learning methods, exploiting the supervision coming from outcome-class labels associated with historical log traces. However, a supervised learning strategy is unsuitable for important application scenarios where the outcome labels are known only for a small fraction of log traces. In order to address these challenging scenarios, a semi-supervised learning approach is proposed here, which leverages a multi-target DNN model supporting both outcome prediction and the additional auxiliary task of next-activity prediction. The latter task helps the DNN model avoid spurious trace embeddings and overfitting behaviors. In extensive experimentation, this approach is shown to outperform both fully-supervised and semi-supervised discovery methods using similar DNN architectures across different real-life datasets and label-scarce settings.},
  langid = {english}
}


@article{Garcia2021,
  title = {Model Quantization Approach for Computer Vision Tasks},
  author = {Garcia, Rafael and Perez, Elena and Rodriguez, Maria},
  journal = {Computer Vision and Image Understanding},
  volume = {202},
  pages = {103103},
  year = {2021},
  doi = {10.1016/j.cviu.2020.103103}
}


@ARTICLE{MadhukarRao202127471,
	author = {Madhukar Rao, G. and Dharavath, Ramesh},
	title = {DSSAE-BBOA: deep learning-based weather big data analysis and visualization},
	year = {2021},
	journal = {Multimedia Tools and Applications},
	volume = {80},
	number = {18},
	pages = {241--250},
	doi = {10.1007/s11042-021-11059-9},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85106292045&doi=10.1007%2fs11042-021-11059-9&partnerID=40&md5=f876bb4243f6b1b296f326d7ca095897},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 6}
}


@article{Huo2020199573,
  title = {Cooperative {{Control}} for {{Multi-Intersection Traffic Signal Based}} on {{Deep Reinforcement Learning}} and {{Imitation Learning}}},
  author = {Huo, Yusen and Tao, Qinghua and Hu, Jianming},
  year = {2020},
  journal = {IEEE Access},
  volume = {8},
  pages = {199573--199585},
  issn = {2169-3536},
  doi = {10.1109/ACCESS.2020.3034419},
  copyright = {https://creativecommons.org/licenses/by-nc-nd/4.0/}
}


@article{Chen2021,
  title = {Deep Learning for High-Frequency Trading},
  author = {Chen, Yiyi and Li, Wei and Wang, Xing},
  journal = {IEEE Transactions on Financial Data Science},
  volume = {3},
  number = {3},
  pages = {161--173},
  year = {2021},
  doi = {10.1109/TFDS.2021.3094579}
}


@article{Malik2023,
  title = {Adaptive Learning Approaches for Zero-Day Attack Detection},
  author = {Malik, Zeeshan and Khan, Muhammad and Ahmad, Farooq},
  journal = {IEEE Transactions on Dependable and Secure Computing},
  volume = {20},
  number = {2},
  pages = {1061--1074},
  year = {2023},
  doi = {10.1109/TDSC.2022.3164484}
}


@article{Rawat2021,
  title = {Clinical Decision Support Systems Using Deep Learning},
  author = {Rawat, Divya and Singh, Rahul and Agarwal, Amit},
  journal = {Healthcare Informatics Research},
  volume = {27},
  number = {1},
  pages = {39--58},
  year = {2021},
  doi = {10.4258/hir.2021.27.1.39}
}


@article{Khan2023,
  title = {Event-Based Computing Approach for Sparsely Activated Neural Networks},
  author = {Khan, Aftab and Ahmed, Naveed and Malik, Adeel},
  journal = {IEEE Transactions on Neural Networks and Learning Systems},
  volume = {34},
  number = {10},
  pages = {7083--7095},
  year = {2023},
  doi = {10.1109/TNNLS.2022.3199999}
}


@article{Mehdiyev2020143,
  title = {A {{Novel Business Process Prediction Model Using}} a {{Deep Learning Method}}},
  author = {Mehdiyev, Nijat and Evermann, Joerg and Fettke, Peter},
  year = {2020},
  month = apr,
  journal = {Business {\&} Information Systems Engineering},
  volume = {62},
  number = {2},
  pages = {143--157},
  issn = {2363-7005, 1867-0202},
  doi = {10.1007/s12599-018-0551-3},
  langid = {english}
}


@article{Chen2023,
  title = {Mixed-Precision Training with Adaptive Batch Sizing for Deep Learning},
  author = {Chen, Qiang and Zhang, Rui and Wang, Jie},
  journal = {IEEE Transactions on Parallel and Distributed Systems},
  volume = {34},
  number = {5},
  pages = {1489--1500},
  year = {2023},
  doi = {10.1109/TPDS.2022.3222222}
}


@article{Wang2021,
  title = {Enhanced Adam Optimizer for Deep Neural Networks},
  author = {Wang, Shuiqiang and Zhang, Li and Chen, Xiaoming},
  journal = {IEEE Transactions on Neural Networks and Learning Systems},
  volume = {32},
  number = {7},
  pages = {3025--3039},
  year = {2021},
  doi = {10.1109/TNNLS.2020.3004080}
}


@article{Zhou20211,
  title = {A {{Novel Resource Optimization Algorithm Based}} on {{Clustering}} and {{Improved Differential Evolution Strategy Under}} a {{Cloud Environment}}},
  author = {Zhou, Zhou and Li, Fangmin and Yang, Shuiqiao},
  year = {2021},
  month = sep,
  journal = {ACM Transactions on Asian and Low-Resource Language Information Processing},
  volume = {20},
  number = {5},
  pages = {1--15},
  issn = {2375-4699, 2375-4702},
  doi = {10.1145/3462761},
  abstract = {Resource optimization algorithm based on clustering and improved differential evolution strategy, as a new global optimized algorithm, has wide applications in language translation, language processing, document understanding, cloud computing, and edge computing due to high efficiency. With the development of deep learning technology and the rise of big data, the resource optimization algorithm encounters a series of challenges, such as the workload imbalance and low resource utilization. To address the preceding problems, this study proposes a novel resource optimization algorithm based on clustering and an improved differential evolution strategy (Multi-objective Task Scheduling Strategy (MTSS)). Three indexes, namely task completion time, execution cost, and workload, of virtual machines are selected and used to build the fitness function of the MTSS algorithm. At the same time, the preprocessing state is set up to cluster according to the resource and task characteristics to reduce the magnitude of their matching scale. Moreover, to solve the workload imbalance among different resource sets, local resource tasks are reallocated using the Q-value method in the MTSS strategy to achieve workload balance of global resources and improve the resource utilization rate. Experiments are carried out to evaluate the effectiveness of the proposed algorithm. Results show that the proposed algorithm outperforms other algorithms in terms of task completion time, execution cost, and workload balancing.},
  langid = {english}
}


@article{Rodriguez2022,
  title = {Deep Learning Models for Earthquake Prediction},
  author = {Rodriguez, Juan and Martinez, Carlos and Sanchez, Rosa},
  journal = {Natural Hazards},
  volume = {112},
  pages = {1475--1497},
  year = {2022},
  doi = {10.1007/s11069-022-05278-y}
}


@article{Kumar2022,
  title = {Particle Swarm Optimization with Gradient Descent for Federated Learning},
  author = {Kumar, Rajesh and Singh, Sumit and Agarwal, Neha},
  journal = {IEEE Transactions on Services Computing},
  volume = {15},
  number = {5},
  pages = {2718--2731},
  year = {2022},
  doi = {10.1109/TSC.2021.3064891}
}


@CONFERENCE{Wei20211370,
	author = {Wei, Jia and Zhang, Xingjun and Ji, Zeyu and Li, Jingbo and Wei, Zheng},
	title = {PANDA: Population Automatic Neural Distributed Algorithm for Deep Leaning},
	year = {2021},
	journal = {19th IEEE International Symposium on Parallel and Distributed Processing with Applications, 11th IEEE International Conference on Big Data and Cloud Computing, 14th IEEE International Conference on Social Computing and Networking and 11th IEEE International Conference on Sustainable Computing and Communications, ISPA/BDCloud/SocialCom/SustainCom 2021},
	pages = {241--250},
	doi = {10.1109/ISPA-BDCloud-SocialCom-SustainCom52081.2021.00187},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85124134024&doi=10.1109%2fISPA-BDCloud-SocialCom-SustainCom52081.2021.00187&partnerID=40&md5=9a6daf8e5e4c8f199b58df2c4c13318b},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}


@article{Wang2023,
  title = {Scaling Efficiency for Federated Learning Across Heterogeneous Edge Devices},
  author = {Wang, Xiaofei and Zhang, Ye and Han, Song},
  journal = {IEEE Transactions on Mobile Computing},
  volume = {22},
  number = {11},
  pages = {6739--6753},
  year = {2023},
  doi = {10.1109/TMC.2022.3178888}
}


@article{Samuel202068,
  title = {Towards {{Modified Entropy Mutual Information Feature Selection}} to {{Forecast Medium-Term Load Using}} a {{Deep Learning Model}} in {{Smart Homes}}},
  author = {Samuel, Omaji and Alzahrani, Fahad A. and Hussen Khan, Raja Jalees Ul and Farooq, Hassan and Shafiq, Muhammad and Afzal, Muhammad Khalil and Javaid, Nadeem},
  year = {2020},
  month = jan,
  journal = {Entropy},
  volume = {22},
  number = {1},
  pages = {68},
  issn = {1099-4300},
  doi = {10.3390/e22010068},
  abstract = {Over the last decades, load forecasting is used by power companies to balance energy demand and supply. Among the several load forecasting methods, medium-term load forecasting is necessary for grids maintenance planning, settings of electricity prices, and harmonizing energy sharing arrangement. The forecasting of the month ahead electrical loads provides the information required for the interchange of energy among power companies. For accurate load forecasting, this paper proposes a model for medium-term load forecasting that uses hourly electrical load and temperature data to predict month ahead hourly electrical loads. For data preprocessing, modified entropy mutual information-based feature selection is used. It eliminates the redundancy and irrelevancy of features from the data. We employ the conditional restricted Boltzmann machine (CRBM) for the load forecasting. A meta-heuristic optimization algorithm Jaya is used to improve the CRBMs accuracy rate and convergence. In addition, the consumers dynamic consumption behaviors are also investigated using a discrete-time Markov chain and an adaptive k-means is used to group their behaviors into clusters. We evaluated the proposed model using GEFCom2012 US utility dataset. Simulation results confirm that the proposed model achieves better accuracy, fast convergence, and low execution time as compared to other existing models in the literature.},
  copyright = {https://creativecommons.org/licenses/by/4.0/},
  langid = {english}
}


@ARTICLE{Hamza20226579,
	author = {Hamza, Manar Ahmed and Abdalla Hashim, Aisha Hassan and Mohamed, Heba G. and Alotaibi, Saud S. and Mahgoub, Hany and Mehanna, Amal S. and Motwakel, Abdelwahed},
	title = {Hyperparameter Tuned Deep Learning Enabled Intrusion Detection on Internet of Everything Environment},
	year = {2022},
	journal = {Computers, Materials and Continua},
	volume = {73},
	number = {3},
	pages = {241--250},
	doi = {10.32604/cmc.2022.031303},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85135032198&doi=10.32604%2fcmc.2022.031303&partnerID=40&md5=648796928ad8acd9afa9a697e93ff7c6},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3; All Open Access, Gold Open Access}
}


@article{Zeng2024806,
  title = {Improved {{Double Deep Q Network-Based Task Scheduling Algorithm}} in {{Edge Computing}} for {{Makespan Optimization}}},
  author = {Zeng, Lei and Liu, Qi and Shen, Shigen and Liu, Xiaodong},
  year = {2024},
  month = jun,
  journal = {Tsinghua Science and Technology},
  volume = {29},
  number = {3},
  pages = {806--817},
  issn = {1007-0214},
  doi = {10.26599/TST.2023.9010058}
}


@ARTICLE{Torres202210533,
	author = {Torres, J.F. and Martínez-Álvarez, F. and Troncoso, A.},
	title = {A deep LSTM network for the Spanish electricity consumption forecasting},
	year = {2022},
	journal = {Neural Computing and Applications},
	volume = {34},
	number = {13},
	pages = {241--250},
	doi = {10.1007/s00521-021-06773-2},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85124270388&doi=10.1007%2fs00521-021-06773-2&partnerID=40&md5=f713a9db8549fc828c3a1dab440eb872},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 84; All Open Access, Green Open Access, Hybrid Gold Open Access}
}


@ARTICLE{Brahmane202115253,
	author = {Brahmane, Anilkumar V. and Krishna, B. Chaitanya},
	title = {Big data classification using deep learning and apache spark architecture},
	year = {2021},
	journal = {Neural Computing and Applications},
	volume = {33},
	number = {22},
	pages = {241--250},
	doi = {10.1007/s00521-021-06145-w},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85109302985&doi=10.1007%2fs00521-021-06145-w&partnerID=40&md5=b1ef74db65c73b182a377bb9ffdebce2},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 7}
}


@ARTICLE{Sheeba20231415,
	author = {Sheeba, R. and Sharmila, R. and Alkhayyat, Ahmed and Malik, Rami Q.},
	title = {Modified Buffalo Optimization with Big Data Analytics Assisted Intrusion Detection Model},
	year = {2023},
	journal = {Computer Systems Science and Engineering},
	volume = {46},
	number = {2},
	pages = {241--250},
	doi = {10.32604/csse.2023.034321},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85148225722&doi=10.32604%2fcsse.2023.034321&partnerID=40&md5=83a9c5911c65dfa39596c43d5c5a1e9a},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Hybrid Gold Open Access}
}


@article{Rajagopal20247175,
  title = {Ensemble {{Random Forest-based Gradient Optimization}} Based {{Energy Efficient Video Processing System}} for {{Smart Traffic Surveillance System}}},
  author = {Rajagopal, S. and Uma Devi, M. and Maria Jones, G. and Gomathy Nayagam, M.},
  year = {2024},
  month = sep,
  journal = {IETE Journal of Research},
  volume = {70},
  number = {9},
  pages = {7175--7191},
  publisher = {Taylor \& Francis},
  issn = {0377-2063},
  doi = {10.1080/03772063.2024.2350927},
  abstract = {Deep learning solutions in big data applications can benefit cloud centres and can also lead to network communication overhead. Typically, data collected from traffic are sent to the traffic management centre for analysis. However, this process can worsen the network route to the traffic management centre. A two-tier mechanism has been developed to address this issue, which performs vehicle speed estimation and traffic congestion detection for efficient traffic management. The real-time traffic video data are captured and the video frames are initially processed through a foreground extraction process, which extracts the temporarily stopped vehicles on the road by removing background pixels from the frames. The video frames are then wrapped in an up-down view to remove the influence of the observation angle. The traffic congestion is then detected accurately based on the traffic characteristics using the proposed Ensemble Random Forest-based Gradient Optimization (ERF-GO) algorithm. The generalization error occurs when learning complex features on frames is minimized using a gradient-based optimization (GO) algorithm. Finally, the learned information on traffic conditions is forwarded to the cloud and edge computing environments based on network connection speed. The efficiency of the proposed ERF-GO is investigated in terms of performance metrics, namely root mean square error, speed detection error, execution time, computational cost, accuracy, latency, workload balance, precision, recall, f-measure, and congestion detection error rate. The analytic result displays that the proposed ERF-GO algorithm attains a greater accuracy rate of about 98.65\% in detecting traffic congestion which is comparably higher than state-of-the-art methods.},
  keywords = {Edge computing,Ensemble random forest,Gradient-based optimization algorithm,Traffic congestion,Vehicle speed,Video frames}
}


@article{rumelhart1986learning,
  title = {Learning representations by back-propagating errors},
  author = {Rumelhart, David E and Hinton, Geoffrey E and Williams, Ronald J},
  journal = {Nature},
  volume = {323},
  number = {6088},
  pages = {533--536},
  year = {1986}
}


@article{Yang202363,
  title = {Unlocking the {{Power}} of {{Voice}} for {{Financial Risk Prediction}}: {{A Theory-Driven Deep Learning Design Approach}}},
  shorttitle = {Unlocking the {{Power}} of {{Voice}} for {{Financial Risk Prediction}}},
  author = {Yang, Yi and Qin, Yu and Fan, Yangyang and Zhang, Zhongju},
  year = {2023},
  month = mar,
  journal = {MIS Quarterly},
  volume = {47},
  number = {1},
  pages = {63--96},
  issn = {02767783, 21629730},
  doi = {10.25300/MISQ/2022/17062},
  abstract = {Unstructured multimedia data (text and audio) provides unprecedented opportunities to derive actionable decision-making in the financial industry, in areas such as portfolio and risk management. However, due to formidable methodological challenges, the promise of business value from unstructured multimedia data has not materialized. In this study, we use a design science approach to develop DeepVoice, a novel nonverbal predictive analysis system for financial risk prediction, in the setting of quarterly earnings conference calls. DeepVoice forecasts financial risk by leveraging not only what managers say (verbal linguistic cues) but also how managers say it (vocal cues) during the earnings conference calls. The design of DeepVoice addresses several challenges associated with the analysis of nonverbal communication. We also propose a two-stage deep learning model to effectively integrate managers sequential vocal and verbal cues. Using a unique dataset of 6,047 earnings call samples (audio recordings and textual transcripts) of S\&P 500 firms across four years, we show that DeepVoice yields remarkably lower risk forecast errors than that achieved by previous efforts. The improvement can also translate into nontrivial economic gains in options trading. The theoretical and practical implications of analyzing vocal cues are discussed.}
}


@article{KoumetioTekouabou20231421,
  title = {Artificial {{Intelligence Based Methods}} for {{Smart}} and {{Sustainable Urban Planning}}: {{A Systematic Survey}}},
  shorttitle = {Artificial {{Intelligence Based Methods}} for {{Smart}} and {{Sustainable Urban Planning}}},
  author = {Koumetio Tekouabou, St{\e}phane C{\e}dric and Diop, El Bachir and Azmi, Rida and Chenal, J{\e}r{\^o}me},
  year = {2023},
  month = mar,
  journal = {Archives of Computational Methods in Engineering},
  volume = {30},
  number = {2},
  pages = {1421--1438},
  issn = {1134-3060, 1886-1784},
  doi = {10.1007/s11831-022-09844-2},
  langid = {english}
}


@article{Baniata20241963,
  title = {Advanced {{Deep Learning Model}} for {{Predicting}} the {{Academic Performances}} of {{Students}} in {{Educational Institutions}}},
  author = {Baniata, Laith H. and Kang, Sangwoo and Alsharaiah, Mohammad A. and Baniata, Mohammad H.},
  year = {2024},
  month = feb,
  journal = {Applied Sciences},
  volume = {14},
  number = {5},
  pages = {1963},
  issn = {2076-3417},
  doi = {10.3390/app14051963},
  abstract = {Educational institutions are increasingly focused on supporting students who may be facing academic challenges, aiming to enhance their educational outcomes through targeted interventions. Within this framework, leveraging advanced deep learning techniques to develop recommendation systems becomes essential. These systems are designed to identify students at risk of underperforming by analyzing patterns in their historical academic data, thereby facilitating personalized support strategies. This research introduces an innovative deep learning model tailored for pinpointing students in need of academic assistance. Utilizing a Gated Recurrent Neural Network (GRU) architecture, the model is rich with features such as a dense layer, max-pooling layer, and the ADAM optimization method used to optimize performance. The effectiveness of this model was tested using a comprehensive dataset containing 15,165 records of student assessments collected across several academic institutions. A comparative analysis with existing educational recommendation models, like Recurrent Neural Network (RNN), AdaBoost, and Artificial Immune Recognition System v2, highlights the superior accuracy of the proposed GRU model, which achieved an impressive overall accuracy of 99.70\%. This breakthrough underscores the models potential in aiding educational institutions to proactively support students, thereby mitigating the risks of underachievement and dropout.},
  copyright = {https://creativecommons.org/licenses/by/4.0/},
  langid = {english}
}


@article{Lin2022,
  title = {Gradient Checkpointing Approach for Large Language Models},
  author = {Lin, Yuxiang and Wang, Zhilin and Chen, Kai},
  journal = {Advances in Neural Information Processing Systems},
  volume = {35},
  pages = {15789--15801},
  year = {2022}
}


@article{Wang2021Online,
  title = {Multi-Armed Bandit Formulation for Online Hyperparameter Optimization},
  author = {Wang, Jialong and Xu, Shuai and Xu, Bo},
  journal = {IEEE Transactions on Neural Networks and Learning Systems},
  volume = {32},
  number = {2},
  pages = {710--722},
  year = {2021},
  doi = {10.1109/TNNLS.2020.2978554}
}


@article{Park2021,
  title = {Customer Behavior Modeling using Deep Learning},
  author = {Park, Sungjin and Kim, Jungwoo and Lee, Jaeho},
  journal = {Journal of Retailing and Consumer Services},
  volume = {63},
  pages = {102723},
  year = {2021},
  doi = {10.1016/j.jretconser.2021.102723}
}


@article{Zhang20221,
  title = {Tensor Parallelism for Large-Scale Model Training},
  author = {Zhang, Chengming and Yang, Yunxin and Chen, Wei},
  journal = {Proceedings of Machine Learning and Systems},
  volume = {4},
  pages = {267--281},
  year = {2022}
}


@ARTICLE{Pustokhin2021,
	author = {Pustokhin, Denis A. and Pustokhina, Irina V. and Rani, Poonam and Kansal, Vineet and Elhoseny, Mohamed and Joshi, Gyanendra Prasad and Shankar, K.},
	title = {Optimal deep learning approaches and healthcare big data analytics for mobile networks toward 5G},
	year = {2021},
	journal = {Computers and Electrical Engineering},
	volume = {95},
	doi = {10.1016/j.compeleceng.2021.107376},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85112824101&doi=10.1016%2fj.compeleceng.2021.107376&partnerID=40&md5=10252347ec36ea5f094e4e610b5305b2},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 26}
}


@ARTICLE{Babu20233621,
	author = {Babu, Ierin and Mathusoothana, R. and Kumar, S.},
	title = {Evolutionary Algorithm Based Feature Subset Selection for Students Academic Performance Analysis},
	year = {2023},
	journal = {Intelligent Automation and Soft Computing},
	volume = {36},
	number = {3},
	pages = {241--250},
	doi = {10.32604/iasc.2023.033791},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85150772054&doi=10.32604%2fiasc.2023.033791&partnerID=40&md5=517db7668ec7947497b5959ac1936631},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 5; All Open Access, Hybrid Gold Open Access}
}


@article{Eid20223845,
  title = {Meta-{{Heuristic Optimization}} of {{LSTM-Based Deep Network}} for {{Boosting}} the {{Prediction}} of {{Monkeypox Cases}}},
  author = {Eid, Marwa M. and {El-Kenawy}, El-Sayed M. and Khodadadi, Nima and Mirjalili, Seyedali and Khodadadi, Ehsaneh and Abotaleb, Mostafa and Alharbi, Amal H. and Abdelhamid, Abdelaziz A. and Ibrahim, Abdelhameed and Amer, Ghada M. and Kadi, Ammar and Khafaga, Doaa Sami},
  year = {2022},
  month = oct,
  journal = {Mathematics},
  volume = {10},
  number = {20},
  pages = {3845},
  issn = {2227-7390},
  doi = {10.3390/math10203845},
  abstract = {Recent technologies such as artificial intelligence, machine learning, and big data are essential for supporting healthcare monitoring systems, particularly for monitoring Monkeypox confirmed cases. Infected and uninfected cases around the world have contributed to a growing dataset, which is publicly available and can be used by artificial intelligence and machine learning to predict the confirmed cases of Monkeypox at an early stage. Motivated by this, we propose in this paper a new approach for accurate prediction of the Monkeypox confirmed cases based on an optimized Long Short-Term Memory (LSTM) deep network. To fine-tune the hyper-parameters of the LSTM-based deep network, we employed the Al-Biruni Earth Radius (BER) optimization algorithm; thus, the proposed approach is denoted by BER-LSTM. Experimental results show the effectiveness of the proposed approach when assessed using various evaluation criteria, such as Mean Bias Error, which is recorded as (0.06) using BER-LSTM. To prove the superiority of the proposed approach, six different machine learning models are included in the conducted experiments. In addition, four different optimization algorithms are considered for comparison purposes. The results of this comparison confirmed the superiority of the proposed approach. On the other hand, several statistical tests are applied to analyze the stability and significance of the proposed approach. These tests include one-way Analysis of Variance (ANOVA), Wilcoxon, and regression tests. The results of these tests emphasize the robustness, significance, and efficiency of the proposed approach.},
  copyright = {https://creativecommons.org/licenses/by/4.0/},
  langid = {english}
}


@ARTICLE{Zhou2022764,
	author = {Zhou, Yangfan and Huang, Kaizhu and Cheng, Cheng and Wang, Xuguang and Liu, Xin},
	title = {LightAdam: Towards a Fast and Accurate Adaptive Momentum Online Algorithm},
	year = {2022},
	journal = {Cognitive Computation},
	volume = {14},
	number = {2},
	pages = {241--250},
	doi = {10.1007/s12559-021-09985-9},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85122690180&doi=10.1007%2fs12559-021-09985-9&partnerID=40&md5=c844748d8c9ef7dbe7b6a03b7618327d},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 6}
}


@article{Gupta2022,
  title = {Botnet Identification in IoT Networks},
  author = {Gupta, Saurabh and Verma, Ajay and Singh, Devendra},
  journal = {IEEE Internet of Things Journal},
  volume = {9},
  number = {10},
  pages = {7865--7877},
  year = {2022},
  doi = {10.1109/JIOT.2021.3132845}
}


@article{Kratsch2021261,
  title = {Machine {{Learning}} in {{Business Process Monitoring}}: {{A Comparison}} of {{Deep Learning}} and {{Classical Approaches Used}} for {{Outcome Prediction}}},
  shorttitle = {Machine {{Learning}} in {{Business Process Monitoring}}},
  author = {Kratsch, Wolfgang and Manderscheid, Jonas and R{\"o}glinger, Maximilian and Seyfried, Johannes},
  year = {2021},
  month = jun,
  journal = {Business {\journal = {Business \& Information Systems Engineering}} Information Systems Engineering},
  volume = {63},
  number = {3},
  pages = {261--276},
  issn = {1867-0202},
  doi = {10.1007/s12599-020-00645-0},
  abstract = {Predictive process monitoring aims at forecasting the behavior, performance, and outcomes of business processes at runtime. It helps identify problems before they occur and re-allocate resources before they are wasted. Although deep learning (DL) has yielded breakthroughs, most existing approaches build on classical machine learning (ML) techniques, particularly when it comes to outcome-oriented predictive process monitoring. This circumstance reflects a lack of understanding about which event log properties facilitate the use of DL techniques. To address this gap, the authors compared the performance of DL (i.e., simple feedforward deep neural networks and long short term memory networks) and ML techniques (i.e., random forests and support vector machines) based on five publicly available event logs. It could be observed that DL generally outperforms classical ML techniques. Moreover, three specific propositions could be inferred from further observations: First, the outperformance of DL techniques is particularly strong for logs with a high variant-to-instance ratio (i.e., many non-standard cases). Second, DL techniques perform more stably in case of imbalanced target variables, especially for logs with a high event-to-activity ratio (i.e., many loops in the control flow). Third, logs with a high activity-to-instance payload ratio (i.e., input data is predominantly generated at runtime) call for the application of long short term memory networks. Due to the purposive sampling of event logs and techniques, these findings also hold for logs outside this study.},
  langid = {english},
  keywords = {Business process management,Deep learning,Machine learning,Outcome prediction,Predictive process monitoring}
}


@article{Jin2022,
  title = {Specialized Optimization for Edge NPU Implementations},
  author = {Jin, Sungho and Kim, Hyungjun and Park, Jongwoo},
  journal = {IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems},
  volume = {41},
  number = {9},
  pages = {2890--2903},
  year = {2022},
  doi = {10.1109/TCAD.2021.3109494}
}


@article{Mohyuddin2023100317,
  title = {A Comprehensive Framework for Hand Gesture Recognition Using Hybrid-Metaheuristic Algorithms and Deep Learning Models},
  author = {Mohyuddin, Hassan and Moosavi, Syed Kumayl Raza and Zafar, Muhammad Hamza and Sanfilippo, Filippo},
  year = {2023},
  month = sep,
  journal = {Array},
  volume = {19},
  pages = {100317},
  issn = {25900056},
  doi = {10.1016/j.array.2023.100317},
  langid = {english}
}


@article{Nguyen2021,
  title = {Deep Learning for Supply Chain Optimization},
  author = {Nguyen, Thi and Tran, Minh and Duong, Thanh},
  journal = {Computers {\&} Industrial Engineering},
  volume = {152},
  pages = {107023},
  year = {2021},
  doi = {10.1016/j.cie.2020.107023}
}


@article{Sagu202535,
  title = {Hybrid {{Optimization Algorithm}} for {{Detection}} of {{Security Attacks}} in {{IoT-Enabled Cyber-Physical Systems}}},
  author = {Sagu, Amit and Gill, Nasib Singh and Gulia, Preeti and Priyadarshini, Ishaani and Chatterjee, Jyotir Moy},
  year = {2025},
  month = feb,
  journal = {IEEE Transactions on Big Data},
  volume = {11},
  number = {1},
  pages = {35--46},
  issn = {2332-7790, 2372-2096},
  doi = {10.1109/TBDATA.2024.3372368},
  copyright = {https://ieeexplore.ieee.org/Xplorehelp/downloads/license-information/IEEE.html}
}


@article{Xu2023034501,
  title = {{{SuperMeshing}}: {{Boosting}} the {{Mesh Density}} of {{Stress Field}} in {{Plane-Strain Problems Using Deep Learning Method}}},
  shorttitle = {{{SuperMeshing}}},
  author = {Xu, Handing and Nie, Zhenguo and Xu, Qingfeng and Li, Yaguan and Xie, Fugui and Liu, Xin-Jun},
  year = {2023},
  month = jun,
  journal = {Journal of Computing and Information Science in Engineering},
  volume = {23},
  number = {3},
  pages = {034501},
  issn = {1530-9827, 1944-7078},
  doi = {10.1115/1.4054687},
  abstract = {Abstract             The increase of the spatial resolution in numerical computation always leads to a decrease in computing efficiency with respect to the constraint of mesh density. In response to this problem of the inability to perform numerical computation, we propose a novel method to boost the mesh-density in the finite element method (FEM) within 2D domains. Running on the von Mises stress fields of the 2D plane-strain problems computed by FEM, the proposed method utilizes a deep neural network named SMNet to learn a nonlinear mapping from low mesh-density to high mesh-density in stress fields and realizes the improvement of numerical computation accuracy and efficiency simultaneously. By introducing residual density blocks into SMNet, we can extract abundant local features and improve prediction capacity. The result indicates that SMNet can effectively increase the spatial resolution of stress fields under multiple scaling factors in mesh-density: 2 {\texttimes}, 3 {\texttimes}, and 4 {\texttimes}. Compared with the targets, the relative error of SMNet is 1.67\%, showing better performance than many other methods. SMNet can be generically used as an enhanced mesh-density boosting model of 2D physical fields for mesh-based numerical methods.},
  langid = {english}
}


@article{Moayedi20211331,
  title = {Double-{{Target Based Neural Networks}} in {{Predicting Energy Consumption}} in {{Residential Buildings}}},
  author = {Moayedi, Hossein and Mosavi, Amir},
  year = {2021},
  month = mar,
  journal = {Energies},
  volume = {14},
  number = {5},
  pages = {1331},
  issn = {1996-1073},
  doi = {10.3390/en14051331},
  abstract = {A reliable prediction of sustainable energy consumption is key for designing environmentally friendly buildings. In this study, three novel hybrid intelligent methods, namely the grasshopper optimization algorithm (GOA), wind-driven optimization (WDO), and biogeography-based optimization (BBO), are employed to optimize the multitarget prediction of heating loads (HLs) and cooling loads (CLs) in the heating, ventilation and air conditioning (HVAC) systems. Concerning the optimization of the applied algorithms, a series of swarm-based iterations are performed, and the best structure is proposed for each model. The GOA, WDO, and BBO algorithms are mixed with a class of feedforward artificial neural networks (ANNs), which is called a multi-layer perceptron (MLP) to predict the HL and CL. According to the sensitivity analysis, the WDO with swarm size = 500 proposes the most-fitted ANN. The proposed WDO-ANN provided an accurate prediction in terms of heating load (training (R2 correlation = 0.977 and RMSE error = 0.183) and testing (R2 correlation = 0.973 and RMSE error = 0.190)) and yielded the best-fitted prediction in terms of cooling load (training (R2 correlation = 0.99 and RMSE error = 0.147) and testing (R2 correlation = 0.99 and RMSE error = 0.148)).},
  copyright = {https://creativecommons.org/licenses/by/4.0/},
  langid = {english}
}


@article{AhmedHamza20226563,
  title = {Intelligent {{Slime Mould Optimization}} with {{Deep Learning Enabled Traffic Prediction}} in {{Smart Cities}}},
  author = {Ahmed Hamza, Manar and Alsolai, Hadeel and S. Alzahrani, Jaber and Alamgeer, Mohammad and Mahmoud Sayed, Mohamed and Sarwar Zamani, Abu and Yaseen, Ishfaq and Motwakel, Abdelwahed},
  year = {2022},
  journal = {Computers, Materials {\journal = {Computers, Materials \& Continua}} Continua},
  volume = {73},
  number = {3},
  pages = {6563--6577},
  issn = {1546-2226},
  doi = {10.32604/cmc.2022.031541},
  langid = {english}
}


@article{Huang2020,
  title = {Deep Learning for Pandemic Forecasting},
  author = {Huang, Li and Chen, Jianhua and Yang, Xin},
  journal = {Nature Communications},
  volume = {11},
  pages = {5887},
  year = {2020},
  doi = {10.1038/s41467-020-19673-1}
}


@article{Nguyen2023,
  title = {Extreme Model Compression for Edge Deployment},
  author = {Nguyen, Thanh and Le, Minh and Pham, Huy},
  journal = {IEEE Internet of Things Journal},
  volume = {10},
  number = {6},
  pages = {5478--5490},
  year = {2023},
  doi = {10.1109/JIOT.2022.3201111}
}


@ARTICLE{Pandey2023,
	author = {Pandey, Bishwajeet Kumar and M．R．M．, Veeramanickam and Ahmad, Shabeer and Rodriguez, Ciro and Esenarro, Doris},
	title = {ExpSSOA-Deep maxout: Exponential Shuffled shepherd optimization based Deep maxout network for intrusion detection using big data in cloud computing framework},
	year = {2023},
	journal = {Computers and Security},
	volume = {124},
	doi = {10.1016/j.cose.2022.102975},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85142248862&doi=10.1016%2fj.cose.2022.102975&partnerID=40&md5=b57510e55fffcc36d221738f93ae5edb},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 21}
}


@ARTICLE{Li2023Battery,
  author = {Li, Chaoran and Han, Xianjie and Zhang, Qiang and Li, Menghan and Rao, Zhonghao and Liao, Wei and Liu, Xiaori and Liu, Xinjian and Li, Gang},
  title = {State-of-health and remaining-useful-life estimations of lithium-ion battery based on temporal convolutional network-long short-term memory},
  year = {2023},
  journal = {Journal of Energy Storage},
  volume = {65},
  doi = {10.1016/j.est.2023.107184},
  url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85147335171&doi=10.1002%2fcpe.7618&partnerID=40&md5=8f3bea839e3eda361651f8453fe2d90c},
  type = {Article},
  publication_stage = {Final},
  source = {Scopus},
  note = {Cited by: 2}
}


@article{Palermo202240,
  title = {Tracking Machine Learning Models for Pandemic Scenarios: A Systematic Review of Machine Learning Models That Predict Local and Global Evolution of Pandemics},
  shorttitle = {Tracking Machine Learning Models for Pandemic Scenarios},
  author = {Palermo, Marcelo Benedeti and Policarpo, Lucas Micol and Costa, Cristiano Andr{\e} Da and Righi, Rodrigo Da Rosa},
  year = {2022},
  month = dec,
  journal = {Network Modeling Analysis in Health Informatics and Bioinformatics},
  volume = {11},
  number = {1},
  pages = {40},
  issn = {2192-6662, 2192-6670},
  doi = {10.1007/s13721-022-00384-0},
  langid = {english}
}


@article{Li2020,
  title = {Deep Learning for IoT Applications},
  author = {Li, Zhihua and Wang, Ruosi and Yu, Dongmin},
  journal = {IEEE Access},
  volume = {8},
  pages = {163535--163556},
  year = {2020},
  doi = {10.1109/ACCESS.2020.3021736}
}


@article{Abayomi2021,
  title = {Optimized CNN Architectures for Network Traffic Analysis},
  author = {Abayomi, John and Williams, Robert and Thomas, Andrew},
  journal = {IEEE Transactions on Network and Service Management},
  volume = {18},
  number = {2},
  pages = {1880--1893},
  year = {2021},
  doi = {10.1109/TNSM.2021.3053410}
}


@article{Tekouabou20241079,
  title = {{{AI-Based}} on {{Machine Learning Methods}} for {{Urban Real Estate Prediction}}: {{A Systematic Survey}}},
  shorttitle = {{{AI-Based}} on {{Machine Learning Methods}} for {{Urban Real Estate Prediction}}},
  author = {Tekouabou, St{\e}phane C. K. and Gherghina, {\c S}tefan Cristian and Kameni, Eric D{\e}sir{\e} and Filali, Youssef and Idrissi Gartoumi, Khalil},
  year = {2024},
  month = mar,
  journal = {Archives of Computational Methods in Engineering},
  volume = {31},
  number = {2},
  pages = {1079--1095},
  issn = {1134-3060, 1886-1784},
  doi = {10.1007/s11831-023-10010-5},
  langid = {english}
}


@article{Xu2022,
  title = {Distributed Optimization Approach for Scientific Machine Learning},
  author = {Xu, Tianfeng and Liang, Jian and Zhang, Xuesong},
  journal = {Journal of Computational Science},
  volume = {62},
  pages = {101735},
  year = {2022},
  doi = {10.1016/j.jocs.2022.101735}
}


@article{Oberdorf202349,
  title = {Predictive {{End-to-End Enterprise Process Network Monitoring}}},
  author = {Oberdorf, Felix and Schaschek, Myriam and Weinzierl, Sven and Stein, Nikolai and Matzner, Martin and Flath, Christoph M.},
  year = {2023},
  month = feb,
  journal = {Business {\journal = {Business \& Information Systems Engineering}} Information Systems Engineering},
  volume = {65},
  number = {1},
  pages = {49--64},
  issn = {2363-7005, 1867-0202},
  doi = {10.1007/s12599-022-00778-4},
  abstract = {Abstract             Ever-growing data availability combined with rapid progress in analytics has laid the foundation for the emergence of business process analytics. Organizations strive to leverage predictive process analytics to obtain insights. However, current implementations are designed to deal with homogeneous data. Consequently, there is limited practical use in an organization with heterogeneous data sources. The paper proposes a method for predictive end-to-end enterprise process network monitoring leveraging multi-headed deep neural networks to overcome this limitation. A case study performed with a medium-sized German manufacturing company highlights the methods utility for organizations.},
  langid = {english}
}


@article{Wu2021,
  title = {Parameter Sharing Technique for Transformer Models},
  author = {Wu, Jianqiao and Li, Menghan and Zhang, Tong},
  journal = {Transactions of the Association for Computational Linguistics},
  volume = {9},
  pages = {629--645},
  year = {2021},
  doi = {10.1162/tacl_a_00387}
}


@article{Li2022,
  title = {Transfer Learning with Hyperparameter Optimization for Deep Neural Networks},
  author = {Li, Jinbao and Wang, Xiang and Chen, Han},
  journal = {Knowledge-Based Systems},
  volume = {235},
  pages = {107658},
  year = {2022},
  doi = {10.1016/j.knosys.2021.107658}
}


@article{Rahman2023,
  title = {DDoS Attack Mitigation Through Optimized Deep Learning},
  author = {Rahman, Abdur and Khan, Zafar and Javaid, Nadeem},
  journal = {IEEE Network},
  volume = {37},
  number = {1},
  pages = {46--52},
  year = {2023},
  doi = {10.1109/MNET.2022.3191666}
} 
@ARTICLE{Banchhor2022,
	author = {Banchhor, Chitrakant and Srinivasu, N.},
	title = {Grey Wolf Shuffled Shepherd Optimization Algorithm-Based Hybrid Deep Learning Classifier for Big Data Classification},
	year = {2022},
	journal = {International Journal of Swarm Intelligence Research},
	volume = {13},
	number = {1},
	doi = {10.4018/IJSIR.302612},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85153934848&doi=10.4018%2fIJSIR.302612&partnerID=40&md5=267d8fd52cdefc41da6d3baa0499cdf2},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@article{ataei2024filtering,
  title={Filtering Useful App Reviews Using Na{\"\i}ve Bayes—Which Na{\"\i}ve Bayes?},
  author={Ataei, Pouya and Regula, Sri and Staegemann, Daniel and Malgaonkar, Saurabh},
  journal={AI},
  volume={5},
  number={4},
  pages={2237--2259},
  year={2024},
  publisher={MDPI}
}


@article{Kim2022,
  title = {Hardware-Aware Optimization Techniques for Inference Latency Reduction},
  author = {Kim, Hyunjoon and Park, Joonho and Lee, Sunghyun},
  journal = {IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems},
  volume = {41},
  number = {8},
  pages = {2567--2580},
  year = {2022},
  doi = {10.1109/TCAD.2021.3089276}
}


@article{Prasanth2019282,
  title = {Effective {{Big Data Retrieval Using Deep Learning Modified Neural Networks}}},
  author = {Prasanth, T. and Gunasekaran, M.},
  year = {2019},
  month = feb,
  journal = {Mobile Networks and Applications},
  volume = {24},
  number = {1},
  pages = {282--294},
  issn = {1383-469X, 1572-8153},
  doi = {10.1007/s11036-018-1204-y},
  langid = {english}
}


@article{Shan2020224884,
  title = {Reliability {{Analysis}} of {{Power Distribution Network Based}} on {{PSO-DBN}}},
  author = {Shan, Hongtao and Sun, Yuanyuan and Zhang, Wenjun and Kudreyko, Aleksey and Ren, Lijia},
  year = {2020},
  journal = {IEEE Access},
  volume = {8},
  pages = {224884--224894},
  issn = {2169-3536},
  doi = {10.1109/ACCESS.2020.3007776},
  copyright = {https://creativecommons.org/licenses/by/4.0/legalcode}
}


@article{Almutairi20225924,
  title = {A {{TLBO-Tuned Neural Processor}} for {{Predicting Heating Load}} in {{Residential Buildings}}},
  author = {Almutairi, Khalid and Algarni, Salem and Alqahtani, Talal and Moayedi, Hossein and Mosavi, Amir},
  year = {2022},
  month = may,
  journal = {Sustainability},
  volume = {14},
  number = {10},
  pages = {5924},
  issn = {2071-1050},
  doi = {10.3390/su14105924},
  abstract = {Recent studies have witnessed remarkable merits of metaheuristic algorithms in optimization problems. Due to the significance of the early analysis of the thermal load in energy-efficient buildings, this work introduces and compares four novel optimizer techniques---the firefly algorithm (FA), optics-inspired optimization (OIO), shuffled complex evolution (SCE), and teaching--learning-based optimization (TLBO)---for an accurate prediction of the heating load (HL). The models are applied to a multilayer perceptron (MLP) neural network to surmount its computational shortcomings. The models are fed by a literature-based dataset obtained for residential buildings. The results revealed that all models used are capable of properly analyzing and predicting the HL pattern. A comparison between them, however, showed that the TLBO-MLP with the coefficients of determination 0.9610 vs. 0.9438, 0.9373, and 0.9556 (respectively, for FA-MLP, OIO-MLP, and SCE-MLP) and the root mean square error of 2.1103 vs. 2.5456, 2.7099, and 2.2774 presents the most reliable approximation of the HL. It also surpassed several methods used in previous studies. Thus, the developed TLBO-MLP can be a beneficial model for subsequent practical applications.},
  copyright = {https://creativecommons.org/licenses/by/4.0/},
  langid = {english}
}


@ARTICLE{Thapaliya202316,
	author = {Thapaliya, Suman and Sharma, Pawan Kumar},
	title = {Cyber Forensic Investigation in IoT Using Deep Learning Based Feature Fusion in Big Data},
	year = {2023},
	journal = {International Journal of Wireless Information Networks},
	volume = {30},
	number = {1},
	pages = {241--250},
	doi = {10.1007/s10776-022-00586-3},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85143391443&doi=10.1007%2fs10776-022-00586-3&partnerID=40&md5=183a61751cdbbfe9dc4479d48e7a4dc0},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2}
}


@article{Wu2023,
  title = {Adaptive Optimization Strategy for Non-Stationary Data},
  author = {Wu, Xiangrong and Zhang, Li and Chen, Yiwen},
  journal = {Neural Networks},
  volume = {158},
  pages = {142--155},
  year = {2023},
  doi = {10.1016/j.neunet.2022.11.019}
}


@article{Ampel2024137,
  title = {Creating {{Proactive Cyber Threat Intelligence}} with {{Hacker Exploit Labels}}: {{A Deep Transfer Learning Approach}}},
  shorttitle = {Creating {{Proactive Cyber Threat Intelligence}} with {{Hacker Exploit Labels}}},
  author = {Ampel, Benjamin and Samtani, Sagar and Zhu, Hongyi and Chen, Hsinchun},
  year = {2024},
  month = mar,
  journal = {MIS Quarterly},
  volume = {48},
  number = {1},
  pages = {137--166},
  issn = {02767783, 21629730},
  doi = {10.25300/MISQ/2023/17316},
  abstract = {The rapid proliferation of complex information systems has been met by an ever-increasing quantity of exploits that can cause irreparable cyber breaches. To mitigate these cyber threats, academia and industry have placed a significant focus on proactively identifying and labeling exploits developed by the international hacker community. However, prevailing approaches for labeling exploits in hacker forums do not leverage metadata from exploit darknet markets or public exploit repositories to enhance labeling performance. In this study, we adopted the computational design science paradigm to develop a novel information technology artifact, the deep transfer learning exploit labeler (DTL-EL). DTL-EL incorporates a pre-initialization design, multi-layer deep transfer learning (DTL), and a self-attention mechanism to automatically label exploits in hacker forums. We rigorously evaluated the proposed DTL-EL against state-of-the-art non-DTL benchmark methods based in classical machine learning and deep learning. Results suggest that the proposed DTL-EL significantly outperforms benchmark methods based on accuracy, precision, recall, and F1-score. Our proposed DTL-EL framework provides important practical implications for key stakeholders such as cybersecurity managers, analysts, and educators.}
}


@article{Zhang2022,
  title = {Improved Communication Protocol for Distributed Deep Learning},
  author = {Zhang, Hao and Li, Zeyu and Wang, Jianyu},
  journal = {IEEE Transactions on Parallel and Distributed Systems},
  volume = {33},
  number = {8},
  pages = {1878--1890},
  year = {2022},
  doi = {10.1109/TPDS.2021.3135689}
}


@article{Khan2020,
  title = {Bayesian Optimization for Hyperparameter Tuning in Resource-Constrained Environments},
  author = {Khan, Rafiullah and Schmidt, Bernhard and Kurtz, William},
  journal = {IEEE Transactions on Neural Networks and Learning Systems},
  volume = {31},
  number = {11},
  pages = {5051--5065},
  year = {2020},
  doi = {10.1109/TNNLS.2020.2978577}
}


@ARTICLE{SulthanAlikhan2023,
	author = {Sulthan Alikhan, J. and Alageswaran, R. and Miruna Joe Amali, S.},
	title = {Self-attention convolutional neural network optimized with season optimization algorithm Espoused Chronic Kidney Diseases Diagnosis in Big Data System},
	year = {2023},
	journal = {Biomedical Signal Processing and Control},
	volume = {85},
	doi = {10.1016/j.bspc.2023.105011},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85160015120&doi=10.1016%2fj.bspc.2023.105011&partnerID=40&md5=31dfae96f4a9b24536e66f732392b98d},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 14}
}


@article{Vijayalakshmi2022,
  title = {Deep Learning for Patient Monitoring Systems},
  author = {Vijayalakshmi, K. and Rajesh, S. and Kumar, P.},
  journal = {Journal of Medical Systems},
  volume = {46},
  number = {3},
  pages = {18--31},
  year = {2022},
  doi = {10.1007/s10916-022-01782-7}
}


@inproceedings{Wang2018175,
  title = {Bone Age Assessment Using Convolutional Neural Networks},
  booktitle = {2018 {{International Conference}} on {{Artificial Intelligence}} and {{Big Data}} ({{ICAIBD}})},
  author = {Wang, Shuqiang and Shen, Yanyan and Zeng, Dewei and Hu, Yong},
  year = {2018},
  month = may,
  pages = {175--178},
  publisher = {IEEE},
  address = {Chengdu},
  doi = {10.1109/ICAIBD.2018.8396189},
  isbn = {978-1-5386-6987-7}
}


@article{Zhu2022,
  title = {Quality Control Systems with Deep Learning},
  author = {Zhu, Xiaoning and Chen, Bo and Yang, Fan},
  journal = {Journal of Manufacturing Systems},
  volume = {62},
  pages = {351--364},
  year = {2022},
  doi = {10.1016/j.jmsy.2021.09.016}
}


@article{Ananth2022918,
  title = {Extended and Optimized Deep Convolutional Neural Network-Based Lung Tumor Identification in Big Data},
  author = {Ananth, Antony Dennis and Palanisamy, Chenniappan},
  year = {2022},
  journal = {International Journal of Imaging Systems and Technology},
  volume = {32},
  number = {3},
  pages = {918--934},
  issn = {1098-1098},
  doi = {10.1002/ima.22667},
  abstract = {Lung tumor is a complex disease caused due to the irregular growth of lung cells. A key factor in effective treatment planning is the early detection of lung tumor. Visual similarity between benign and malignant nodules, heterogeneity and low contrast variation are the factors that make accurate cancerous lesion recognition, a very challenging task. In this paper, Optimized Deep convolutional neural network (DCNN) and Fuzzy C-means with Equilibrium optimizer (FCM-EO) is proposed for classification and segmentation of CT lung images. The proposed architecture is comprised of four phases such as preprocessing, feature extraction, classification and segmentation. In preprocessing, the weighted mean histogram analysis (WMHA) is utilized to enhance the quality of images and noise removal. Hybrid Dual tree-complex wavelet transform (DT-CWT) with Gabor filter is proposed in feature extraction to extract the features from the preprocessed images. DCNN model is designed to classify the original images into benign and malignant images. The weight of DCNN model is updated using the Enhanced black widow optimization algorithm (EBWOA). In segmentation, FCM-EO is introduced to identify the tumor regions and remove the outliers from the malignant images. LIDC-IDRI dataset is utilized for the experimental analysis and MATLAB is the implementation tool. The simulation analysis is performed for both the classification and segmentation processes. Accuracy, specificity, sensitivity, precision, F-measure, FROC, DSC, MCC, and IoU are evaluated for both these processes. The experimental results showed the proposed framework is efficient for the identification of tumor from the CT lung images.},
  copyright = {{\copyright} 2021 Wiley Periodicals LLC.},
  langid = {english},
  keywords = {big data,classification,CT images,deep learning,feature extraction,lung tumor detection,segmentation}
}


@article{Khan2022,
  title = {Ensemble Deep Learning for Risk Assessment},
  author = {Khan, Asif and Ahmed, Sajid and Kumar, Rajesh},
  journal = {International Journal of Information Management},
  volume = {67},
  pages = {102515},
  year = {2022},
  doi = {10.1016/j.ijinfomgt.2022.102515}
}




@article{Joardar2019852,
  title = {Learning-{{Based Application-Agnostic 3D NoC Design}} for {{Heterogeneous Manycore Systems}}},
  author = {Joardar, Biresh Kumar and Kim, Ryan Gary and Doppa, Janardhan Rao and Pande, Partha Pratim and Marculescu, Diana and Marculescu, Radu},
  year = {2019},
  month = jun,
  journal = {IEEE Transactions on Computers},
  volume = {68},
  number = {6},
  pages = {852--866},
  issn = {0018-9340, 1557-9956, 2326-3814},
  doi = {10.1109/TC.2018.2889053},
  copyright = {https://ieeexplore.ieee.org/Xplorehelp/downloads/license-information/IEEE.html}
}


@ARTICLE{Lin2022Baidu,
  author = {Lin, Yong and Wang, Renyu and Gong, Xingyue and Jia, Guozhu},
  title = {Cross-correlation and forecast impact of public attention on USD/CNY exchange rate: Evidence from Baidu Index},
  year = {2022},
  journal = {International Review of Economics and Finance},
  volume = {79},
  doi = {10.1016/j.iref.2022.01.015},
  url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85124283187&doi=10.1016%2fj.iref.2022.01.015&partnerID=40&md5=9729de6f5ae1e7b6aa4c9a64c3e64f84},
  type = {Article},
  publication_stage = {Final},
  source = {Scopus},
  note = {Cited by: 15}
}


@ARTICLE{Pan2020201,
	author = {Pan, Hengyue and Niu, Xin and Li, RongChun and Dou, Yong and Jiang, Hui},
	title = {Annealed gradient descent for deep learning},
	year = {2020},
	journal = {Neurocomputing},
	volume = {380},
	pages = {241--250},
	doi = {10.1016/j.neucom.2019.11.021},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85075852958&doi=10.1016%2fj.neucom.2019.11.021&partnerID=40&md5=21d9c81a8c6c51a2faaea8164f87bd20},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 27}
}


@article{Zhou2023195,
  title = {Unintended {{Emotional Effects}} of {{Online Health Communities}}: {{A Text Mining-Supported Empirical Study}}},
  shorttitle = {Unintended {{Emotional Effects}} of {{Online Health Communities}}},
  author = {Zhou, Jiaqi and Zhang, Qingpeng and Zhou, Sijia and Li, Xin and Zhang, Xiaoquan (Michael)},
  year = {2023},
  month = mar,
  journal = {MIS Quarterly},
  volume = {47},
  number = {1},
  pages = {195--226},
  issn = {02767783, 21629730},
  doi = {10.25300/MISQ/2022/17018},
  abstract = {Online health communities (OHCs) play an important role in enabling patients to exchange information and obtain social support from each other. However, do OHC interactions always benefit patients? In this research, we investigate different mechanisms by which OHC content may affect patients emotions. Specifically, we notice users can read not only emotional support intended to help them but also emotional support targeting other persons or posts that are not intended to generate any emotional support (auxiliary content). Drawing from emotional contagion theories, we argue that even though emotional support may benefit targeted support seekers, it could have a negative impact on the emotions of other support seekers. Our empirical study on an OHC for depression patients supports these arguments. Our findings are new to the literature and have critical practical implications since they suggest that we should carefully manage OHC-based interventions for depression patients to avoid unintended consequences. We design a novel deep learning model to differentiate emotional support from auxiliary content. Such differentiation is critical for identifying the negative effect of emotional support on unintended recipients. We also discuss options to alter the intervention volume, length, and frequency to tackle the challenge of the negative effect.}
}


@article{Samadianfard20191934,
  title = {Support {{Vector Regression Integrated}} with {{Fruit Fly Optimization Algorithm}} for {{River Flow Forecasting}} in {{Lake Urmia Basin}}},
  author = {Samadianfard, Saeed and Jarhan, Salar and Salwana, Ely and Mosavi, Amir and Shamshirband, Shahaboddin and Akib, Shatirah},
  year = {2019},
  month = sep,
  journal = {Water},
  volume = {11},
  number = {9},
  pages = {1934},
  issn = {2073-4441},
  doi = {10.3390/w11091934},
  abstract = {Advancement in river flow prediction systems can greatly empower the operational river management to make better decisions, practices, and policies. Machine learning methods recently have shown promising results in building accurate models for river flow prediction. This paper aims to identify models with higher accuracy, robustness, and generalization ability by inspecting the accuracy of a number of machine learning models. The proposed models for river flow include support vector regression (SVR), a hybrid of SVR with a fruit fly optimization algorithm (FOA) (so-called FOASVR), and an M5 model tree (M5). Additionally, the influence of periodicity ({$\pi$}) on the forecasting enactment was examined. To assess the performance of the proposed models, different statistical meters were implemented, including root mean squared error (RMSE), mean absolute error (MAE), correlation coefficient (R), and Bayesian information criterion (BIC). Results showed that the FOASVR with RMSE (4.36 and 6.33 m3/s), MAE (2.40 and 3.71 m3/s) and R (0.82 and 0.81) values had the best performance in forecasting river flows at Babarud and Vaniar stations, respectively. Also, regarding BIC parameters, Qt-1 and {$\pi$} were selected as parsimonious inputs for predicting river flow one month ahead. Overall findings indicated that, although both the FOASVR and M5 predicted the river flows in suitable accordance with observed river flows, the performance of the FOASVR was moderately better than the M5 and periodicity noticeably increased the performance of the models; consequently, FOASVR can be suggested as the most accurate method for forecasting river flows.},
  copyright = {https://creativecommons.org/licenses/by/4.0/},
  langid = {english}
}


@inproceedings{Zhang20231,
  title = {Learning to {{Optimize Vehicle Routes Problem}}: {{A Two-Stage Hybrid Reinforcement Learning}}},
  shorttitle = {Learning to {{Optimize Vehicle Routes Problem}}},
  booktitle = {2023 {{International Conference}} on {{Sensing}}, {{Measurement}} \&amp; {{Data Analytics}} in the Era of {{Artificial Intelligence}} ({{ICSMD}})},
  author = {Zhang, Wenqiang and Wang, Xiaomeng},
  year = {2023},
  month = nov,
  pages = {1--6},
  publisher = {IEEE},
  address = {Xian, China},
  doi = {10.1109/ICSMD60522.2023.10490595},
  copyright = {https://doi.org/10.15223/policy-029},
  isbn = {979-8-3503-1801-2}
}


@article{Cheng2023,
  title = {Deep Learning for Pollution Monitoring Networks},
  author = {Cheng, Xiaofeng and Liu, Wei and Zhang, Chen},
  journal = {Environmental Monitoring and Assessment},
  volume = {195},
  number = {3},
  pages = {329},
  year = {2023},
  doi = {10.1007/s10661-023-10909-5}
}


@article{Wissuchek2024,
  title = {Prescriptive Analytics Systems Revised: A Systematic Literature Review from an Information Systems Perspective},
  shorttitle = {Prescriptive Analytics Systems Revised},
  author = {Wissuchek, Christopher and Zschech, Patrick},
  year = {2024},
  month = aug,
  journal = {Information Systems and e-Business Management},
  issn = {1617-9846, 1617-9854},
  doi = {10.1007/s10257-024-00688-w},
  abstract = {Abstract             Prescriptive Analytics Systems (PAS) represent the most mature iteration of business analytics, significantly enhancing organizational decision-making. Recently, research has gained traction, with various technological innovations, including machine learning and artificial intelligence, significantly influencing the design of PAS. Although recent studies highlight these developments, the rising trend focuses on broader implications, such as the synergies and delegation between systems and users in organizational decision-making environments. Against this backdrop, we utilized a systematic literature review of 262 articles to build on this evolving perspective. Guided by general systems theory and socio-technical thinking, the concept of an information systems artifact directed this review. Our first objective was to clarify the essential subsystems, identifying 23 constituent components of PAS. Subsequently, we delved into the meta-level design of PAS, emphasizing the synergy and delegation between the human decision-maker and prescriptive analytics in supporting organizational decisions. From this exploration, four distinct system archetypes emerged: advisory, executive, adaptive, and self-governing PAS. Lastly, we engaged with affordance theory, illuminating the action potential of PAS. Our study advances the perspective on PAS, specifically from a broader socio-technical and information systems viewpoint, highlighting six distinct research directions, acting as a launchpad for future research in the domain.},
  langid = {english}
}


@article{Wang2022,
  title = {Knowledge Distillation Technique for Cybersecurity Applications},
  author = {Wang, Yifan and Chen, Jie and Zhang, Qi},
  journal = {IEEE Transactions on Information Forensics and Security},
  volume = {17},
  pages = {2158--2171},
  year = {2022},
  doi = {10.1109/TIFS.2022.3176577}
}

@ARTICLE{Manivannan202350,
	author = {Manivannan, K. and Suresh, T. and Parthiban, M.},
	title = {Big Data Analytics Assisted Arithmetic Optimization with Deep Learning Model for Sentiment Classification},
	year = {2023},
	journal = {International Journal of Engineering Trends and Technology},
	volume = {71},
	number = {12},
	pages = {241--250},
	doi = {10.14445/22315381/IJETT-V71I12P206},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85180339333&doi=10.14445%2f22315381%2fIJETT-V71I12P206&partnerID=40&md5=892176e1bddeecd8340970a0a8687114},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}


@article{Li2020101765,
  title = {Multi-Site {{fMRI}} Analysis Using Privacy-Preserving Federated Learning and Domain Adaptation: {{ABIDE}} Results},
  shorttitle = {Multi-Site {{fMRI}} Analysis Using Privacy-Preserving Federated Learning and Domain Adaptation},
  author = {Li, Xiaoxiao and Gu, Yufeng and Dvornek, Nicha and Staib, Lawrence H. and Ventola, Pamela and Duncan, James S.},
  year = {2020},
  month = oct,
  journal = {Medical Image Analysis},
  volume = {65},
  pages = {101765},
  issn = {13618415},
  doi = {10.1016/j.media.2020.101765},
  langid = {english}
}


@article{Zheng2019147755,
  title = {Improved {{Multi-Agent Deep Deterministic Policy Gradient}} for {{Path Planning-Based Crowd Simulation}}},
  author = {Zheng, Shangfei and Liu, Hong},
  year = {2019},
  journal = {IEEE Access},
  volume = {7},
  pages = {147755--147770},
  issn = {2169-3536},
  doi = {10.1109/ACCESS.2019.2946659},
  copyright = {https://creativecommons.org/licenses/by/4.0/legalcode}
}


@article{Hassan2022,
  title = {Optimized Deep Learning for Remote Sensing Data Analysis},
  author = {Hassan, Mohammed and Ali, Ahmed and Kamal, Mostafa},
  journal = {Remote Sensing},
  volume = {14},
  number = {5},
  pages = {1132},
  year = {2022},
  doi = {10.3390/rs14051132}
}


@ARTICLE{Nagaraju2022,
	author = {Nagaraju, Regonda and Pentang, Jupeth Toriano and Abdufattokhov, Shokhjakhon and CosioBorda, Ricardo Fernando and Mageswari, N. and Uganya, G.},
	title = {Attack prevention in IoT through hybrid optimization mechanism and deep learning framework},
	year = {2022},
	journal = {Measurement: Sensors},
	volume = {24},
	doi = {10.1016/j.measen.2022.100431},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85137276875&doi=10.1016%2fj.measen.2022.100431&partnerID=40&md5=236310a5fbe7f2fee311b3dccea0846e},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 14; All Open Access, Gold Open Access, Green Open Access}
}


@article{Kumar2023,
  title = {Optimized Deep Learning for Genomic Data Analysis},
  author = {Kumar, Sanjay and Singh, Rahul and Gupta, Alok},
  journal = {Computational Biology and Chemistry},
  volume = {104},
  pages = {107711},
  year = {2023},
  doi = {10.1016/j.compbiolchem.2023.107711}
}


@article{Shin20201459,
  title = {Enhancing {{Social Media Analysis}} with {{Visual Data Analytics}}: {{A Deep Learning Approach}}},
  shorttitle = {Enhancing {{Social Media Analysis}} with {{Visual Data Analytics}}},
  author = {Shin, Donghyuk and He, Shu and Lee, Gene Moo and Whinston, Andrew B. and Cetintas, Suleyman and Lee, Kuang-Chih},
  year = {2020},
  month = dec,
  journal = {MIS Quarterly},
  volume = {44},
  number = {4},
  pages = {1459--1492},
  issn = {02767783, 21629730},
  doi = {10.25300/MISQ/2020/14870}
}


@article{Dash2023,
  title = {Sentiment Analysis for Market Prediction},
  author = {Dash, Satyabrata and Acharya, Binita and Mittal, Amit},
  journal = {International Journal of Finance {\&} Economics},
  volume = {28},
  number = {3},
  pages = {2837--2851},
  year = {2023},
  doi = {10.1002/ijfe.2463}
}


@article{Sankaran20223005,
  title = {An Automated Prediction of Remote Sensing Data of {{Queensland-Australia}} for Flood and Wildfire Susceptibility Using {{BISSOA-DBMLA}} Scheme},
  author = {Sankaran, Krishnan Sakthidasan and Lim, Se-Jung and Bhaskar, Seelam Ch Vijaya},
  year = {2022},
  month = oct,
  journal = {Acta Geophysica},
  volume = {70},
  number = {6},
  pages = {3005--3021},
  issn = {1895-7455},
  doi = {10.1007/s11600-022-00925-1},
  langid = {english}
}


@article{Ghosh2022,
  title = {Transfer Learning for Domain Adaptation in Finance},
  author = {Ghosh, Saptarshi and Das, Arindam and Sen, Souvik},
  journal = {Expert Systems with Applications},
  volume = {202},
  pages = {117200},
  year = {2022},
  doi = {10.1016/j.eswa.2022.117200}
}


@article{hassib2020woa,
  title = {WOA+ BRNN: An imbalanced big data classification framework using Whale optimization and deep neural network},
  author = {Hassib, Eslam M and El-Desouky, Ali I and Labib, Labib M and El-Kenawy, El-Sayed M},
  journal = {Soft Computing},
  volume = {24},
  number = {8},
  pages = {5573--5592},
  year = {2020},
  publisher = {Springer}
}


@inproceedings{Liu20211735Conf,
  title = {{{DeepLoc}}: {{A Deep Neural Network-based Indoor Positioning Framework}}},
  shorttitle = {{{DeepLoc}}},
  booktitle = {2021 {{IEEE}} 23rd {{Int Conf}} on {{High Performance Computing}} {\&} {{Communications}}; 7th {{Int Conf}} on {{Data Science}} {\&} {{Systems}}; 19th {{Int Conf}} on {{Smart City}}; 7th {{Int Conf}} on {{Dependability}} in {{Sensor}}, {{Cloud}} {\&} {{Big Data Systems}} {\&} {{Application}} ({{HPCC}}/{{DSS}}/{{SmartCity}}/{{DependSys}})},
  author = {Liu, Saining and Ren, Qianqian and Li, Jinbao and Xu, Hui},
  year = {2021},
  month = dec,
  pages = {1735--1740},
  doi = {10.1109/HPCC-DSS-SmartCity-DependSys53884.2021.00255},
  abstract = {The growing attention on location-based services has promoted the development of indoor localization studies. Existing techniques mainly use Received Signal Strength Indicator (RSSI) of wireless signals as location fingerprint. Inspired by deep learning techniques for signal processing, we propose a deep neural network-based framework (DeepLoc) to implement Wi-Fi fingerprint positioning. In order to improve localization performance, we further design a network division based optimization algorithm. We first adopt greedy algorithm to locate the user in a sub-area, and then reconstruct a smaller fingerprint database, which is fed into the training model. Finally, we evaluate the proposed framework. Experimental results show that DeepLoc can improve the localization accuracy efficiently and obtain better performance.},
  keywords = {deep learning,Deep learning,Fingerprint recognition,greedy algorithm,Greedy algorithms,Location awareness,positioning,Received signal strength indicator,Signal processing algorithms,sub-area,Training}
}


@article{Yu20221355,
  title = {Wearable {{Sensor-Based Chronic Condition Severity Assessment}}: {{An Adversarial Attention-Based Deep Multisource Multitask Learning Approach}}},
  shorttitle = {Wearable {{Sensor-Based Chronic Condition Severity Assessment}}},
  author = {Yu, Shuo and Chai, Yidong and Chen, Hsinchun and Sherman, Scott and Brown, Randall},
  year = {2022},
  month = sep,
  journal = {MIS Quarterly},
  volume = {45},
  number = {3},
  pages = {1355--1394},
  issn = {02767783},
  doi = {10.25300/MISQ/2022/15763},
  abstract = {Advancing the quality of healthcare for senior citizens with chronic conditions is of great social relevance. To better manage chronic conditions, objective, convenient, and inexpensive wearable sensor- based information systems (IS) have been increasingly used by researchers and practitioners. However, existing models often focus on a single aspect of chronic conditions and are often ``black boxes with limited interpretability. In this research, we adopt the computational design science paradigm and propose a novel adversarial attention-based deep multisource multitask learning (AADMML) framework. Drawing upon deep learning, multitask learning, multisource learning, attention mechanism, and adversarial learning, AADMML addresses limitations with existing wearable sensor-based chronic condition severity assessment methods. Choosing Parkinsons disease (PD) as our test case because of its prevalence and societal significance, we conduct benchmark experiments to evaluate AADMML against state-of-the-art models on a large-scale dataset containing thousands of instances. We present three case studies to demonstrate the practical utility and economic benefits of AADMML and by applying it to detect early-stage PD. We discuss how our work is related to the IS knowledge base and its practical implications. This work can contribute to improved life quality for senior citizens and advance IS research in mobile health analytics.}
}


@article{Tan2022,
  title = {Optimization Techniques for Distributed Training of Large Language Models},
  author = {Tan, Mingxing and Chen, Bo and Li, Peng},
  journal = {Journal of Machine Learning Research},
  volume = {23},
  number = {103},
  pages = {1--35},
  year = {2022}
}

@article{Chen2022,
  title={Deep learning-based electronic health record analysis for clinical decision support in cardiovascular medicine},
  author={Chen, J. and Zhang, X. and Luo, Y. and Wu, T. and Zhao, D.},
  journal={JACC: Advances},
  volume={1},
  number={2},
  pages={100--112},
  year={2022},
  publisher={Elsevier}
}

@article{Kanchanamala20232414,
  title={Exponential Chimp Optimization Algorithm for optimizing deep neuro-fuzzy networks in MapReduce frameworks for fake news detection},
  author={Kanchanamala, K. and Rao, P.V. and Guntuku, S.C.},
  journal={Expert Systems with Applications},
  volume={217},
  pages={119611},
  year={2023},
  publisher={Elsevier}
}

@article{Liu20211735,
  title={Energy-efficient deep learning on edge devices: Hardware-aware optimization framework},
  author={Liu, Y. and Zhao, T. and Wang, W. and Liu, X.},
  journal={IEEE Internet of Things Journal},
  volume={8},
  number={3},
  pages={1735--1747},
  year={2021},
  publisher={IEEE}
}

@article{Ahmed2023,
  title={Cuckoo search optimization for hyperparameter tuning in deep learning security models},
  author={Ahmed, R. and Khan, M.A. and Ali, S. and Kumar, N.},
  journal={Neural Computing and Applications},
  volume={35},
  number={8},
  pages={5672--5688},
  year={2023},
  publisher={Springer}
}

@article{Rahman2022,
  title={Feature selection with Cuckoo Search for malware classification in IoT environments},
  author={Rahman, A. and Nasir, M. and Hasan, K. and Liu, J.},
  journal={Journal of Network and Computer Applications},
  volume={194},
  pages={103217},
  year={2022},
  publisher={Elsevier}
}

@article{Gupta2020,
  title={Neural architecture search using Cuckoo optimization for deep learning applications},
  author={Gupta, V. and Rani, R. and Kumar, V.},
  journal={Applied Intelligence},
  volume={50},
  number={11},
  pages={4058--4080},
  year={2020},
  publisher={Springer}
}

@article{Sharma2022,
  title={Solving combinatorial optimization problems with exponential chimp optimization algorithm},
  author={Sharma, A. and Sharma, D. and Panigrahi, B.K.},
  journal={Knowledge-Based Systems},
  volume={240},
  pages={108120},
  year={2022},
  publisher={Elsevier}
}

@article{Heidari20191,
  title={Whale Optimization Algorithm for clustering big data in MapReduce environments},
  author={Heidari, A.A. and Faris, H. and Mirjalili, S. and Aljarah, I.},
  journal={Cluster Computing},
  volume={22},
  pages={10357--10373},
  year={2019},
  publisher={Springer}
}

@article{Kumar2021,
  title={Feature selection using whale optimization and deep neural networks for big data analytics},
  author={Kumar, R. and Sharma, R.K. and Vadhera, S.},
  journal={Journal of Big Data},
  volume={8},
  number={1},
  pages={1--23},
  year={2021},
  publisher={Springer}
}

@article{Aljarah2022,
  title={Multi-objective whale optimization for large-scale feature selection problems},
  author={Aljarah, I. and Mafarja, M. and Heidari, A.A. and Faris, H.},
  journal={Knowledge-Based Systems},
  volume={241},
  pages={108240},
  year={2022},
  publisher={Elsevier}
}

@article{Chen20221,
  title={Gravitational search algorithm for parameter optimization in deep reinforcement learning},
  author={Chen, H. and Yang, J. and Li, C. and Wang, M.},
  journal={Applied Soft Computing},
  volume={123},
  pages={108948},
  year={2022},
  publisher={Elsevier}
}

@article{Mirjalili2020,
  title={Multi-objective gravitational search algorithm for engineering optimization problems},
  author={Mirjalili, S. and Gandomi, A.H. and Mirjalili, S.Z. and Saremi, S.},
  journal={Computer Methods in Applied Mechanics and Engineering},
  volume={357},
  pages={112583},
  year={2020},
  publisher={Elsevier}
}

@article{Das2022,
  title={Adaptive gravitational search algorithm for noisy optimization environments},
  author={Das, S. and Kar, S. and Srivastava, G. and Mafarja, M.},
  journal={Expert Systems with Applications},
  volume={202},
  pages={117258},
  year={2022},
  publisher={Elsevier}
}

@article{Wang20232325,
  title={Neural architecture search using genetic algorithms for deep learning model design},
  author={Wang, J. and Zhang, L. and Zhao, H. and Qian, Y.},
  journal={Information Sciences},
  volume={615},
  pages={2325--2348},
  year={2023},
  publisher={Elsevier}
}

@article{Liu2020,
  title={Multi-objective genetic algorithm for hyperparameter optimization in deep learning models},
  author={Liu, Y. and Sun, Y. and Wu, P.},
  journal={Neural Networks},
  volume={125},
  pages={249--259},
  year={2020},
  publisher={Elsevier}
}

@article{Kim2021,
  title={Ensemble model generation using genetic algorithms for deep learning},
  author={Kim, S. and Kim, H. and Yoon, M.},
  journal={Applied Sciences},
  volume={11},
  number={4},
  pages={1523},
  year={2021},
  publisher={MDPI}
}

@article{Rao2021,
  title={Teaching-learning-based optimization for constrained engineering design problems},
  author={Rao, R.V. and Patel, V.},
  journal={Engineering Optimization},
  volume={53},
  number={2},
  pages={319--337},
  year={2021},
  publisher={Taylor \& Francis}
}

@article{Satapathy2022,
  title={Improved teaching-learning-based optimization for multi-modal optimization problems},
  author={Satapathy, S.C. and Naik, A. and Parvathi, K.},
  journal={Applied Soft Computing},
  volume={118},
  pages={108422},
  year={2022},
  publisher={Elsevier}
}

@article{Singh2021,
  title={Hyperparameter tuning using differential evolution for convolutional neural networks},
  author={Singh, P. and Chaudhari, S. and Sharma, T.K.},
  journal={Neural Computing and Applications},
  volume={33},
  pages={12631--12646},
  year={2021},
  publisher={Springer}
}

@article{Das2021,
  title={Adaptive parameter control in differential evolution for neural network training},
  author={Das, P.K. and Behera, H.S. and Panigrahi, B.K.},
  journal={Applied Intelligence},
  volume={51},
  pages={7978--7996},
  year={2021},
  publisher={Springer}
}

@article{Wang2020,
  title={Hybrid differential evolution and particle swarm optimization for complex optimization problems},
  author={Wang, D. and Tan, D. and Liu, L.},
  journal={Information Sciences},
  volume={181},
  number={20},
  pages={4514--4532},
  year={2020},
  publisher={Elsevier}
}

@article{Srivatsan20234723,
  title={Feature selection for big data using particle swarm optimization variants},
  author={Srivatsan, R. and Manimaran, J. and Thirumaran, M.},
  journal={Journal of Supercomputing},
  volume={79},
  pages={4723--4744},
  year={2023},
  publisher={Springer}
}

@article{Kennedy2022,
  title={Dynamic particle swarm optimization for time-varying objective functions},
  author={Kennedy, J. and Mendes, R. and Banks, A.},
  journal={Swarm Intelligence},
  volume={16},
  pages={29--53},
  year={2022},
  publisher={Springer}
}

@article{Zhang2020,
  title={Adaptive particle swarm optimization for high-dimensional problems},
  author={Zhang, Y. and Wang, S. and Ji, G.},
  journal={Soft Computing},
  volume={24},
  pages={11987--12007},
  year={2020},
  publisher={Springer}
}

@article{Zhou20221,
  title={Bayesian optimization for neural architecture search in high-cost evaluation scenarios},
  author={Zhou, A. and Wang, Y. and Hang, W. and Liu, S.},
  journal={IEEE Transactions on Neural Networks and Learning Systems},
  volume={33},
  number={11},
  pages={6281--6292},
  year={2022},
  publisher={IEEE}
}

@article{Snoek2021,
  title={Multi-fidelity Bayesian optimization for hyperparameter tuning},
  author={Snoek, J. and Rippel, O. and Swersky, K. and Kiros, R. and Satish, N.},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  pages={12449--12460},
  year={2021}
}

@article{Frazier2022,
  title={Parallel Bayesian optimization for expensive function evaluations},
  author={Frazier, P.I. and Clark, S.C. and Molinaro, M. and Wang, J.},
  journal={Journal of Global Optimization},
  volume={82},
  pages={389--415},
  year={2022},
  publisher={Springer}
}

@article{Li20212467,
  title={Learning to optimize: A meta-learning approach for gradient-based optimizers},
  author={Li, K. and Malik, J. and Ren, W.},
  journal={Neural Networks},
  volume={140},
  pages={167--178},
  year={2021},
  publisher={Elsevier}
}

@article{Andrychowicz2021,
  title={Learning to learn by gradient descent by gradient descent},
  author={Andrychowicz, M. and Denil, M. and Gomez, S. and Hoffman, M.W. and Pfau, D. and Schaul, T. and Shillingford, B. and de Freitas, N.},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  pages={3981--3989},
  year={2021}
}

@article{Chen2020,
  title={Neural optimizers with hypergradients for tuning parameter-wise learning rates},
  author={Chen, X. and Liu, S. and Sun, R. and Hong, M.},
  journal={Proceedings of the 37th International Conference on Machine Learning},
  pages={1055--1064},
  year={2020}
}

@article{Ghahramani2015,
  title = {Probabilistic machine learning and artificial intelligence},
  author = {Ghahramani, Zoubin},
  journal = {Nature},
  volume = {521},
  number = {7553},
  pages = {452--459},
  year = {2015},
  doi = {10.1038/nature14541}
}

@article{LeCun2015,
  title = {Deep learning},
  author = {LeCun, Yann and Bengio, Yoshua and Hinton, Geoffrey},
  journal = {Nature},
  volume = {521},
  number = {7553},
  pages = {436--444},
  year = {2015},
  doi = {10.1038/nature14539}
}

@book{Back1996,
  title = {Evolutionary Algorithms in Theory and Practice},
  author = {B{\"a}ck, Thomas},
  publisher = {Oxford University Press},
  year = {1996},
  doi = {10.1093/oso/9780195099713.001.0001}
}

@article{Hinton2015,
  title = {Distilling the Knowledge in a Neural Network},
  author = {Hinton, Geoffrey and Vinyals, Oriol and Dean, Jeff},
  journal = {arXiv preprint arXiv:1503.02531},
  year = {2015}
}

@article{Narayanan2021,
  title = {Efficient large-scale language model training on GPU clusters using Megatron-LM},
  author = {Narayanan, Deepak and Shoeybi, Mohammad and Casper, Jared and LeGresley, Patrick and Patwary, Mostofa and Korthikanti, Vijay and Vainbrand, Dmitri and Kashinkunti, Prethvi and Bernauer, Julie and Catanzaro, Bryan},
  journal = {arXiv preprint arXiv:2104.04473},
  year = {2021}
}

@inproceedings{Alistarh2017,
  title = {QSGD: Communication-efficient SGD via gradient quantization and encoding},
  author = {Alistarh, Dan and Grubic, Demjan and Li, Jerry and Tomioka, Ryota and Vojnovic, Milan},
  booktitle = {Advances in Neural Information Processing Systems},
  volume = {30},
  pages = {1709--1720},
  year = {2017}
}


@article{najafabadi2015deep,
  title={Deep learning applications and challenges in big data analytics},
  author={Najafabadi, Maryam Mohammadi and Villanustre, Flavio and Khoshgoftaar, Taghi M and Seliya, N and Wald, Richard and Muharemagic, Edin},
  journal={Journal of Big Data},
  volume={2},
  number={1},
  pages={1-21},
  year={2015},
  publisher={Springer}
}

@book{yan2023computational,
  title={Computational Methods for Deep Learning: Theory, Algorithms, and Implementations},
  author={Yan, Wei Qi},
  year={2023},
  publisher={Springer Nature}
}

@article{zhang2023distributed,
  title={From distributed machine to distributed deep learning: a comprehensive survey},
  author={Zhang, Hongming and Dehghani, M and Yazdanparast, Z},
  journal={Journal of Big Data},
  volume={10},
  number={1},
  pages={158},
  year={2023},
  publisher={Springer}
}

@article{li2019federated,
  title={Federated learning: Challenges, methods, and future directions},
  author={Li, Tian and Sahu, Abhishek Kumar and Talwalkar, Ameet and Smith, Virginia},
  journal={IEEE Signal Processing Magazine},
  volume={37},
  number={3},
  pages={50-60},
  year={2019},
  publisher={IEEE}
}

@article{li2020survey,
  title={A survey on scalable deep learning techniques},
  author={Li, Xia and Liu, Yang and Li, Tian and Qin, Hong},
  journal={Journal of Big Data},
  volume={7},
  number={1},
  pages={1-41},
  year={2020},
  publisher={Springer}
}

@article{ben2019demystifying,
  title={Demystifying deep learning optimization in big data contexts},
  author={Ben, Simon and Waller, Jenna},
  journal={Artificial Intelligence Review},
  volume={53},
  number={4},
  pages={3197-3225},
  year={2019},
  publisher={Springer}
}

@incollection{bengio2012practical,
  title={Practical recommendations for gradient-based training of deep architectures},
  author={Bengio, Yoshua},
  booktitle={Neural networks: Tricks of the trade: Second edition},
  pages={437--478},
  year={2012},
  publisher={Springer}
}

@article{krizhevsky2012imagenet,
  title={Imagenet classification with deep convolutional neural networks},
  author={Krizhevsky, Alex and Sutskever, Ilya and Hinton, Geoffrey E},
  journal={Advances in neural information processing systems},
  volume={25},
  year={2012}
}

@article{dean2012large,
  title={Large scale distributed deep networks},
  author={Dean, Jeffrey and Corrado, Greg and Monga, Rajat and Chen, Kai and Devin, Matthieu and Mao, Mark and Ranzato, Marc'aurelio and Senior, Andrew and Tucker, Paul and Yang, Ke and others},
  journal={Advances in neural information processing systems},
  volume={25},
  year={2012}
}

@article{shazeer2017outrageously,
  title={Outrageously large neural networks: The sparsely-gated mixture-of-experts layer},
  author={Shazeer, Noam and Mirhoseini, Azalia and Maziarz, Krzysztof and Davis, Andy and Le, Quoc and Hinton, Geoffrey and Dean, Jeff},
  journal={arXiv preprint arXiv:1701.06538},
  year={2017}
}

@article{you2019large,
  title={Large batch optimization for deep learning: Training bert in 76 minutes},
  author={You, Yang and Li, Jing and Reddi, Sashank and Hseu, Jonathan and Kumar, Sanjiv and Bhojanapalli, Srinadh and Song, Xiaodan and Demmel, James and Keutzer, Kurt and Hsieh, Cho-Jui},
  journal={arXiv preprint arXiv:1904.00962},
  year={2019}
}
