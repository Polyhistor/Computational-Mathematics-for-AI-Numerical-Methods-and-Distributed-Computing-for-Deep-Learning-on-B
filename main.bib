@article{kitchenham2002principles,
    author    = {Kitchenham, Barbara and Pfleeger, Shari Lawrence},
    journal   = {ACM SIGSOFT Software Engineering Notes},
    number    = {2},
    pages     = {20--24},
    publisher = {ACM},
    title     = {Principles of survey research: part 6: data analysis},
    volume    = {27},
    year      = {2002},
}


@book{fitch2001rand,
    author    = {Fitch, Kathryn and Bernstein, Steven J and Aguilar, Mary D and Burnand, Bernard and LaCalle, Juan Ram{\'o}n},
    publisher = {RAND CORP SANTA MONICA CA},
    title     = {The RAND/UCLA appropriateness method user's manual},
    year      = {2001},
}

@article{dalkey1969delphi,
    author  = {Dalkey, Norman and Helmer, Olaf},
    journal = {Rand Corp Santa Monica CA},
    title   = {The Delphi method: An experimental study of group opinion},
    year    = {1969},
}

@article{diamond2014results,
    author    = {Diamond, Ian R and Grant, Robert C and Feldman, Brian M and Pencharz, Paul B and Ling, Simon C and Moore, Aideen M and Wales, Paul W},
    journal   = {Journal of Clinical Epidemiology},
    number    = {4},
    pages     = {402--409},
    publisher = {Elsevier},
    title     = {Results of a systematic review and meta-analysis of the presentations of Delphi studies},
    volume    = {67},
    year      = {2014},
}

@book{delbecq1975group,
    author    = {Delbecq, Andre L and Van de Ven, Andrew H and Gustafson, David H},
    publisher = {Scott, Foresman},
    title     = {Group techniques for program planning: A guide to nominal group and Delphi processes},
    year      = {1975},
}


@article{dalkey1963experimental,
    author    = {Dalkey, Norman and Helmer, Olaf},
    journal   = {Management Science},
    number    = {3},
    pages     = {458--467},
    publisher = {INFORMS},
    title     = {An experimental application of the {D}elphi method to the use of experts},
    volume    = {9},
    year      = {1963},
}

@article{delbecq1971group,
    author    = {Delbecq, Andre L and Van de Ven, Andrew H},
    journal   = {Journal of Applied Behavioral Science},
    number    = {4},
    pages     = {466--492},
    publisher = {Sage Publications},
    title     = {A {G}roup {P}rocess {M}odel for {P}roblem {I}dentification and {P}rogram {P}lanning},
    volume    = {7},
    year      = {1971},
}

@article{laney2001data,
    author  = {Laney, Doug},
    journal = {META Group Research Note},
    number  = {70},
    title   = {{3D} {D}ata {M}anagement: {C}ontrolling {D}ata {V}olume, {V}elocity, and {V}ariety},
    volume  = {6},
    year    = {2001},
}

@book{krippendorff2004reliability,
    address   = {Thousand Oaks, CA},
    author    = {Krippendorff, Klaus},
    publisher = {Sage Publications},
    title     = {Content {A}nalysis: {A}n {I}ntroduction to {I}ts {M}ethodology},
    year      = {2004},
}

@article{petersen2008systematic,
    author  = {Petersen, Kai and Feldt, Robert and Mujtaba, Shahid and Mattsson, Michael},
    journal = {EASE},
    pages   = {68--77},
    title   = {Systematic mapping studies in software engineering},
    volume  = {8},
    year    = {2008},
}

@article{dean2012largemapreduce,
    author    = {Dean, Jeffrey and Ghemawat, Sanjay},
    journal   = {Communications of the ACM},
    number    = {1},
    pages     = {107--113},
    publisher = {ACM},
    title     = {MapReduce: simplified data processing on large clusters},
    volume    = {51},
    year      = {2008},
}

@inproceedings{li2014scaling,
    author    = {Li, Mu and Andersen, David G and Park, Jun Woo and Smola, Alexander J and Ahmed, Amr and Josifovski, Vanja and Long, James and Shekita, Eugene J and Su, Bor-Yiing},
    booktitle = {11th USENIX Symposium on Operating Systems Design and Implementation},
    pages     = {583--598},
    title     = {Scaling distributed machine learning with the parameter server},
    year      = {2014},
}

@article{zaharia2016apache,
    author    = {Zaharia, Matei and Xin, Reynold S and Wendell, Patrick and Das, Tathagata and Armbrust, Michael and Dave, Ankur and Meng, Xiangrui and Rosen, Josh and Venkataraman, Shivaram and Franklin, Michael J and others},
    journal   = {Communications of the ACM},
    number    = {11},
    pages     = {56--65},
    publisher = {ACM},
    title     = {Apache {S}park: {A} unified engine for big data processing},
    volume    = {59},
    year      = {2016},
}

@article{lecun2015deep,
    author    = {LeCun, Yann and Bengio, Yoshua and Hinton, Geoffrey},
    journal   = {Nature},
    number    = {7553},
    pages     = {436--444},
    publisher = {Nature Publishing Group},
    title     = {Deep learning},
    volume    = {521},
    year      = {2015},
}

@article{jordan2015machine,
    author    = {Jordan, Michael I and Mitchell, Tom M},
    journal   = {Science},
    number    = {6245},
    pages     = {255--260},
    publisher = {American Association for the Advancement of Science},
    title     = {Machine learning: Trends, perspectives, and prospects},
    volume    = {349},
    year      = {2015},
}

@book{goodfellow2016deep,
    address   = {Cambridge, MA},
    author    = {Goodfellow, Ian and Bengio, Yoshua and Courville, Aaron},
    publisher = {MIT Press},
    title     = {Deep Learning},
    year      = {2016},
}


@article{moher2009preferred,
    author    = {Moher, David and Liberati, Alessandro and Tetzlaff, Jennifer and Altman, Douglas G and PRISMA Group},
    journal   = {PLoS medicine},
    number    = {7},
    pages     = {e1000097},
    publisher = {Public Library of Science},
    title     = {Preferred reporting items for systematic reviews and meta-analyses: the PRISMA statement},
    volume    = {6},
    year      = {2009},
}

@article{kitchenham2007guidelines,
    author  = {Kitchenham, Barbara and Charters, Stuart},
    journal = {Technical report, Ver. 2.3 EBSE Technical Report. EBSE},
    title   = {Guidelines for performing systematic literature reviews in software engineering},
    year    = {2007},
}

@article{cooper1988,
    author    = {Cooper, Harris M},
    journal   = {Knowledge in Society},
    number    = {1},
    pages     = {104--126},
    publisher = {Springer},
    title     = {Organizing knowledge syntheses: A taxonomy of literature reviews},
    volume    = {1},
    year      = {1988},
}

@article{Zhang202420230063,
    abstract  = {Abstract             In order to give full play to the application of big data in film and television media and imaging in the cloud era, this study proposes a communication-efficient distributed deep neural network training method based on the DANE algorithm framework. The DANE algorithm is an approximate Newtonian method that has been widely used in communication-efficient distributed machine learning. It has the advantages of fast convergence and no need to calculate the inverse of the Hessian matrix, which can significantly reduce the communication and computational overhead in high-dimensional situations. In order to further improve the computational efficiency, it is necessary to study how to speed up the local optimization of DANE. It is a feasible method to choose to use the most popular adaptive gradient optimization algorithm Adam to replace the commonly used stochastic gradient descent method to solve the local single-machine suboptimization problem of DANE. Experiments show that Adam-based optimization can converge significantly faster than the original SGD-based implementation with little sacrifice in model generalization performance. With the increase of sampling rate, DANE-Adam significantly outperforms the DANE method in terms of convergence speed, and at the same time, the accuracy can be kept almost unchanged, which are 0.96, 0.88 and 0.75, respectively. This shows that Adam-based optimization can converge significantly faster than the original SGD-based implementation with little sacrifice in model generalization performance, with significant potential value.},
    author    = {Zhang, Qing},
    copyright = {http://creativecommons.org/licenses/by/4.0},
    doi       = {10.2478/amns.2023.1.00063},
    issn      = {2444-8656},
    journal   = {Applied Mathematics and Nonlinear Sciences},
    langid    = {english},
    month     = jan,
    number    = {1},
    pages     = {20230063},
    title     = {Analysis of the Application Methods of Film and Television Media and Images in the Era of Big Data Cloud},
    volume    = {9},
    year      = {2024},
}


@article{Chen2016331,
    author  = {Chen, Tao and Yang, Shichen and Li, Jianhua},
    doi     = {10.1109/TEVC.2015.2457491},
    journal = {IEEE Transactions on Evolutionary Computation},
    number  = {3},
    pages   = {331--343},
    title   = {Specialized Genetic Algorithm for Neural Network Architecture Optimization},
    volume  = {20},
    year    = {2016},
}


@article{dauphin2014identifying,
    author  = {Dauphin, Yann N and Pascanu, Razvan and Gulcehre, Caglar and Cho, Kyunghyun and Ganguli, Surya and Bengio, Yoshua},
    journal = {Advances in neural information processing systems},
    title   = {Identifying and attacking the saddle point problem in high-dimensional non-convex optimization},
    volume  = {27},
    year    = {2014},
}


@article{schmidt2021descending,
    author  = {Schmidt, Robin M and Schneider, Frank and Hennig, Philipp},
    journal = {International Conference on Machine Learning},
    pages   = {9367--9376},
    title   = {Descending through a crowded valleyâ€”Benchmarking deep learning optimizers},
    year    = {2021},
}


@article{Gupta2021,
    author  = {Gupta, Harshit and Nath, Arun and Chakraborty, Sandip},
    doi     = {10.1109/MCOM.001.2000295},
    journal = {IEEE Communications Magazine},
    number  = {3},
    pages   = {98--104},
    title   = {Edge Intelligence for Smart Cities},
    volume  = {59},
    year    = {2021},
}


@article{Jin2021,
    author  = {Jin, Tianyu and Zhang, Haifeng and Liu, Song},
    doi     = {10.1016/j.ress.2021.107896},
    journal = {Reliability Engineering {\&} System Safety},
    pages   = {107896},
    title   = {Deep Learning for Industrial Fault Diagnosis},
    volume  = {215},
    year    = {2021},
}


@article{Fong2023,
    author  = {Fong, Simon and Deb, Suash and Wong, Raymond},
    doi     = {10.1109/TAI.2022.3209572},
    journal = {IEEE Transactions on Artificial Intelligence},
    number  = {2},
    pages   = {289--302},
    title   = {Adaptive Mutation Rates in Genetic Algorithms for Deep Learning},
    volume  = {4},
    year    = {2023},
}


@article{Ampavathi20211146,
    author     = {Ampavathi, Anusha and Saradhi, T. Vijaya},
    doi        = {10.1080/10255842.2020.1869726},
    issn       = {1025-5842, 1476-8259},
    journal    = {Computer Methods in Biomechanics and Biomedical Engineering},
    langid     = {english},
    month      = jul,
    number     = {10},
    pages      = {1146--1168},
    shorttitle = {Multi Disease-Prediction Framework Using Hybrid Deep Learning},
    title      = {Multi Disease-Prediction Framework Using Hybrid Deep Learning: An Optimal Prediction Model},
    volume     = {24},
    year       = {2021},
}


@article{Park2022,
    author  = {Park, Jongsoo and Yu, Minjia and Zhao, Tao},
    doi     = {10.1109/JSAC.2021.3118346},
    journal = {IEEE Journal on Selected Areas in Communications},
    number  = {1},
    pages   = {139--153},
    title   = {Adaptive Computation Techniques for Energy Efficiency in Deep Learning},
    volume  = {40},
    year    = {2022},
}


@article{Li20235058,
    abstract  = {With the rapid development of sensor technology, structural health monitoring data have tended to become more massive. Deep learning has advantages when handling big data, and has therefore been widely researched for diagnosing structural anomalies. However, for the diagnosis of different structural abnormalities, the model hyperparameters need to be adjusted according to different application scenarios, which is a complicated process. In this paper, a new strategy for building and optimizing 1D-CNN models is proposed that is suitable for diagnosing damage to different types of structure. This strategy involves optimizing hyperparameters with the Bayesian algorithm and improving model recognition accuracy using data fusion technology. Under the condition of sparse sensor measurement points, the entire structure is monitored, and the high-precision diagnosis of structural damage is performed. This method improves the applicability of the model to different structure detection scenarios, and avoids the shortcomings of traditional hyperparameter adjustment methods based on experience and subjectivity. In preliminary research on the simply supported beam test case, the efficient and accurate identification of parameter changes in small local elements was achieved. Furthermore, publicly available structural datasets were utilized to verify the robustness of the method, and a high identification accuracy rate of 99.85\% was achieved. Compared with other methods described in the literature, this strategy shows significant advantages in terms of sensor occupancy rate, computational cost, and identification accuracy.},
    author    = {Li, Xiaofei and Guo, Hainan and Xu, Langxing and Xing, Zezheng},
    copyright = {http://creativecommons.org/licenses/by/3.0/},
    doi       = {10.3390/s23115058},
    issn      = {1424-8220},
    journal   = {Sensors},
    keywords  = {1-D convolutional neural network,Bayesian optimization algorithm,decision-level fusion,structural anomaly detection,vibration signals},
    langid    = {english},
    month     = jan,
    number    = {11},
    pages     = {5058},
    publisher = {Multidisciplinary Digital Publishing Institute},
    title     = {Bayesian-{{Based Hyperparameter Optimization}} of {{1D-CNN}} for {{Structural Anomaly Detection}}},
    volume    = {23},
    year      = {2023},
}


@article{Zhu2021859,
    abstract   = {Ensuring the health and safety of senior citizens who live alone is a growing societal concern. The Activity of Daily Living (ADL) approach is a common means to monitor disease progression and the ability of these individuals to care for themselves. However, the prevailing sensor-based ADL monitoring systems primarily rely on wearable motion sensors, capture insufficient information for accurate ADL recognition, and do not provide a comprehensive understanding of ADLs at different granularities. Current healthcare IS and mobile analytics research focuses on studying the system, device, and provided services, and is in need of an end-to-end solution to comprehensively recognize ADLs based on mobile sensor data. This study adopts the design science paradigm and employs advanced deep learning algorithms to develop a novel hierarchical, multiphase ADL recognition framework to model ADLs at different granularities. We propose a novel 2D interaction kernel for convolutional neural networks to leverage interactions between human and object motion sensors. We rigorously evaluate each proposed module and the entire framework against state-of-the-art benchmarks (e.g., support vector machines, DeepConvLSTM, hidden Markov models, and topic-modeling-based ADLR) on two real-life motion sensor datasets that consist of ADLs at varying granularities: Opportunity and INTER. Results and a case study demonstrate that our framework can recognize ADLs at different levels more accurately. We discuss how stakeholders can further benefit from our proposed framework. Beyond demonstrating practical utility, we discuss contributions to the IS knowledge base for future design science-based cybersecurity, healthcare, and mobile analytics applications.},
    author     = {Zhu, Hongyi and Samtani, Sagar and Brown, Randall and Chen, Hsinchun},
    doi        = {10.25300/MISQ/2021/15574},
    issn       = {02767783, 21629730},
    journal    = {MIS Quarterly},
    month      = jun,
    number     = {2},
    pages      = {859--896},
    shorttitle = {A {{Deep Learning Approach}} for {{Recognizing Activity}} of {{Daily Living}} ({{ADL}}) for {{Senior Care}}},
    title      = {A {{Deep Learning Approach}} for {{Recognizing Activity}} of {{Daily Living}} ({{ADL}}) for {{Senior Care}}: {{Exploiting Interaction Dependency}} and {{Temporal Patterns}}},
    volume     = {45},
    year       = {2021},
}


@article{Zhao2020,
    author  = {Zhao, Liang and Wang, Jin and Li, Xiaohong},
    doi     = {10.1109/TNNLS.2019.2927703},
    journal = {IEEE Transactions on Neural Networks and Learning Systems},
    number  = {7},
    pages   = {2378--2389},
    title   = {Multi-Strategy Adaptive Methods for Deep Learning},
    volume  = {31},
    year    = {2020},
}


@article{Mao20242614,
    author    = {Mao, Shunan and Zhang, Shiliang},
    copyright = {https://ieeexplore.ieee.org/Xplorehelp/downloads/license-information/IEEE.html},
    doi       = {10.1109/TIP.2024.3378461},
    issn      = {1057-7149, 1941-0042},
    journal   = {IEEE Transactions on Image Processing},
    pages     = {2614--2626},
    title     = {Robust {{Fine-Grained Visual Recognition With Neighbor-Attention Label Correction}}},
    volume    = {33},
    year      = {2024},
}


@article{Kanchanamala20232414IJACS,
    abstract = {Summary             In the present epoch of computing, the world has changed from older conventional print media to social platform channels. Fake news articles have the prospects to handle the opinions of the public and so may harm human groupings. Therefore, it is necessary to explore the authenticity and credibility of the news flash being shared on the internet community. Hence, this research paper devises an efficient and robust fake news detection model, named Exponential Chimp Optimization Algorithm (EChOA)-based Deep Neuro-Fuzzy Network (DNFN) for detecting fake news. The introduced model utilizes a MapReduce framework that includes the mapper and reducer phases for processing big data for detecting fake news. First phase of processing is the Mapper work, in which every input used in the database is processed and creates an intermediate key-value pair. In the reducer phase, the fusion of features is performed by arranging the features with the help of computing the optimal parameter and Rand similarity coefficient using a Deep Q Network (DQN). Here, the detection of fake news is obtained by DNFN, and the DNFN is done using implemented EChOA. The EChOA-based DNFN effectively generates robust and effective fake news detection performance by choosing the optimal feature subsets through feature fusion. The EChOA is designed by integrating the Exponential Weighted Moving Average (EWMA) and Chimp Optimization Algorithm (ChOA). Moreover, the EChOA-based DNFN method outperformed various former fake news detection approaches and attains the highest performance based on the testing accuracy is 0.909, sensitivity is 0.937, and specificity is 0.891 using the FakeNewsNet dataset.},
    author   = {Kanchanamala, Pendela and Selva Rani, B. and Vairamuthu, S.},
    doi      = {10.1002/acs.3645},
    issn     = {0890-6327, 1099-1115},
    journal  = {International Journal of Adaptive Control and Signal Processing},
    langid   = {english},
    month    = sep,
    number   = {9},
    pages    = {2414--2433},
    title    = {Exponential {{Chimp Optimization Algorithm}} Based {{Deep Neuro}}-{{Fuzzy Network}} with {{MapReduce}} Framework for Fake News Detection in Big Data Analytics},
    volume   = {37},
    year     = {2023},
}


@article{bottou2018optimization,
    author  = {Bottou, L{\'e}on and Curtis, Frank E and Nocedal, Jorge},
    journal = {SIAM Review},
    number  = {2},
    pages   = {223--311},
    title   = {Optimization methods for large-scale machine learning},
    volume  = {60},
    year    = {2018},
}


@article{Pal2023,
    author            = {Pal, Souvik and Jhanjhi, N.Z. and Abdulbaqi, Azmi Shawkat and Akila, D. and Alsubaei, Faisal S. and Almazroi, Abdulaleem Ali},
    doi               = {10.3390/su15065104},
    journal           = {Sustainability (Switzerland)},
    note              = {Cited by: 25; All Open Access, Gold Open Access},
    number            = {6},
    publication_stage = {Final},
    source            = {Scopus},
    title             = {An Intelligent Task Scheduling Model for Hybrid Internet of Things and Cloud Environment for Big Data Applications},
    type              = {Article},
    url               = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85169085570&doi=10.3390%2fsu15065104&partnerID=40&md5=9956b585b61826605d8df1c0b65b85ce},
    volume            = {15},
    year              = {2023},
}


@article{Gao2024922,
    author  = {Gao, Ai and Xu, Shengnan and Zhao, Zichen and Shang, Haibin and Xu, Rui},
    doi     = {10.23919/JSEE.2024.000048},
    issn    = {1004-4132},
    journal = {Journal of Systems Engineering and Electronics},
    month   = aug,
    number  = {4},
    pages   = {922--931},
    title   = {Fault {{Diagnosis Method}} of {{Link Control System}} for {{Gravitational Wave Detection}}},
    volume  = {35},
    year    = {2024},
}


@article{Gujjeti2021241,
    author            = {Gujjeti, Sridhar and Pabboju, Suresh},
    doi               = {10.1007/978-981-16-0878-0_24},
    journal           = {Smart Innovation, Systems and Technologies},
    note              = {Cited by: 0},
    pages             = {241--250},
    publication_stage = {Final},
    source            = {Scopus},
    title             = {Rider-Deep Belief Network-Based MapReduce Framework for Big Data Classification},
    type              = {Conference paper},
    url               = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85112226242&doi=10.1007%2f978-981-16-0878-0_24&partnerID=40&md5=70da5a142d6a74b6b071821029f829c9},
    volume            = {225},
    year              = {2021},
}


@article{Lima2024,
    author     = {Lima, Jos{\e} G. B. A. and Gomes, Anderson S. L. and {De Almeida-Filho}, Adiel T.},
    doi        = {10.1007/s11831-024-10163-x},
    issn       = {1134-3060, 1886-1784},
    journal    = {Archives of Computational Methods in Engineering},
    langid     = {english},
    month      = jul,
    shorttitle = {Intelligent {{Materials Improvement Through Artificial Intelligence Approaches}}},
    title      = {Intelligent {{Materials Improvement Through Artificial Intelligence Approaches}}: {{A Systematic Literature Review}}},
    year       = {2024},
}


@article{Zhao2022,
    author  = {Zhao, Wei and Liu, Jun and Chen, Zhuo},
    doi     = {10.1109/TMC.2021.3058267},
    journal = {IEEE Transactions on Mobile Computing},
    number  = {9},
    pages   = {3268--3283},
    title   = {Hardware-Specific Optimizations for Mobile GPU Acceleration},
    volume  = {21},
    year    = {2022},
}


@article{Singh2022,
    author  = {Singh, Rajveer and Kumar, Dinesh and Sharma, Vivek},
    doi     = {10.1109/TSG.2021.3134577},
    journal = {IEEE Transactions on Smart Grid},
    number  = {3},
    pages   = {2137--2148},
    title   = {Smart Grid Optimization using Deep Learning},
    volume  = {13},
    year    = {2022},
}


@article{Lee2021,
    author  = {Lee, Jaewon and Park, Jinyoung and Kim, Heeyoul},
    doi     = {10.1109/TITS.2020.3043030},
    journal = {IEEE Transactions on Intelligent Transportation Systems},
    number  = {7},
    pages   = {4141--4154},
    title   = {Deep Learning for Intelligent Transportation Systems},
    volume  = {22},
    year    = {2021},
}


@article{Liu20211735Conf,
    abstract   = {The growing attention on location-based services has promoted the development of indoor localization studies. Existing techniques mainly use Received Signal Strength Indicator (RSSI) of wireless signals as location fingerprint. Inspired by deep learning techniques for signal processing, we propose a deep neural network-based framework (DeepLoc) to implement Wi-Fi fingerprint positioning. In order to improve localization performance, we further design a network division based optimization algorithm. We first adopt greedy algorithm to locate the user in a sub-area, and then reconstruct a smaller fingerprint database, which is fed into the training model. Finally, we evaluate the proposed framework. Experimental results show that DeepLoc can improve the localization accuracy efficiently and obtain better performance.},
    author     = {Liu, Saining and Ren, Qianqian and Li, Jinbao and Xu, Hui},
    booktitle  = {2021 {{IEEE}} 23rd {{Int Conf}} on {{High Performance Computing}} {\&} {{Communications}}; 7th {{Int Conf}} on {{Data Science}} {\&} {{Systems}}; 19th {{Int Conf}} on {{Smart City}}; 7th {{Int Conf}} on {{Dependability}} in {{Sensor}}, {{Cloud}} {\&} {{Big Data Systems}} {\&} {{Application}} ({{HPCC}}/{{DSS}}/{{SmartCity}}/{{DependSys}})},
    doi        = {10.1109/HPCC-DSS-SmartCity-DependSys53884.2021.00255},
    keywords   = {deep learning,Deep learning,Fingerprint recognition,greedy algorithm,Greedy algorithms,Location awareness,positioning,Received signal strength indicator,Signal processing algorithms,sub-area,Training},
    month      = dec,
    pages      = {1735--1740},
    shorttitle = {{{DeepLoc}}},
    title      = {{{DeepLoc}}: {{A Deep Neural Network-based Indoor Positioning Framework}}},
    year       = {2021},
}


@article{Zhang202211918,
    author    = {Zhang, Chenhan and Cui, Lei and Yu, Shui and Yu, James J. Q.},
    copyright = {https://ieeexplore.ieee.org/Xplorehelp/downloads/license-information/IEEE.html},
    doi       = {10.1109/JIOT.2021.3132363},
    issn      = {2327-4662, 2372-2541},
    journal   = {IEEE Internet of Things Journal},
    month     = jul,
    number    = {14},
    pages     = {11918--11931},
    title     = {A {{Communication-Efficient Federated Learning Scheme}} for {{IoT-Based Traffic Forecasting}}},
    volume    = {9},
    year      = {2022},
}


@article{Li2021,
    author  = {Li, Yuanlong and Zhou, Yiming and Zhu, Jun},
    doi     = {10.1109/TKDE.2020.2964658},
    journal = {IEEE Transactions on Knowledge and Data Engineering},
    number  = {8},
    pages   = {2967--2980},
    title   = {Adaptive Parameter Control for Non-Stationary Distributions},
    volume  = {33},
    year    = {2021},
}
@article{Kanchanamala2023,
    author            = {Kanchanamala, Pendela and Karnati, Ramesh and Bhaskar Reddy, Palagiri Vijaya},
    doi               = {10.1002/cpe.7618},
    journal           = {Concurrency and Computation: Practice and Experience},
    note              = {Cited by: 2},
    number            = {8},
    publication_stage = {Final},
    source            = {Scopus},
    title             = {Hybrid optimization enabled deep learning and spark architecture using big data analytics for stock market forecasting},
    type              = {Article},
    url               = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85147335171&doi=10.1002%2fcpe.7618&partnerID=40&md5=8f3bea839e3eda361651f8453fe2d90c},
    volume            = {35},
    year              = {2023},
}


@article{Sun2022,
    author  = {Sun, Yuxin and Wang, Jian and Zhang, Haibo},
    doi     = {10.1109/TIFS.2022.3153212},
    journal = {IEEE Transactions on Information Forensics and Security},
    pages   = {1455--1467},
    title   = {Deep Learning for Phishing Detection},
    volume  = {17},
    year    = {2022},
}


@article{Chatterjee2021969,
    author    = {Chatterjee, Ankita and Saha, Jayasree and Mukherjee, Jayanta and Aikat, Subhas and Misra, Arundhati},
    copyright = {https://ieeexplore.ieee.org/Xplorehelp/downloads/license-information/IEEE.html},
    doi       = {10.1109/LGRS.2020.2993095},
    issn      = {1545-598X, 1558-0571},
    journal   = {IEEE Geoscience and Remote Sensing Letters},
    month     = jun,
    number    = {6},
    pages     = {969--973},
    title     = {Unsupervised {{Land Cover Classification}} of {{Hybrid}} and {{Dual-Polarized Images Using Deep Convolutional Neural Network}}},
    volume    = {18},
    year      = {2021},
}


@article{Huang2023,
    author  = {Huang, Jiawei and Zhang, Min and Wang, Lei},
    doi     = {10.1109/TNNLS.2022.3178293},
    journal = {IEEE Transactions on Neural Networks and Learning Systems},
    number  = {8},
    pages   = {4259--4271},
    title   = {Dynamic Sparse Attention Mechanism for Memory Reduction},
    volume  = {34},
    year    = {2023},
}


@article{Javaid2022,
    author  = {Javaid, Muhammad and Haleem, Abid and Singh, Ravi Pratap},
    doi     = {10.1016/j.iot.2022.100516},
    journal = {Internet of Things},
    pages   = {100516},
    title   = {Digital Twin Technologies with Optimized Deep Learning},
    volume  = {19},
    year    = {2022},
}


@article{Zhou2021,
    author            = {Zhou, Zhou and Li, Fangmin and Yang, Shuiqiao},
    doi               = {10.1145/3462761},
    journal           = {ACM Transactions on Asian and Low-Resource Language Information Processing},
    note              = {Cited by: 9},
    number            = {5},
    publication_stage = {Final},
    source            = {Scopus},
    title             = {A Novel Resource Optimization Algorithm Based on Clustering and Improved Differential Evolution Strategy under a Cloud Environment},
    type              = {Article},
    url               = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85120324865&doi=10.1145%2f3462761&partnerID=40&md5=05bfaa2ddde1c6e60614d2314f166132},
    volume            = {20},
    year              = {2021},
}


@inproceedings{Manoranjithem2023212,
    address   = {Bengaluru, India},
    author    = {{Manoranjithem} and Dhanasekaran, S. and Asokan, Anju and Kumar, Arvind and Yamini, C. and Tiwari, Mohit},
    booktitle = {2023 {{International Conference}} on {{Intelligent Data Communication Technologies}} and {{Internet}} of {{Things}} ({{IDCIoT}})},
    copyright = {https://doi.org/10.15223/policy-029},
    doi       = {10.1109/IDCIoT56793.2023.10053504},
    isbn      = {978-1-6654-7451-1},
    month     = jan,
    pages     = {212--216},
    publisher = {IEEE},
    title     = {An {{Intrusion Detection Approach}} Using {{Hierarchical Deep Learning-based Butterfly Optimization Algorithm}} in {{Big Data Platform}}},
    year      = {2023},
}


@article{Xiao2022,
    author  = {Xiao, Jianfeng and Wang, Li and Zhang, Han},
    doi     = {10.1109/TPAMI.2021.3078562},
    journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
    number  = {9},
    pages   = {5127--5142},
    title   = {Gaussian Process Surrogate Models for Neural Architecture Search},
    volume  = {44},
    year    = {2022},
}


@article{Wu2022,
    author  = {Wu, Jianguo and Chen, Xin and Wang, Shuo},
    doi     = {10.1109/TKDE.2020.3038701},
    journal = {IEEE Transactions on Knowledge and Data Engineering},
    number  = {7},
    pages   = {3338--3351},
    title   = {Deep Learning for Financial Fraud Detection},
    volume  = {34},
    year    = {2022},
}


@article{Zhang20229876,
    author  = {Zhang, Wei and Lin, Xiaofeng and Chen, Jiayi},
    doi     = {10.1109/JIOT.2021.3135426},
    journal = {IEEE Internet of Things Journal},
    number  = {12},
    pages   = {9876--9889},
    title   = {Privacy-Preserving Federated Learning for IoT Edge Intelligence},
    volume  = {9},
    year    = {2022},
}


@article{Hassib20205573,
    author     = {Hassib, {\relax Eslam}. M. and {El-Desouky}, {\relax Ali}. I. and Labib, {\relax Labib}. M. and {El-kenawy}, El-Sayed M.},
    doi        = {10.1007/s00500-019-03901-y},
    issn       = {1432-7643, 1433-7479},
    journal    = {Soft Computing},
    langid     = {english},
    month      = apr,
    number     = {8},
    pages      = {5573--5592},
    shorttitle = {{{WOA}} + {{BRNN}}},
    title      = {{{WOA}} + {{BRNN}}: {{An}} Imbalanced Big Data Classification Framework Using {{Whale}} Optimization and Deep Neural Network},
    volume     = {24},
    year       = {2020},
}


@article{Lee2023,
    author  = {Lee, Jaehyun and Kwon, Hyunsung and Jung, Woojin},
    doi     = {10.1109/TPAMI.2022.3192712},
    journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
    number  = {7},
    pages   = {8421--8436},
    title   = {Attention Mechanism Optimization for Transformer Inference},
    volume  = {45},
    year    = {2023},
}


@article{Zhang2021,
    author  = {Zhang, Yi and Li, Jianwei and Wang, Xin},
    doi     = {10.1016/j.patcog.2020.107809},
    journal = {Pattern Recognition},
    pages   = {107809},
    title   = {Dynamic Learning Rate Approach for Convolutional Neural Networks},
    volume  = {112},
    year    = {2021},
}


@article{Li2023,
    author  = {Li, Xiaohua and Chen, Wei and Zhang, Hongqing},
    doi     = {10.1093/bioinformatics/btad153},
    journal = {Bioinformatics},
    number  = {4},
    pages   = {btad153},
    title   = {Drug Discovery Optimization Using Computational Methods},
    volume  = {39},
    year    = {2023},
}


@article{Thoppil2021,
    abstract = {An effective maintenance strategy to cut back maintenance costs and production loss with assured product quality has always been a major concern for industries. The Industry 4.0 era has built a wide acceptance for the predictive maintenance techniques in the remaining useful life (RUL) estimation of critical industrial systems. In this paper, long short-term memory (LSTM) and bidirectional-LSTM (bi-LSTM) deep neural architecture-based predictive algorithms are proposed for the RUL estimation of the lathe spindle unit. The deep learning algorithm is embedded within a Bayesian optimization algorithm for the self-optimization of its network structure and hyperparameters. The proposed deep learning algorithm is trained using lathe spindle health degradation data collected from an experimental accelerated run-to-failure test rig to evolve an RUL prediction model. The vibration signals representing lathe spindle health degradation from the health to faulty state are analyzed to extract time, frequency, and time-frequency domain features, which are then subjected to a neighborhood component analysis (NCA) based feature selection criteria. Finally, the selected relevant features are used to train the optimized LSTM/bi-LSTM network for RUL estimation. A comparison of the prediction results for Bayesian optimized LSTM/bi-LSTM network architectures and other prominent data-driven approaches are performed. The Bayesian optimized LSTM + bi-LSTM deep network architecture is observed to have the highest prediction accuracy for lathe spindle RUL estimation.},
    author   = {Thoppil, Nikhil M. and Vasu, V. and Rao, C. S. P.},
    doi      = {10.1115/1.4052838},
    issn     = {1530-9827},
    journal  = {Journal of Computing and Information Science in Engineering},
    month    = dec,
    number   = {021012},
    title    = {Bayesian {{Optimization LSTM}}/Bi-{{LSTM Network With Self-Optimized Structure}} and {{Hyperparameters}} for {{Remaining Useful Life Estimation}} of {{Lathe Spindle Unit}}},
    volume   = {22},
    year     = {2021},
}


@article{Liang2022,
    author  = {Liang, Xin and Wu, Zhenyu and Chen, Tianjian},
    doi     = {10.1109/MM.2022.3179084},
    journal = {IEEE Micro},
    number  = {5},
    pages   = {38--46},
    title   = {Specialized Operators for Low-Power Machine Learning Accelerators},
    volume  = {42},
    year    = {2022},
}


@article{Kanchanamala20232414IJACS,
    author  = {Kanchanamala, Padmavathi and Reddy, Chandra Sekhar and Kumar, Rajesh},
    doi     = {10.1109/ACCESS.2023.3235691},
    journal = {IEEE Access},
    pages   = {2414--2428},
    title   = {Exponential Chimp Optimization Algorithm for Fake News Detection},
    volume  = {11},
    year    = {2023},
}


@article{Liu2020257,
    author     = {Liu, Xiao and Zhang, Bin and Susarlia, Anjana and Padman, Rema},
    doi        = {10.25300/MISQ/2020/15107},
    issn       = {02767783, 21629730},
    journal    = {MIS Quarterly},
    month      = jan,
    number     = {1},
    pages      = {257--283},
    shorttitle = {Go to {{You Tube}} and {{Call Me}} in the {{Morning}}},
    title      = {Go to {{You Tube}} and {{Call Me}} in the {{Morning}}: {{Use}} of {{Social Media}} for {{Chronic Conditions}}},
    volume     = {44},
    year       = {2020},
}


@article{Wang2022939,
    author    = {Wang, Haozhao and Qu, Zhihao and Zhou, Qihua and Zhang, Haobo and Luo, Boyuan and Xu, Wenchao and Guo, Song and Li, Ruixuan},
    copyright = {https://ieeexplore.ieee.org/Xplorehelp/downloads/license-information/IEEE.html},
    doi       = {10.1109/JIOT.2021.3111624},
    issn      = {2327-4662, 2372-2541},
    journal   = {IEEE Internet of Things Journal},
    month     = jan,
    number    = {2},
    pages     = {939--963},
    title     = {A {{Comprehensive Survey}} on {{Training Acceleration}} for {{Large Machine Learning Models}} in {{IoT}}},
    volume    = {9},
    year      = {2022},
}


@article{Jiang2022,
    author            = {Jiang, Jinsheng and Ren, Haoran and Zhang, Meng},
    doi               = {10.1109/LGRS.2021.3073560},
    journal           = {IEEE Geoscience and Remote Sensing Letters},
    note              = {Cited by: 50},
    publication_stage = {Final},
    source            = {Scopus},
    title             = {A Convolutional Autoencoder Method for Simultaneous Seismic Data Reconstruction and Denoising},
    type              = {Article},
    url               = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85105059437&doi=10.1109%2fLGRS.2021.3073560&partnerID=40&md5=fd24b5d707947f637fdf8399ebfe1e7b},
    volume            = {19},
    year              = {2022},
}


@article{Zhang2023,
    author  = {Zhang, Wenqing and Liu, Jian and Wang, Zhen},
    doi     = {10.1109/TNNLS.2022.3224567},
    journal = {IEEE Transactions on Neural Networks and Learning Systems},
    number  = {12},
    pages   = {10283--10297},
    title   = {Distributed Reinforcement Learning Framework for Multiple Compute Clusters},
    volume  = {34},
    year    = {2023},
}


@article{Folino2022729,
    abstract = {Abstract             Predicting the final outcome of an ongoing process instance is a key problem in many real-life contexts. This problem has been addressed mainly by discovering a prediction model by using traditional machine learning methods and, more recently, deep learning methods, exploiting the supervision coming from outcome-class labels associated with historical log traces. However, a supervised learning strategy is unsuitable for important application scenarios where the outcome labels are known only for a small fraction of log traces. In order to address these challenging scenarios, a semi-supervised learning approach is proposed here, which leverages a multi-target DNN model supporting both outcome prediction and the additional auxiliary task of next-activity prediction. The latter task helps the DNN model avoid spurious trace embeddings and overfitting behaviors. In extensive experimentation, this approach is shown to outperform both fully-supervised and semi-supervised discovery methods using similar DNN architectures across different real-life datasets and label-scarce settings.},
    author   = {Folino, Francesco and Folino, Gianluigi and Guarascio, Massimo and Pontieri, Luigi},
    doi      = {10.1007/s12599-022-00749-9},
    issn     = {2363-7005, 1867-0202},
    journal  = {Business {\&} Information Systems Engineering},
    langid   = {english},
    month    = dec,
    number   = {6},
    pages    = {729--749},
    title    = {Semi-{{Supervised Discovery}} of {{DNN-Based Outcome Predictors}} from {{Scarcely-Labeled Process Logs}}},
    volume   = {64},
    year     = {2022},
}


@article{Garcia2021,
    author  = {Garcia, Rafael and Perez, Elena and Rodriguez, Maria},
    doi     = {10.1016/j.cviu.2020.103103},
    journal = {Computer Vision and Image Understanding},
    pages   = {103103},
    title   = {Model Quantization Approach for Computer Vision Tasks},
    volume  = {202},
    year    = {2021},
}


@article{MadhukarRao202127471,
    author            = {Madhukar Rao, G. and Dharavath, Ramesh},
    doi               = {10.1007/s11042-021-11059-9},
    journal           = {Multimedia Tools and Applications},
    note              = {Cited by: 6},
    number            = {18},
    pages             = {241--250},
    publication_stage = {Final},
    source            = {Scopus},
    title             = {DSSAE-BBOA: deep learning-based weather big data analysis and visualization},
    type              = {Article},
    url               = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85106292045&doi=10.1007%2fs11042-021-11059-9&partnerID=40&md5=f876bb4243f6b1b296f326d7ca095897},
    volume            = {80},
    year              = {2021},
}


@article{Huo2020199573,
    author    = {Huo, Yusen and Tao, Qinghua and Hu, Jianming},
    copyright = {https://creativecommons.org/licenses/by-nc-nd/4.0/},
    doi       = {10.1109/ACCESS.2020.3034419},
    issn      = {2169-3536},
    journal   = {IEEE Access},
    pages     = {199573--199585},
    title     = {Cooperative {{Control}} for {{Multi-Intersection Traffic Signal Based}} on {{Deep Reinforcement Learning}} and {{Imitation Learning}}},
    volume    = {8},
    year      = {2020},
}


@article{Chen2021,
    author  = {Chen, Yiyi and Li, Wei and Wang, Xing},
    doi     = {10.1109/TFDS.2021.3094579},
    journal = {IEEE Transactions on Financial Data Science},
    number  = {3},
    pages   = {161--173},
    title   = {Deep Learning for High-Frequency Trading},
    volume  = {3},
    year    = {2021},
}


@article{Malik2023,
    author  = {Malik, Zeeshan and Khan, Muhammad and Ahmad, Farooq},
    doi     = {10.1109/TDSC.2022.3164484},
    journal = {IEEE Transactions on Dependable and Secure Computing},
    number  = {2},
    pages   = {1061--1074},
    title   = {Adaptive Learning Approaches for Zero-Day Attack Detection},
    volume  = {20},
    year    = {2023},
}


@article{Rawat2021,
    author  = {Rawat, Divya and Singh, Rahul and Agarwal, Amit},
    doi     = {10.4258/hir.2021.27.1.39},
    journal = {Healthcare Informatics Research},
    number  = {1},
    pages   = {39--58},
    title   = {Clinical Decision Support Systems Using Deep Learning},
    volume  = {27},
    year    = {2021},
}


@article{Khan2023,
    author  = {Khan, Aftab and Ahmed, Naveed and Malik, Adeel},
    doi     = {10.1109/TNNLS.2022.3199999},
    journal = {IEEE Transactions on Neural Networks and Learning Systems},
    number  = {10},
    pages   = {7083--7095},
    title   = {Event-Based Computing Approach for Sparsely Activated Neural Networks},
    volume  = {34},
    year    = {2023},
}


@article{Mehdiyev2020143,
    author  = {Mehdiyev, Nijat and Evermann, Joerg and Fettke, Peter},
    doi     = {10.1007/s12599-018-0551-3},
    issn    = {2363-7005, 1867-0202},
    journal = {Business {\&} Information Systems Engineering},
    langid  = {english},
    month   = apr,
    number  = {2},
    pages   = {143--157},
    title   = {A {{Novel Business Process Prediction Model Using}} a {{Deep Learning Method}}},
    volume  = {62},
    year    = {2020},
}


@article{Chen2023,
    author  = {Chen, Qiang and Zhang, Rui and Wang, Jie},
    doi     = {10.1109/TPDS.2022.3222222},
    journal = {IEEE Transactions on Parallel and Distributed Systems},
    number  = {5},
    pages   = {1489--1500},
    title   = {Mixed-Precision Training with Adaptive Batch Sizing for Deep Learning},
    volume  = {34},
    year    = {2023},
}


@article{Wang2021,
    author  = {Wang, Shuiqiang and Zhang, Li and Chen, Xiaoming},
    doi     = {10.1109/TNNLS.2020.3004080},
    journal = {IEEE Transactions on Neural Networks and Learning Systems},
    number  = {7},
    pages   = {3025--3039},
    title   = {Enhanced Adam Optimizer for Deep Neural Networks},
    volume  = {32},
    year    = {2021},
}


@article{Zhou20211,
    abstract = {Resource optimization algorithm based on clustering and improved differential evolution strategy, as a new global optimized algorithm, has wide applications in language translation, language processing, document understanding, cloud computing, and edge computing due to high efficiency. With the development of deep learning technology and the rise of big data, the resource optimization algorithm encounters a series of challenges, such as the workload imbalance and low resource utilization. To address the preceding problems, this study proposes a novel resource optimization algorithm based on clustering and an improved differential evolution strategy (Multi-objective Task Scheduling Strategy (MTSS)). Three indexes, namely task completion time, execution cost, and workload, of virtual machines are selected and used to build the fitness function of the MTSS algorithm. At the same time, the preprocessing state is set up to cluster according to the resource and task characteristics to reduce the magnitude of their matching scale. Moreover, to solve the workload imbalance among different resource sets, local resource tasks are reallocated using the Q-value method in the MTSS strategy to achieve workload balance of global resources and improve the resource utilization rate. Experiments are carried out to evaluate the effectiveness of the proposed algorithm. Results show that the proposed algorithm outperforms other algorithms in terms of task completion time, execution cost, and workload balancing.},
    author   = {Zhou, Zhou and Li, Fangmin and Yang, Shuiqiao},
    doi      = {10.1145/3462761},
    issn     = {2375-4699, 2375-4702},
    journal  = {ACM Transactions on Asian and Low-Resource Language Information Processing},
    langid   = {english},
    month    = sep,
    number   = {5},
    pages    = {1--15},
    title    = {A {{Novel Resource Optimization Algorithm Based}} on {{Clustering}} and {{Improved Differential Evolution Strategy Under}} a {{Cloud Environment}}},
    volume   = {20},
    year     = {2021},
}


@article{Rodriguez2022,
    author  = {Rodriguez, Juan and Martinez, Carlos and Sanchez, Rosa},
    doi     = {10.1007/s11069-022-05278-y},
    journal = {Natural Hazards},
    pages   = {1475--1497},
    title   = {Deep Learning Models for Earthquake Prediction},
    volume  = {112},
    year    = {2022},
}


@article{Kumar2022,
    author  = {Kumar, Rajesh and Singh, Sumit and Agarwal, Neha},
    doi     = {10.1109/TSC.2021.3064891},
    journal = {IEEE Transactions on Services Computing},
    number  = {5},
    pages   = {2718--2731},
    title   = {Particle Swarm Optimization with Gradient Descent for Federated Learning},
    volume  = {15},
    year    = {2022},
}


@conference{Wei20211370,
    author            = {Wei, Jia and Zhang, Xingjun and Ji, Zeyu and Li, Jingbo and Wei, Zheng},
    doi               = {10.1109/ISPA-BDCloud-SocialCom-SustainCom52081.2021.00187},
    journal           = {19th IEEE International Symposium on Parallel and Distributed Processing with Applications, 11th IEEE International Conference on Big Data and Cloud Computing, 14th IEEE International Conference on Social Computing and Networking and 11th IEEE International Conference on Sustainable Computing and Communications, ISPA/BDCloud/SocialCom/SustainCom 2021},
    note              = {Cited by: 0},
    pages             = {241--250},
    publication_stage = {Final},
    source            = {Scopus},
    title             = {PANDA: Population Automatic Neural Distributed Algorithm for Deep Leaning},
    type              = {Conference paper},
    url               = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85124134024&doi=10.1109%2fISPA-BDCloud-SocialCom-SustainCom52081.2021.00187&partnerID=40&md5=9a6daf8e5e4c8f199b58df2c4c13318b},
    year              = {2021},
}


@article{Wang2023,
    author  = {Wang, Xiaofei and Zhang, Ye and Han, Song},
    doi     = {10.1109/TMC.2022.3178888},
    journal = {IEEE Transactions on Mobile Computing},
    number  = {11},
    pages   = {6739--6753},
    title   = {Scaling Efficiency for Federated Learning Across Heterogeneous Edge Devices},
    volume  = {22},
    year    = {2023},
}


@article{Samuel202068,
    abstract  = {Over the last decades, load forecasting is used by power companies to balance energy demand and supply. Among the several load forecasting methods, medium-term load forecasting is necessary for grids maintenance planning, settings of electricity prices, and harmonizing energy sharing arrangement. The forecasting of the month ahead electrical loads provides the information required for the interchange of energy among power companies. For accurate load forecasting, this paper proposes a model for medium-term load forecasting that uses hourly electrical load and temperature data to predict month ahead hourly electrical loads. For data preprocessing, modified entropy mutual information-based feature selection is used. It eliminates the redundancy and irrelevancy of features from the data. We employ the conditional restricted Boltzmann machine (CRBM) for the load forecasting. A meta-heuristic optimization algorithm Jaya is used to improve the CRBMs accuracy rate and convergence. In addition, the consumers dynamic consumption behaviors are also investigated using a discrete-time Markov chain and an adaptive k-means is used to group their behaviors into clusters. We evaluated the proposed model using GEFCom2012 US utility dataset. Simulation results confirm that the proposed model achieves better accuracy, fast convergence, and low execution time as compared to other existing models in the literature.},
    author    = {Samuel, Omaji and Alzahrani, Fahad A. and Hussen Khan, Raja Jalees Ul and Farooq, Hassan and Shafiq, Muhammad and Afzal, Muhammad Khalil and Javaid, Nadeem},
    copyright = {https://creativecommons.org/licenses/by/4.0/},
    doi       = {10.3390/e22010068},
    issn      = {1099-4300},
    journal   = {Entropy},
    langid    = {english},
    month     = jan,
    number    = {1},
    pages     = {68},
    title     = {Towards {{Modified Entropy Mutual Information Feature Selection}} to {{Forecast Medium-Term Load Using}} a {{Deep Learning Model}} in {{Smart Homes}}},
    volume    = {22},
    year      = {2020},
}


@article{Hamza20226579,
    author            = {Hamza, Manar Ahmed and Abdalla Hashim, Aisha Hassan and Mohamed, Heba G. and Alotaibi, Saud S. and Mahgoub, Hany and Mehanna, Amal S. and Motwakel, Abdelwahed},
    doi               = {10.32604/cmc.2022.031303},
    journal           = {Computers, Materials and Continua},
    note              = {Cited by: 3; All Open Access, Gold Open Access},
    number            = {3},
    pages             = {241--250},
    publication_stage = {Final},
    source            = {Scopus},
    title             = {Hyperparameter Tuned Deep Learning Enabled Intrusion Detection on Internet of Everything Environment},
    type              = {Article},
    url               = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85135032198&doi=10.32604%2fcmc.2022.031303&partnerID=40&md5=648796928ad8acd9afa9a697e93ff7c6},
    volume            = {73},
    year              = {2022},
}


@article{Zeng2024806,
    author  = {Zeng, Lei and Liu, Qi and Shen, Shigen and Liu, Xiaodong},
    doi     = {10.26599/TST.2023.9010058},
    issn    = {1007-0214},
    journal = {Tsinghua Science and Technology},
    month   = jun,
    number  = {3},
    pages   = {806--817},
    title   = {Improved {{Double Deep Q Network-Based Task Scheduling Algorithm}} in {{Edge Computing}} for {{Makespan Optimization}}},
    volume  = {29},
    year    = {2024},
}


@article{Torres202210533,
    author            = {Torres, J.F. and MartÃ­nez-Ãlvarez, F. and Troncoso, A.},
    doi               = {10.1007/s00521-021-06773-2},
    journal           = {Neural Computing and Applications},
    note              = {Cited by: 84; All Open Access, Green Open Access, Hybrid Gold Open Access},
    number            = {13},
    pages             = {241--250},
    publication_stage = {Final},
    source            = {Scopus},
    title             = {A deep LSTM network for the Spanish electricity consumption forecasting},
    type              = {Article},
    url               = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85124270388&doi=10.1007%2fs00521-021-06773-2&partnerID=40&md5=f713a9db8549fc828c3a1dab440eb872},
    volume            = {34},
    year              = {2022},
}


@article{Brahmane202115253,
    author            = {Brahmane, Anilkumar V. and Krishna, B. Chaitanya},
    doi               = {10.1007/s00521-021-06145-w},
    journal           = {Neural Computing and Applications},
    note              = {Cited by: 7},
    number            = {22},
    pages             = {241--250},
    publication_stage = {Final},
    source            = {Scopus},
    title             = {Big data classification using deep learning and apache spark architecture},
    type              = {Article},
    url               = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85109302985&doi=10.1007%2fs00521-021-06145-w&partnerID=40&md5=b1ef74db65c73b182a377bb9ffdebce2},
    volume            = {33},
    year              = {2021},
}


@article{Sheeba20231415,
    author            = {Sheeba, R. and Sharmila, R. and Alkhayyat, Ahmed and Malik, Rami Q.},
    doi               = {10.32604/csse.2023.034321},
    journal           = {Computer Systems Science and Engineering},
    note              = {Cited by: 0; All Open Access, Hybrid Gold Open Access},
    number            = {2},
    pages             = {241--250},
    publication_stage = {Final},
    source            = {Scopus},
    title             = {Modified Buffalo Optimization with Big Data Analytics Assisted Intrusion Detection Model},
    type              = {Article},
    url               = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85148225722&doi=10.32604%2fcsse.2023.034321&partnerID=40&md5=83a9c5911c65dfa39596c43d5c5a1e9a},
    volume            = {46},
    year              = {2023},
}


@article{Rajagopal20247175,
    abstract  = {Deep learning solutions in big data applications can benefit cloud centres and can also lead to network communication overhead. Typically, data collected from traffic are sent to the traffic management centre for analysis. However, this process can worsen the network route to the traffic management centre. A two-tier mechanism has been developed to address this issue, which performs vehicle speed estimation and traffic congestion detection for efficient traffic management. The real-time traffic video data are captured and the video frames are initially processed through a foreground extraction process, which extracts the temporarily stopped vehicles on the road by removing background pixels from the frames. The video frames are then wrapped in an up-down view to remove the influence of the observation angle. The traffic congestion is then detected accurately based on the traffic characteristics using the proposed Ensemble Random Forest-based Gradient Optimization (ERF-GO) algorithm. The generalization error occurs when learning complex features on frames is minimized using a gradient-based optimization (GO) algorithm. Finally, the learned information on traffic conditions is forwarded to the cloud and edge computing environments based on network connection speed. The efficiency of the proposed ERF-GO is investigated in terms of performance metrics, namely root mean square error, speed detection error, execution time, computational cost, accuracy, latency, workload balance, precision, recall, f-measure, and congestion detection error rate. The analytic result displays that the proposed ERF-GO algorithm attains a greater accuracy rate of about 98.65\% in detecting traffic congestion which is comparably higher than state-of-the-art methods.},
    author    = {Rajagopal, S. and Uma Devi, M. and Maria Jones, G. and Gomathy Nayagam, M.},
    doi       = {10.1080/03772063.2024.2350927},
    issn      = {0377-2063},
    journal   = {IETE Journal of Research},
    keywords  = {Edge computing,Ensemble random forest,Gradient-based optimization algorithm,Traffic congestion,Vehicle speed,Video frames},
    month     = sep,
    number    = {9},
    pages     = {7175--7191},
    publisher = {Taylor \& Francis},
    title     = {Ensemble {{Random Forest-based Gradient Optimization}} Based {{Energy Efficient Video Processing System}} for {{Smart Traffic Surveillance System}}},
    volume    = {70},
    year      = {2024},
}


@article{rumelhart1986learning,
    author  = {Rumelhart, David E and Hinton, Geoffrey E and Williams, Ronald J},
    journal = {Nature},
    number  = {6088},
    pages   = {533--536},
    title   = {Learning representations by back-propagating errors},
    volume  = {323},
    year    = {1986},
}


@article{Yang202363,
    abstract   = {Unstructured multimedia data (text and audio) provides unprecedented opportunities to derive actionable decision-making in the financial industry, in areas such as portfolio and risk management. However, due to formidable methodological challenges, the promise of business value from unstructured multimedia data has not materialized. In this study, we use a design science approach to develop DeepVoice, a novel nonverbal predictive analysis system for financial risk prediction, in the setting of quarterly earnings conference calls. DeepVoice forecasts financial risk by leveraging not only what managers say (verbal linguistic cues) but also how managers say it (vocal cues) during the earnings conference calls. The design of DeepVoice addresses several challenges associated with the analysis of nonverbal communication. We also propose a two-stage deep learning model to effectively integrate managers sequential vocal and verbal cues. Using a unique dataset of 6,047 earnings call samples (audio recordings and textual transcripts) of S\&P 500 firms across four years, we show that DeepVoice yields remarkably lower risk forecast errors than that achieved by previous efforts. The improvement can also translate into nontrivial economic gains in options trading. The theoretical and practical implications of analyzing vocal cues are discussed.},
    author     = {Yang, Yi and Qin, Yu and Fan, Yangyang and Zhang, Zhongju},
    doi        = {10.25300/MISQ/2022/17062},
    issn       = {02767783, 21629730},
    journal    = {MIS Quarterly},
    month      = mar,
    number     = {1},
    pages      = {63--96},
    shorttitle = {Unlocking the {{Power}} of {{Voice}} for {{Financial Risk Prediction}}},
    title      = {Unlocking the {{Power}} of {{Voice}} for {{Financial Risk Prediction}}: {{A Theory-Driven Deep Learning Design Approach}}},
    volume     = {47},
    year       = {2023},
}


@article{KoumetioTekouabou20231421,
    author     = {Koumetio Tekouabou, St{\e}phane C{\e}dric and Diop, El Bachir and Azmi, Rida and Chenal, J{\e}r{\^o}me},
    doi        = {10.1007/s11831-022-09844-2},
    issn       = {1134-3060, 1886-1784},
    journal    = {Archives of Computational Methods in Engineering},
    langid     = {english},
    month      = mar,
    number     = {2},
    pages      = {1421--1438},
    shorttitle = {Artificial {{Intelligence Based Methods}} for {{Smart}} and {{Sustainable Urban Planning}}},
    title      = {Artificial {{Intelligence Based Methods}} for {{Smart}} and {{Sustainable Urban Planning}}: {{A Systematic Survey}}},
    volume     = {30},
    year       = {2023},
}


@article{Baniata20241963,
    abstract  = {Educational institutions are increasingly focused on supporting students who may be facing academic challenges, aiming to enhance their educational outcomes through targeted interventions. Within this framework, leveraging advanced deep learning techniques to develop recommendation systems becomes essential. These systems are designed to identify students at risk of underperforming by analyzing patterns in their historical academic data, thereby facilitating personalized support strategies. This research introduces an innovative deep learning model tailored for pinpointing students in need of academic assistance. Utilizing a Gated Recurrent Neural Network (GRU) architecture, the model is rich with features such as a dense layer, max-pooling layer, and the ADAM optimization method used to optimize performance. The effectiveness of this model was tested using a comprehensive dataset containing 15,165 records of student assessments collected across several academic institutions. A comparative analysis with existing educational recommendation models, like Recurrent Neural Network (RNN), AdaBoost, and Artificial Immune Recognition System v2, highlights the superior accuracy of the proposed GRU model, which achieved an impressive overall accuracy of 99.70\%. This breakthrough underscores the models potential in aiding educational institutions to proactively support students, thereby mitigating the risks of underachievement and dropout.},
    author    = {Baniata, Laith H. and Kang, Sangwoo and Alsharaiah, Mohammad A. and Baniata, Mohammad H.},
    copyright = {https://creativecommons.org/licenses/by/4.0/},
    doi       = {10.3390/app14051963},
    issn      = {2076-3417},
    journal   = {Applied Sciences},
    langid    = {english},
    month     = feb,
    number    = {5},
    pages     = {1963},
    title     = {Advanced {{Deep Learning Model}} for {{Predicting}} the {{Academic Performances}} of {{Students}} in {{Educational Institutions}}},
    volume    = {14},
    year      = {2024},
}


@article{Lin2022,
    author  = {Lin, Yuxiang and Wang, Zhilin and Chen, Kai},
    journal = {Advances in Neural Information Processing Systems},
    pages   = {15789--15801},
    title   = {Gradient Checkpointing Approach for Large Language Models},
    volume  = {35},
    year    = {2022},
}


@article{Wang2021Online,
    author  = {Wang, Jialong and Xu, Shuai and Xu, Bo},
    doi     = {10.1109/TNNLS.2020.2978554},
    journal = {IEEE Transactions on Neural Networks and Learning Systems},
    number  = {2},
    pages   = {710--722},
    title   = {Multi-Armed Bandit Formulation for Online Hyperparameter Optimization},
    volume  = {32},
    year    = {2021},
}


@article{Park2021,
    author  = {Park, Sungjin and Kim, Jungwoo and Lee, Jaeho},
    doi     = {10.1016/j.jretconser.2021.102723},
    journal = {Journal of Retailing and Consumer Services},
    pages   = {102723},
    title   = {Customer Behavior Modeling using Deep Learning},
    volume  = {63},
    year    = {2021},
}


@article{Zhang20221,
    author  = {Zhang, Chengming and Yang, Yunxin and Chen, Wei},
    journal = {Proceedings of Machine Learning and Systems},
    pages   = {267--281},
    title   = {Tensor Parallelism for Large-Scale Model Training},
    volume  = {4},
    year    = {2022},
}


@article{Pustokhin2021,
    author            = {Pustokhin, Denis A. and Pustokhina, Irina V. and Rani, Poonam and Kansal, Vineet and Elhoseny, Mohamed and Joshi, Gyanendra Prasad and Shankar, K.},
    doi               = {10.1016/j.compeleceng.2021.107376},
    journal           = {Computers and Electrical Engineering},
    note              = {Cited by: 26},
    publication_stage = {Final},
    source            = {Scopus},
    title             = {Optimal deep learning approaches and healthcare big data analytics for mobile networks toward 5G},
    type              = {Article},
    url               = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85112824101&doi=10.1016%2fj.compeleceng.2021.107376&partnerID=40&md5=10252347ec36ea5f094e4e610b5305b2},
    volume            = {95},
    year              = {2021},
}


@article{Babu20233621,
    author            = {Babu, Ierin and Mathusoothana, R. and Kumar, S.},
    doi               = {10.32604/iasc.2023.033791},
    journal           = {Intelligent Automation and Soft Computing},
    note              = {Cited by: 5; All Open Access, Hybrid Gold Open Access},
    number            = {3},
    pages             = {241--250},
    publication_stage = {Final},
    source            = {Scopus},
    title             = {Evolutionary Algorithm Based Feature Subset Selection for Students Academic Performance Analysis},
    type              = {Article},
    url               = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85150772054&doi=10.32604%2fiasc.2023.033791&partnerID=40&md5=517db7668ec7947497b5959ac1936631},
    volume            = {36},
    year              = {2023},
}


@article{Eid20223845,
    abstract  = {Recent technologies such as artificial intelligence, machine learning, and big data are essential for supporting healthcare monitoring systems, particularly for monitoring Monkeypox confirmed cases. Infected and uninfected cases around the world have contributed to a growing dataset, which is publicly available and can be used by artificial intelligence and machine learning to predict the confirmed cases of Monkeypox at an early stage. Motivated by this, we propose in this paper a new approach for accurate prediction of the Monkeypox confirmed cases based on an optimized Long Short-Term Memory (LSTM) deep network. To fine-tune the hyper-parameters of the LSTM-based deep network, we employed the Al-Biruni Earth Radius (BER) optimization algorithm; thus, the proposed approach is denoted by BER-LSTM. Experimental results show the effectiveness of the proposed approach when assessed using various evaluation criteria, such as Mean Bias Error, which is recorded as (0.06) using BER-LSTM. To prove the superiority of the proposed approach, six different machine learning models are included in the conducted experiments. In addition, four different optimization algorithms are considered for comparison purposes. The results of this comparison confirmed the superiority of the proposed approach. On the other hand, several statistical tests are applied to analyze the stability and significance of the proposed approach. These tests include one-way Analysis of Variance (ANOVA), Wilcoxon, and regression tests. The results of these tests emphasize the robustness, significance, and efficiency of the proposed approach.},
    author    = {Eid, Marwa M. and {El-Kenawy}, El-Sayed M. and Khodadadi, Nima and Mirjalili, Seyedali and Khodadadi, Ehsaneh and Abotaleb, Mostafa and Alharbi, Amal H. and Abdelhamid, Abdelaziz A. and Ibrahim, Abdelhameed and Amer, Ghada M. and Kadi, Ammar and Khafaga, Doaa Sami},
    copyright = {https://creativecommons.org/licenses/by/4.0/},
    doi       = {10.3390/math10203845},
    issn      = {2227-7390},
    journal   = {Mathematics},
    langid    = {english},
    month     = oct,
    number    = {20},
    pages     = {3845},
    title     = {Meta-{{Heuristic Optimization}} of {{LSTM-Based Deep Network}} for {{Boosting}} the {{Prediction}} of {{Monkeypox Cases}}},
    volume    = {10},
    year      = {2022},
}


@article{Zhou2022764,
    author            = {Zhou, Yangfan and Huang, Kaizhu and Cheng, Cheng and Wang, Xuguang and Liu, Xin},
    doi               = {10.1007/s12559-021-09985-9},
    journal           = {Cognitive Computation},
    note              = {Cited by: 6},
    number            = {2},
    pages             = {241--250},
    publication_stage = {Final},
    source            = {Scopus},
    title             = {LightAdam: Towards a Fast and Accurate Adaptive Momentum Online Algorithm},
    type              = {Article},
    url               = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85122690180&doi=10.1007%2fs12559-021-09985-9&partnerID=40&md5=c844748d8c9ef7dbe7b6a03b7618327d},
    volume            = {14},
    year              = {2022},
}


@article{Gupta2022,
    author  = {Gupta, Saurabh and Verma, Ajay and Singh, Devendra},
    doi     = {10.1109/JIOT.2021.3132845},
    journal = {IEEE Internet of Things Journal},
    number  = {10},
    pages   = {7865--7877},
    title   = {Botnet Identification in IoT Networks},
    volume  = {9},
    year    = {2022},
}


@article{Kratsch2021261,
    abstract   = {Predictive process monitoring aims at forecasting the behavior, performance, and outcomes of business processes at runtime. It helps identify problems before they occur and re-allocate resources before they are wasted. Although deep learning (DL) has yielded breakthroughs, most existing approaches build on classical machine learning (ML) techniques, particularly when it comes to outcome-oriented predictive process monitoring. This circumstance reflects a lack of understanding about which event log properties facilitate the use of DL techniques. To address this gap, the authors compared the performance of DL (i.e., simple feedforward deep neural networks and long short term memory networks) and ML techniques (i.e., random forests and support vector machines) based on five publicly available event logs. It could be observed that DL generally outperforms classical ML techniques. Moreover, three specific propositions could be inferred from further observations: First, the outperformance of DL techniques is particularly strong for logs with a high variant-to-instance ratio (i.e., many non-standard cases). Second, DL techniques perform more stably in case of imbalanced target variables, especially for logs with a high event-to-activity ratio (i.e., many loops in the control flow). Third, logs with a high activity-to-instance payload ratio (i.e., input data is predominantly generated at runtime) call for the application of long short term memory networks. Due to the purposive sampling of event logs and techniques, these findings also hold for logs outside this study.},
    author     = {Kratsch, Wolfgang and Manderscheid, Jonas and R{\"o}glinger, Maximilian and Seyfried, Johannes},
    doi        = {10.1007/s12599-020-00645-0},
    issn       = {1867-0202},
    journal    = {Business {\journal = {Business \& Information Systems Engineering}} Information Systems Engineering},
    keywords   = {Business process management,Deep learning,Machine learning,Outcome prediction,Predictive process monitoring},
    langid     = {english},
    month      = jun,
    number     = {3},
    pages      = {261--276},
    shorttitle = {Machine {{Learning}} in {{Business Process Monitoring}}},
    title      = {Machine {{Learning}} in {{Business Process Monitoring}}: {{A Comparison}} of {{Deep Learning}} and {{Classical Approaches Used}} for {{Outcome Prediction}}},
    volume     = {63},
    year       = {2021},
}


@article{Jin2022,
    author  = {Jin, Sungho and Kim, Hyungjun and Park, Jongwoo},
    doi     = {10.1109/TCAD.2021.3109494},
    journal = {IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems},
    number  = {9},
    pages   = {2890--2903},
    title   = {Specialized Optimization for Edge NPU Implementations},
    volume  = {41},
    year    = {2022},
}


@article{Mohyuddin2023100317,
    author  = {Mohyuddin, Hassan and Moosavi, Syed Kumayl Raza and Zafar, Muhammad Hamza and Sanfilippo, Filippo},
    doi     = {10.1016/j.array.2023.100317},
    issn    = {25900056},
    journal = {Array},
    langid  = {english},
    month   = sep,
    pages   = {100317},
    title   = {A Comprehensive Framework for Hand Gesture Recognition Using Hybrid-Metaheuristic Algorithms and Deep Learning Models},
    volume  = {19},
    year    = {2023},
}


@article{Nguyen2021,
    author  = {Nguyen, Thi and Tran, Minh and Duong, Thanh},
    doi     = {10.1016/j.cie.2020.107023},
    journal = {Computers {\&} Industrial Engineering},
    pages   = {107023},
    title   = {Deep Learning for Supply Chain Optimization},
    volume  = {152},
    year    = {2021},
}


@article{Sagu202535,
    author    = {Sagu, Amit and Gill, Nasib Singh and Gulia, Preeti and Priyadarshini, Ishaani and Chatterjee, Jyotir Moy},
    copyright = {https://ieeexplore.ieee.org/Xplorehelp/downloads/license-information/IEEE.html},
    doi       = {10.1109/TBDATA.2024.3372368},
    issn      = {2332-7790, 2372-2096},
    journal   = {IEEE Transactions on Big Data},
    month     = feb,
    number    = {1},
    pages     = {35--46},
    title     = {Hybrid {{Optimization Algorithm}} for {{Detection}} of {{Security Attacks}} in {{IoT-Enabled Cyber-Physical Systems}}},
    volume    = {11},
    year      = {2025},
}


@article{Xu2023034501,
    abstract   = {Abstract             The increase of the spatial resolution in numerical computation always leads to a decrease in computing efficiency with respect to the constraint of mesh density. In response to this problem of the inability to perform numerical computation, we propose a novel method to boost the mesh-density in the finite element method (FEM) within 2D domains. Running on the von Mises stress fields of the 2D plane-strain problems computed by FEM, the proposed method utilizes a deep neural network named SMNet to learn a nonlinear mapping from low mesh-density to high mesh-density in stress fields and realizes the improvement of numerical computation accuracy and efficiency simultaneously. By introducing residual density blocks into SMNet, we can extract abundant local features and improve prediction capacity. The result indicates that SMNet can effectively increase the spatial resolution of stress fields under multiple scaling factors in mesh-density: 2 {\texttimes}, 3 {\texttimes}, and 4 {\texttimes}. Compared with the targets, the relative error of SMNet is 1.67\%, showing better performance than many other methods. SMNet can be generically used as an enhanced mesh-density boosting model of 2D physical fields for mesh-based numerical methods.},
    author     = {Xu, Handing and Nie, Zhenguo and Xu, Qingfeng and Li, Yaguan and Xie, Fugui and Liu, Xin-Jun},
    doi        = {10.1115/1.4054687},
    issn       = {1530-9827, 1944-7078},
    journal    = {Journal of Computing and Information Science in Engineering},
    langid     = {english},
    month      = jun,
    number     = {3},
    pages      = {034501},
    shorttitle = {{{SuperMeshing}}},
    title      = {{{SuperMeshing}}: {{Boosting}} the {{Mesh Density}} of {{Stress Field}} in {{Plane-Strain Problems Using Deep Learning Method}}},
    volume     = {23},
    year       = {2023},
}


@article{Moayedi20211331,
    abstract  = {A reliable prediction of sustainable energy consumption is key for designing environmentally friendly buildings. In this study, three novel hybrid intelligent methods, namely the grasshopper optimization algorithm (GOA), wind-driven optimization (WDO), and biogeography-based optimization (BBO), are employed to optimize the multitarget prediction of heating loads (HLs) and cooling loads (CLs) in the heating, ventilation and air conditioning (HVAC) systems. Concerning the optimization of the applied algorithms, a series of swarm-based iterations are performed, and the best structure is proposed for each model. The GOA, WDO, and BBO algorithms are mixed with a class of feedforward artificial neural networks (ANNs), which is called a multi-layer perceptron (MLP) to predict the HL and CL. According to the sensitivity analysis, the WDO with swarm size = 500 proposes the most-fitted ANN. The proposed WDO-ANN provided an accurate prediction in terms of heating load (training (R2 correlation = 0.977 and RMSE error = 0.183) and testing (R2 correlation = 0.973 and RMSE error = 0.190)) and yielded the best-fitted prediction in terms of cooling load (training (R2 correlation = 0.99 and RMSE error = 0.147) and testing (R2 correlation = 0.99 and RMSE error = 0.148)).},
    author    = {Moayedi, Hossein and Mosavi, Amir},
    copyright = {https://creativecommons.org/licenses/by/4.0/},
    doi       = {10.3390/en14051331},
    issn      = {1996-1073},
    journal   = {Energies},
    langid    = {english},
    month     = mar,
    number    = {5},
    pages     = {1331},
    title     = {Double-{{Target Based Neural Networks}} in {{Predicting Energy Consumption}} in {{Residential Buildings}}},
    volume    = {14},
    year      = {2021},
}


@article{AhmedHamza20226563,
    author  = {Ahmed Hamza, Manar and Alsolai, Hadeel and S. Alzahrani, Jaber and Alamgeer, Mohammad and Mahmoud Sayed, Mohamed and Sarwar Zamani, Abu and Yaseen, Ishfaq and Motwakel, Abdelwahed},
    doi     = {10.32604/cmc.2022.031541},
    issn    = {1546-2226},
    journal = {Computers, Materials {\journal = {Computers, Materials \& Continua}} Continua},
    langid  = {english},
    number  = {3},
    pages   = {6563--6577},
    title   = {Intelligent {{Slime Mould Optimization}} with {{Deep Learning Enabled Traffic Prediction}} in {{Smart Cities}}},
    volume  = {73},
    year    = {2022},
}


@article{Huang2020,
    author  = {Huang, Li and Chen, Jianhua and Yang, Xin},
    doi     = {10.1038/s41467-020-19673-1},
    journal = {Nature Communications},
    pages   = {5887},
    title   = {Deep Learning for Pandemic Forecasting},
    volume  = {11},
    year    = {2020},
}


@article{Nguyen2023,
    author  = {Nguyen, Thanh and Le, Minh and Pham, Huy},
    doi     = {10.1109/JIOT.2022.3201111},
    journal = {IEEE Internet of Things Journal},
    number  = {6},
    pages   = {5478--5490},
    title   = {Extreme Model Compression for Edge Deployment},
    volume  = {10},
    year    = {2023},
}


@article{Pandey2023,
    author            = {Pandey, Bishwajeet Kumar and Mï¼ŽRï¼ŽMï¼Ž, Veeramanickam and Ahmad, Shabeer and Rodriguez, Ciro and Esenarro, Doris},
    doi               = {10.1016/j.cose.2022.102975},
    journal           = {Computers and Security},
    note              = {Cited by: 21},
    publication_stage = {Final},
    source            = {Scopus},
    title             = {ExpSSOA-Deep maxout: Exponential Shuffled shepherd optimization based Deep maxout network for intrusion detection using big data in cloud computing framework},
    type              = {Article},
    url               = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85142248862&doi=10.1016%2fj.cose.2022.102975&partnerID=40&md5=b57510e55fffcc36d221738f93ae5edb},
    volume            = {124},
    year              = {2023},
}


@article{Li2023Battery,
    author            = {Li, Chaoran and Han, Xianjie and Zhang, Qiang and Li, Menghan and Rao, Zhonghao and Liao, Wei and Liu, Xiaori and Liu, Xinjian and Li, Gang},
    doi               = {10.1016/j.est.2023.107184},
    journal           = {Journal of Energy Storage},
    note              = {Cited by: 2},
    publication_stage = {Final},
    source            = {Scopus},
    title             = {State-of-health and remaining-useful-life estimations of lithium-ion battery based on temporal convolutional network-long short-term memory},
    type              = {Article},
    url               = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85147335171&doi=10.1002%2fcpe.7618&partnerID=40&md5=8f3bea839e3eda361651f8453fe2d90c},
    volume            = {65},
    year              = {2023},
}


@article{Palermo202240,
    author     = {Palermo, Marcelo Benedeti and Policarpo, Lucas Micol and Costa, Cristiano Andr{\e} Da and Righi, Rodrigo Da Rosa},
    doi        = {10.1007/s13721-022-00384-0},
    issn       = {2192-6662, 2192-6670},
    journal    = {Network Modeling Analysis in Health Informatics and Bioinformatics},
    langid     = {english},
    month      = dec,
    number     = {1},
    pages      = {40},
    shorttitle = {Tracking Machine Learning Models for Pandemic Scenarios},
    title      = {Tracking Machine Learning Models for Pandemic Scenarios: A Systematic Review of Machine Learning Models That Predict Local and Global Evolution of Pandemics},
    volume     = {11},
    year       = {2022},
}


@article{Li2020,
    author  = {Li, Zhihua and Wang, Ruosi and Yu, Dongmin},
    doi     = {10.1109/ACCESS.2020.3021736},
    journal = {IEEE Access},
    pages   = {163535--163556},
    title   = {Deep Learning for IoT Applications},
    volume  = {8},
    year    = {2020},
}


@article{Abayomi2021,
    author  = {Abayomi, John and Williams, Robert and Thomas, Andrew},
    doi     = {10.1109/TNSM.2021.3053410},
    journal = {IEEE Transactions on Network and Service Management},
    number  = {2},
    pages   = {1880--1893},
    title   = {Optimized CNN Architectures for Network Traffic Analysis},
    volume  = {18},
    year    = {2021},
}


@article{Tekouabou20241079,
    author     = {Tekouabou, St{\e}phane C. K. and Gherghina, {\c S}tefan Cristian and Kameni, Eric D{\e}sir{\e} and Filali, Youssef and Idrissi Gartoumi, Khalil},
    doi        = {10.1007/s11831-023-10010-5},
    issn       = {1134-3060, 1886-1784},
    journal    = {Archives of Computational Methods in Engineering},
    langid     = {english},
    month      = mar,
    number     = {2},
    pages      = {1079--1095},
    shorttitle = {{{AI-Based}} on {{Machine Learning Methods}} for {{Urban Real Estate Prediction}}},
    title      = {{{AI-Based}} on {{Machine Learning Methods}} for {{Urban Real Estate Prediction}}: {{A Systematic Survey}}},
    volume     = {31},
    year       = {2024},
}


@article{Xu2022,
    author  = {Xu, Tianfeng and Liang, Jian and Zhang, Xuesong},
    doi     = {10.1016/j.jocs.2022.101735},
    journal = {Journal of Computational Science},
    pages   = {101735},
    title   = {Distributed Optimization Approach for Scientific Machine Learning},
    volume  = {62},
    year    = {2022},
}


@article{Oberdorf202349,
    abstract = {Abstract             Ever-growing data availability combined with rapid progress in analytics has laid the foundation for the emergence of business process analytics. Organizations strive to leverage predictive process analytics to obtain insights. However, current implementations are designed to deal with homogeneous data. Consequently, there is limited practical use in an organization with heterogeneous data sources. The paper proposes a method for predictive end-to-end enterprise process network monitoring leveraging multi-headed deep neural networks to overcome this limitation. A case study performed with a medium-sized German manufacturing company highlights the methods utility for organizations.},
    author   = {Oberdorf, Felix and Schaschek, Myriam and Weinzierl, Sven and Stein, Nikolai and Matzner, Martin and Flath, Christoph M.},
    doi      = {10.1007/s12599-022-00778-4},
    issn     = {2363-7005, 1867-0202},
    journal  = {Business {\journal = {Business \& Information Systems Engineering}} Information Systems Engineering},
    langid   = {english},
    month    = feb,
    number   = {1},
    pages    = {49--64},
    title    = {Predictive {{End-to-End Enterprise Process Network Monitoring}}},
    volume   = {65},
    year     = {2023},
}


@article{Wu2021,
    author  = {Wu, Jianqiao and Li, Menghan and Zhang, Tong},
    doi     = {10.1162/tacl_a_00387},
    journal = {Transactions of the Association for Computational Linguistics},
    pages   = {629--645},
    title   = {Parameter Sharing Technique for Transformer Models},
    volume  = {9},
    year    = {2021},
}


@article{Li2022,
    author  = {Li, Jinbao and Wang, Xiang and Chen, Han},
    doi     = {10.1016/j.knosys.2021.107658},
    journal = {Knowledge-Based Systems},
    pages   = {107658},
    title   = {Transfer Learning with Hyperparameter Optimization for Deep Neural Networks},
    volume  = {235},
    year    = {2022},
}


@article{Rahman2023,
    author  = {Rahman, Abdur and Khan, Zafar and Javaid, Nadeem},
    doi     = {10.1109/MNET.2022.3191666},
    journal = {IEEE Network},
    number  = {1},
    pages   = {46--52},
    title   = {DDoS Attack Mitigation Through Optimized Deep Learning},
    volume  = {37},
    year    = {2023},
}
@article{Banchhor2022,
    author            = {Banchhor, Chitrakant and Srinivasu, N.},
    doi               = {10.4018/IJSIR.302612},
    journal           = {International Journal of Swarm Intelligence Research},
    note              = {Cited by: 1},
    number            = {1},
    publication_stage = {Final},
    source            = {Scopus},
    title             = {Grey Wolf Shuffled Shepherd Optimization Algorithm-Based Hybrid Deep Learning Classifier for Big Data Classification},
    type              = {Article},
    url               = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85153934848&doi=10.4018%2fIJSIR.302612&partnerID=40&md5=267d8fd52cdefc41da6d3baa0499cdf2},
    volume            = {13},
    year              = {2022},
}

@article{ataei2024filtering,
    author    = {Ataei, Pouya and Regula, Sri and Staegemann, Daniel and Malgaonkar, Saurabh},
    journal   = {AI},
    number    = {4},
    pages     = {2237--2259},
    publisher = {MDPI},
    title     = {Filtering Useful App Reviews Using Na{\"\i}ve Bayesâ€”Which Na{\"\i}ve Bayes?},
    volume    = {5},
    year      = {2024},
}


@article{Kim2022,
    author  = {Kim, Hyunjoon and Park, Joonho and Lee, Sunghyun},
    doi     = {10.1109/TCAD.2021.3089276},
    journal = {IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems},
    number  = {8},
    pages   = {2567--2580},
    title   = {Hardware-Aware Optimization Techniques for Inference Latency Reduction},
    volume  = {41},
    year    = {2022},
}


@article{Prasanth2019282,
    author  = {Prasanth, T. and Gunasekaran, M.},
    doi     = {10.1007/s11036-018-1204-y},
    issn    = {1383-469X, 1572-8153},
    journal = {Mobile Networks and Applications},
    langid  = {english},
    month   = feb,
    number  = {1},
    pages   = {282--294},
    title   = {Effective {{Big Data Retrieval Using Deep Learning Modified Neural Networks}}},
    volume  = {24},
    year    = {2019},
}


@article{Shan2020224884,
    author    = {Shan, Hongtao and Sun, Yuanyuan and Zhang, Wenjun and Kudreyko, Aleksey and Ren, Lijia},
    copyright = {https://creativecommons.org/licenses/by/4.0/legalcode},
    doi       = {10.1109/ACCESS.2020.3007776},
    issn      = {2169-3536},
    journal   = {IEEE Access},
    pages     = {224884--224894},
    title     = {Reliability {{Analysis}} of {{Power Distribution Network Based}} on {{PSO-DBN}}},
    volume    = {8},
    year      = {2020},
}


@article{Almutairi20225924,
    abstract  = {Recent studies have witnessed remarkable merits of metaheuristic algorithms in optimization problems. Due to the significance of the early analysis of the thermal load in energy-efficient buildings, this work introduces and compares four novel optimizer techniques---the firefly algorithm (FA), optics-inspired optimization (OIO), shuffled complex evolution (SCE), and teaching--learning-based optimization (TLBO)---for an accurate prediction of the heating load (HL). The models are applied to a multilayer perceptron (MLP) neural network to surmount its computational shortcomings. The models are fed by a literature-based dataset obtained for residential buildings. The results revealed that all models used are capable of properly analyzing and predicting the HL pattern. A comparison between them, however, showed that the TLBO-MLP with the coefficients of determination 0.9610 vs. 0.9438, 0.9373, and 0.9556 (respectively, for FA-MLP, OIO-MLP, and SCE-MLP) and the root mean square error of 2.1103 vs. 2.5456, 2.7099, and 2.2774 presents the most reliable approximation of the HL. It also surpassed several methods used in previous studies. Thus, the developed TLBO-MLP can be a beneficial model for subsequent practical applications.},
    author    = {Almutairi, Khalid and Algarni, Salem and Alqahtani, Talal and Moayedi, Hossein and Mosavi, Amir},
    copyright = {https://creativecommons.org/licenses/by/4.0/},
    doi       = {10.3390/su14105924},
    issn      = {2071-1050},
    journal   = {Sustainability},
    langid    = {english},
    month     = may,
    number    = {10},
    pages     = {5924},
    title     = {A {{TLBO-Tuned Neural Processor}} for {{Predicting Heating Load}} in {{Residential Buildings}}},
    volume    = {14},
    year      = {2022},
}


@article{Thapaliya202316,
    author            = {Thapaliya, Suman and Sharma, Pawan Kumar},
    doi               = {10.1007/s10776-022-00586-3},
    journal           = {International Journal of Wireless Information Networks},
    note              = {Cited by: 2},
    number            = {1},
    pages             = {241--250},
    publication_stage = {Final},
    source            = {Scopus},
    title             = {Cyber Forensic Investigation in IoT Using Deep Learning Based Feature Fusion in Big Data},
    type              = {Article},
    url               = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85143391443&doi=10.1007%2fs10776-022-00586-3&partnerID=40&md5=183a61751cdbbfe9dc4479d48e7a4dc0},
    volume            = {30},
    year              = {2023},
}


@article{Wu2023,
    author  = {Wu, Xiangrong and Zhang, Li and Chen, Yiwen},
    doi     = {10.1016/j.neunet.2022.11.019},
    journal = {Neural Networks},
    pages   = {142--155},
    title   = {Adaptive Optimization Strategy for Non-Stationary Data},
    volume  = {158},
    year    = {2023},
}


@article{Ampel2024137,
    abstract   = {The rapid proliferation of complex information systems has been met by an ever-increasing quantity of exploits that can cause irreparable cyber breaches. To mitigate these cyber threats, academia and industry have placed a significant focus on proactively identifying and labeling exploits developed by the international hacker community. However, prevailing approaches for labeling exploits in hacker forums do not leverage metadata from exploit darknet markets or public exploit repositories to enhance labeling performance. In this study, we adopted the computational design science paradigm to develop a novel information technology artifact, the deep transfer learning exploit labeler (DTL-EL). DTL-EL incorporates a pre-initialization design, multi-layer deep transfer learning (DTL), and a self-attention mechanism to automatically label exploits in hacker forums. We rigorously evaluated the proposed DTL-EL against state-of-the-art non-DTL benchmark methods based in classical machine learning and deep learning. Results suggest that the proposed DTL-EL significantly outperforms benchmark methods based on accuracy, precision, recall, and F1-score. Our proposed DTL-EL framework provides important practical implications for key stakeholders such as cybersecurity managers, analysts, and educators.},
    author     = {Ampel, Benjamin and Samtani, Sagar and Zhu, Hongyi and Chen, Hsinchun},
    doi        = {10.25300/MISQ/2023/17316},
    issn       = {02767783, 21629730},
    journal    = {MIS Quarterly},
    month      = mar,
    number     = {1},
    pages      = {137--166},
    shorttitle = {Creating {{Proactive Cyber Threat Intelligence}} with {{Hacker Exploit Labels}}},
    title      = {Creating {{Proactive Cyber Threat Intelligence}} with {{Hacker Exploit Labels}}: {{A Deep Transfer Learning Approach}}},
    volume     = {48},
    year       = {2024},
}


@article{Zhang2022,
    author  = {Zhang, Hao and Li, Zeyu and Wang, Jianyu},
    doi     = {10.1109/TPDS.2021.3135689},
    journal = {IEEE Transactions on Parallel and Distributed Systems},
    number  = {8},
    pages   = {1878--1890},
    title   = {Improved Communication Protocol for Distributed Deep Learning},
    volume  = {33},
    year    = {2022},
}


@article{Khan2020,
    author  = {Khan, Rafiullah and Schmidt, Bernhard and Kurtz, William},
    doi     = {10.1109/TNNLS.2020.2978577},
    journal = {IEEE Transactions on Neural Networks and Learning Systems},
    number  = {11},
    pages   = {5051--5065},
    title   = {Bayesian Optimization for Hyperparameter Tuning in Resource-Constrained Environments},
    volume  = {31},
    year    = {2020},
}


@article{SulthanAlikhan2023,
    author            = {Sulthan Alikhan, J. and Alageswaran, R. and Miruna Joe Amali, S.},
    doi               = {10.1016/j.bspc.2023.105011},
    journal           = {Biomedical Signal Processing and Control},
    note              = {Cited by: 14},
    publication_stage = {Final},
    source            = {Scopus},
    title             = {Self-attention convolutional neural network optimized with season optimization algorithm Espoused Chronic Kidney Diseases Diagnosis in Big Data System},
    type              = {Article},
    url               = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85160015120&doi=10.1016%2fj.bspc.2023.105011&partnerID=40&md5=31dfae96f4a9b24536e66f732392b98d},
    volume            = {85},
    year              = {2023},
}


@article{Vijayalakshmi2022,
    author  = {Vijayalakshmi, K. and Rajesh, S. and Kumar, P.},
    doi     = {10.1007/s10916-022-01782-7},
    journal = {Journal of Medical Systems},
    number  = {3},
    pages   = {18--31},
    title   = {Deep Learning for Patient Monitoring Systems},
    volume  = {46},
    year    = {2022},
}


@inproceedings{Wang2018175,
    address   = {Chengdu},
    author    = {Wang, Shuqiang and Shen, Yanyan and Zeng, Dewei and Hu, Yong},
    booktitle = {2018 {{International Conference}} on {{Artificial Intelligence}} and {{Big Data}} ({{ICAIBD}})},
    doi       = {10.1109/ICAIBD.2018.8396189},
    isbn      = {978-1-5386-6987-7},
    month     = may,
    pages     = {175--178},
    publisher = {IEEE},
    title     = {Bone Age Assessment Using Convolutional Neural Networks},
    year      = {2018},
}


@article{Zhu2022,
    author  = {Zhu, Xiaoning and Chen, Bo and Yang, Fan},
    doi     = {10.1016/j.jmsy.2021.09.016},
    journal = {Journal of Manufacturing Systems},
    pages   = {351--364},
    title   = {Quality Control Systems with Deep Learning},
    volume  = {62},
    year    = {2022},
}


@article{Ananth2022918,
    abstract  = {Lung tumor is a complex disease caused due to the irregular growth of lung cells. A key factor in effective treatment planning is the early detection of lung tumor. Visual similarity between benign and malignant nodules, heterogeneity and low contrast variation are the factors that make accurate cancerous lesion recognition, a very challenging task. In this paper, Optimized Deep convolutional neural network (DCNN) and Fuzzy C-means with Equilibrium optimizer (FCM-EO) is proposed for classification and segmentation of CT lung images. The proposed architecture is comprised of four phases such as preprocessing, feature extraction, classification and segmentation. In preprocessing, the weighted mean histogram analysis (WMHA) is utilized to enhance the quality of images and noise removal. Hybrid Dual tree-complex wavelet transform (DT-CWT) with Gabor filter is proposed in feature extraction to extract the features from the preprocessed images. DCNN model is designed to classify the original images into benign and malignant images. The weight of DCNN model is updated using the Enhanced black widow optimization algorithm (EBWOA). In segmentation, FCM-EO is introduced to identify the tumor regions and remove the outliers from the malignant images. LIDC-IDRI dataset is utilized for the experimental analysis and MATLAB is the implementation tool. The simulation analysis is performed for both the classification and segmentation processes. Accuracy, specificity, sensitivity, precision, F-measure, FROC, DSC, MCC, and IoU are evaluated for both these processes. The experimental results showed the proposed framework is efficient for the identification of tumor from the CT lung images.},
    author    = {Ananth, Antony Dennis and Palanisamy, Chenniappan},
    copyright = {{\copyright} 2021 Wiley Periodicals LLC.},
    doi       = {10.1002/ima.22667},
    issn      = {1098-1098},
    journal   = {International Journal of Imaging Systems and Technology},
    keywords  = {big data,classification,CT images,deep learning,feature extraction,lung tumor detection,segmentation},
    langid    = {english},
    number    = {3},
    pages     = {918--934},
    title     = {Extended and Optimized Deep Convolutional Neural Network-Based Lung Tumor Identification in Big Data},
    volume    = {32},
    year      = {2022},
}


@article{Khan2022,
    author  = {Khan, Asif and Ahmed, Sajid and Kumar, Rajesh},
    doi     = {10.1016/j.ijinfomgt.2022.102515},
    journal = {International Journal of Information Management},
    pages   = {102515},
    title   = {Ensemble Deep Learning for Risk Assessment},
    volume  = {67},
    year    = {2022},
}




@article{Joardar2019852,
    author    = {Joardar, Biresh Kumar and Kim, Ryan Gary and Doppa, Janardhan Rao and Pande, Partha Pratim and Marculescu, Diana and Marculescu, Radu},
    copyright = {https://ieeexplore.ieee.org/Xplorehelp/downloads/license-information/IEEE.html},
    doi       = {10.1109/TC.2018.2889053},
    issn      = {0018-9340, 1557-9956, 2326-3814},
    journal   = {IEEE Transactions on Computers},
    month     = jun,
    number    = {6},
    pages     = {852--866},
    title     = {Learning-{{Based Application-Agnostic 3D NoC Design}} for {{Heterogeneous Manycore Systems}}},
    volume    = {68},
    year      = {2019},
}


@article{Lin2022Baidu,
    author            = {Lin, Yong and Wang, Renyu and Gong, Xingyue and Jia, Guozhu},
    doi               = {10.1016/j.iref.2022.01.015},
    journal           = {International Review of Economics and Finance},
    note              = {Cited by: 15},
    publication_stage = {Final},
    source            = {Scopus},
    title             = {Cross-correlation and forecast impact of public attention on USD/CNY exchange rate: Evidence from Baidu Index},
    type              = {Article},
    url               = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85124283187&doi=10.1016%2fj.iref.2022.01.015&partnerID=40&md5=9729de6f5ae1e7b6aa4c9a64c3e64f84},
    volume            = {79},
    year              = {2022},
}


@article{Pan2020201,
    author            = {Pan, Hengyue and Niu, Xin and Li, RongChun and Dou, Yong and Jiang, Hui},
    doi               = {10.1016/j.neucom.2019.11.021},
    journal           = {Neurocomputing},
    note              = {Cited by: 27},
    pages             = {241--250},
    publication_stage = {Final},
    source            = {Scopus},
    title             = {Annealed gradient descent for deep learning},
    type              = {Article},
    url               = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85075852958&doi=10.1016%2fj.neucom.2019.11.021&partnerID=40&md5=21d9c81a8c6c51a2faaea8164f87bd20},
    volume            = {380},
    year              = {2020},
}


@article{Zhou2023195,
    abstract   = {Online health communities (OHCs) play an important role in enabling patients to exchange information and obtain social support from each other. However, do OHC interactions always benefit patients? In this research, we investigate different mechanisms by which OHC content may affect patients emotions. Specifically, we notice users can read not only emotional support intended to help them but also emotional support targeting other persons or posts that are not intended to generate any emotional support (auxiliary content). Drawing from emotional contagion theories, we argue that even though emotional support may benefit targeted support seekers, it could have a negative impact on the emotions of other support seekers. Our empirical study on an OHC for depression patients supports these arguments. Our findings are new to the literature and have critical practical implications since they suggest that we should carefully manage OHC-based interventions for depression patients to avoid unintended consequences. We design a novel deep learning model to differentiate emotional support from auxiliary content. Such differentiation is critical for identifying the negative effect of emotional support on unintended recipients. We also discuss options to alter the intervention volume, length, and frequency to tackle the challenge of the negative effect.},
    author     = {Zhou, Jiaqi and Zhang, Qingpeng and Zhou, Sijia and Li, Xin and Zhang, Xiaoquan (Michael)},
    doi        = {10.25300/MISQ/2022/17018},
    issn       = {02767783, 21629730},
    journal    = {MIS Quarterly},
    month      = mar,
    number     = {1},
    pages      = {195--226},
    shorttitle = {Unintended {{Emotional Effects}} of {{Online Health Communities}}},
    title      = {Unintended {{Emotional Effects}} of {{Online Health Communities}}: {{A Text Mining-Supported Empirical Study}}},
    volume     = {47},
    year       = {2023},
}


@article{Samadianfard20191934,
    abstract  = {Advancement in river flow prediction systems can greatly empower the operational river management to make better decisions, practices, and policies. Machine learning methods recently have shown promising results in building accurate models for river flow prediction. This paper aims to identify models with higher accuracy, robustness, and generalization ability by inspecting the accuracy of a number of machine learning models. The proposed models for river flow include support vector regression (SVR), a hybrid of SVR with a fruit fly optimization algorithm (FOA) (so-called FOASVR), and an M5 model tree (M5). Additionally, the influence of periodicity ({$\pi$}) on the forecasting enactment was examined. To assess the performance of the proposed models, different statistical meters were implemented, including root mean squared error (RMSE), mean absolute error (MAE), correlation coefficient (R), and Bayesian information criterion (BIC). Results showed that the FOASVR with RMSE (4.36 and 6.33 m3/s), MAE (2.40 and 3.71 m3/s) and R (0.82 and 0.81) values had the best performance in forecasting river flows at Babarud and Vaniar stations, respectively. Also, regarding BIC parameters, Qt-1 and {$\pi$} were selected as parsimonious inputs for predicting river flow one month ahead. Overall findings indicated that, although both the FOASVR and M5 predicted the river flows in suitable accordance with observed river flows, the performance of the FOASVR was moderately better than the M5 and periodicity noticeably increased the performance of the models; consequently, FOASVR can be suggested as the most accurate method for forecasting river flows.},
    author    = {Samadianfard, Saeed and Jarhan, Salar and Salwana, Ely and Mosavi, Amir and Shamshirband, Shahaboddin and Akib, Shatirah},
    copyright = {https://creativecommons.org/licenses/by/4.0/},
    doi       = {10.3390/w11091934},
    issn      = {2073-4441},
    journal   = {Water},
    langid    = {english},
    month     = sep,
    number    = {9},
    pages     = {1934},
    title     = {Support {{Vector Regression Integrated}} with {{Fruit Fly Optimization Algorithm}} for {{River Flow Forecasting}} in {{Lake Urmia Basin}}},
    volume    = {11},
    year      = {2019},
}


@inproceedings{Zhang20231,
    address    = {Xian, China},
    author     = {Zhang, Wenqiang and Wang, Xiaomeng},
    booktitle  = {2023 {{International Conference}} on {{Sensing}}, {{Measurement}} \&amp; {{Data Analytics}} in the Era of {{Artificial Intelligence}} ({{ICSMD}})},
    copyright  = {https://doi.org/10.15223/policy-029},
    doi        = {10.1109/ICSMD60522.2023.10490595},
    isbn       = {979-8-3503-1801-2},
    month      = nov,
    pages      = {1--6},
    publisher  = {IEEE},
    shorttitle = {Learning to {{Optimize Vehicle Routes Problem}}},
    title      = {Learning to {{Optimize Vehicle Routes Problem}}: {{A Two-Stage Hybrid Reinforcement Learning}}},
    year       = {2023},
}


@article{Cheng2023,
    author  = {Cheng, Xiaofeng and Liu, Wei and Zhang, Chen},
    doi     = {10.1007/s10661-023-10909-5},
    journal = {Environmental Monitoring and Assessment},
    number  = {3},
    pages   = {329},
    title   = {Deep Learning for Pollution Monitoring Networks},
    volume  = {195},
    year    = {2023},
}


@article{Wissuchek2024,
    abstract   = {Abstract             Prescriptive Analytics Systems (PAS) represent the most mature iteration of business analytics, significantly enhancing organizational decision-making. Recently, research has gained traction, with various technological innovations, including machine learning and artificial intelligence, significantly influencing the design of PAS. Although recent studies highlight these developments, the rising trend focuses on broader implications, such as the synergies and delegation between systems and users in organizational decision-making environments. Against this backdrop, we utilized a systematic literature review of 262 articles to build on this evolving perspective. Guided by general systems theory and socio-technical thinking, the concept of an information systems artifact directed this review. Our first objective was to clarify the essential subsystems, identifying 23 constituent components of PAS. Subsequently, we delved into the meta-level design of PAS, emphasizing the synergy and delegation between the human decision-maker and prescriptive analytics in supporting organizational decisions. From this exploration, four distinct system archetypes emerged: advisory, executive, adaptive, and self-governing PAS. Lastly, we engaged with affordance theory, illuminating the action potential of PAS. Our study advances the perspective on PAS, specifically from a broader socio-technical and information systems viewpoint, highlighting six distinct research directions, acting as a launchpad for future research in the domain.},
    author     = {Wissuchek, Christopher and Zschech, Patrick},
    doi        = {10.1007/s10257-024-00688-w},
    issn       = {1617-9846, 1617-9854},
    journal    = {Information Systems and e-Business Management},
    langid     = {english},
    month      = aug,
    shorttitle = {Prescriptive Analytics Systems Revised},
    title      = {Prescriptive Analytics Systems Revised: A Systematic Literature Review from an Information Systems Perspective},
    year       = {2024},
}


@article{Wang2022,
    author  = {Wang, Yifan and Chen, Jie and Zhang, Qi},
    doi     = {10.1109/TIFS.2022.3176577},
    journal = {IEEE Transactions on Information Forensics and Security},
    pages   = {2158--2171},
    title   = {Knowledge Distillation Technique for Cybersecurity Applications},
    volume  = {17},
    year    = {2022},
}

@article{Manivannan202350,
    author            = {Manivannan, K. and Suresh, T. and Parthiban, M.},
    doi               = {10.14445/22315381/IJETT-V71I12P206},
    journal           = {International Journal of Engineering Trends and Technology},
    note              = {Cited by: 1},
    number            = {12},
    pages             = {241--250},
    publication_stage = {Final},
    source            = {Scopus},
    title             = {Big Data Analytics Assisted Arithmetic Optimization with Deep Learning Model for Sentiment Classification},
    type              = {Article},
    url               = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85180339333&doi=10.14445%2f22315381%2fIJETT-V71I12P206&partnerID=40&md5=892176e1bddeecd8340970a0a8687114},
    volume            = {71},
    year              = {2023},
}


@article{Li2020101765,
    author     = {Li, Xiaoxiao and Gu, Yufeng and Dvornek, Nicha and Staib, Lawrence H. and Ventola, Pamela and Duncan, James S.},
    doi        = {10.1016/j.media.2020.101765},
    issn       = {13618415},
    journal    = {Medical Image Analysis},
    langid     = {english},
    month      = oct,
    pages      = {101765},
    shorttitle = {Multi-Site {{fMRI}} Analysis Using Privacy-Preserving Federated Learning and Domain Adaptation},
    title      = {Multi-Site {{fMRI}} Analysis Using Privacy-Preserving Federated Learning and Domain Adaptation: {{ABIDE}} Results},
    volume     = {65},
    year       = {2020},
}


@article{Zheng2019147755,
    author    = {Zheng, Shangfei and Liu, Hong},
    copyright = {https://creativecommons.org/licenses/by/4.0/legalcode},
    doi       = {10.1109/ACCESS.2019.2946659},
    issn      = {2169-3536},
    journal   = {IEEE Access},
    pages     = {147755--147770},
    title     = {Improved {{Multi-Agent Deep Deterministic Policy Gradient}} for {{Path Planning-Based Crowd Simulation}}},
    volume    = {7},
    year      = {2019},
}


@article{Hassan2022,
    author  = {Hassan, Mohammed and Ali, Ahmed and Kamal, Mostafa},
    doi     = {10.3390/rs14051132},
    journal = {Remote Sensing},
    number  = {5},
    pages   = {1132},
    title   = {Optimized Deep Learning for Remote Sensing Data Analysis},
    volume  = {14},
    year    = {2022},
}


@article{Nagaraju2022,
    author            = {Nagaraju, Regonda and Pentang, Jupeth Toriano and Abdufattokhov, Shokhjakhon and CosioBorda, Ricardo Fernando and Mageswari, N. and Uganya, G.},
    doi               = {10.1016/j.measen.2022.100431},
    journal           = {Measurement: Sensors},
    note              = {Cited by: 14; All Open Access, Gold Open Access, Green Open Access},
    publication_stage = {Final},
    source            = {Scopus},
    title             = {Attack prevention in IoT through hybrid optimization mechanism and deep learning framework},
    type              = {Article},
    url               = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85137276875&doi=10.1016%2fj.measen.2022.100431&partnerID=40&md5=236310a5fbe7f2fee311b3dccea0846e},
    volume            = {24},
    year              = {2022},
}


@article{Kumar2023,
    author  = {Kumar, Sanjay and Singh, Rahul and Gupta, Alok},
    doi     = {10.1016/j.compbiolchem.2023.107711},
    journal = {Computational Biology and Chemistry},
    pages   = {107711},
    title   = {Optimized Deep Learning for Genomic Data Analysis},
    volume  = {104},
    year    = {2023},
}


@article{Shin20201459,
    author     = {Shin, Donghyuk and He, Shu and Lee, Gene Moo and Whinston, Andrew B. and Cetintas, Suleyman and Lee, Kuang-Chih},
    doi        = {10.25300/MISQ/2020/14870},
    issn       = {02767783, 21629730},
    journal    = {MIS Quarterly},
    month      = dec,
    number     = {4},
    pages      = {1459--1492},
    shorttitle = {Enhancing {{Social Media Analysis}} with {{Visual Data Analytics}}},
    title      = {Enhancing {{Social Media Analysis}} with {{Visual Data Analytics}}: {{A Deep Learning Approach}}},
    volume     = {44},
    year       = {2020},
}


@article{Dash2023,
    author  = {Dash, Satyabrata and Acharya, Binita and Mittal, Amit},
    doi     = {10.1002/ijfe.2463},
    journal = {International Journal of Finance {\&} Economics},
    number  = {3},
    pages   = {2837--2851},
    title   = {Sentiment Analysis for Market Prediction},
    volume  = {28},
    year    = {2023},
}


@article{Sankaran20223005,
    author  = {Sankaran, Krishnan Sakthidasan and Lim, Se-Jung and Bhaskar, Seelam Ch Vijaya},
    doi     = {10.1007/s11600-022-00925-1},
    issn    = {1895-7455},
    journal = {Acta Geophysica},
    langid  = {english},
    month   = oct,
    number  = {6},
    pages   = {3005--3021},
    title   = {An Automated Prediction of Remote Sensing Data of {{Queensland-Australia}} for Flood and Wildfire Susceptibility Using {{BISSOA-DBMLA}} Scheme},
    volume  = {70},
    year    = {2022},
}


@article{Ghosh2022,
    author  = {Ghosh, Saptarshi and Das, Arindam and Sen, Souvik},
    doi     = {10.1016/j.eswa.2022.117200},
    journal = {Expert Systems with Applications},
    pages   = {117200},
    title   = {Transfer Learning for Domain Adaptation in Finance},
    volume  = {202},
    year    = {2022},
}


@article{hassib2020woa,
    author    = {Hassib, Eslam M and El-Desouky, Ali I and Labib, Labib M and El-Kenawy, El-Sayed M},
    journal   = {Soft Computing},
    number    = {8},
    pages     = {5573--5592},
    publisher = {Springer},
    title     = {WOA+ BRNN: An imbalanced big data classification framework using Whale optimization and deep neural network},
    volume    = {24},
    year      = {2020},
}


@inproceedings{Liu20211735Conf,
    abstract   = {The growing attention on location-based services has promoted the development of indoor localization studies. Existing techniques mainly use Received Signal Strength Indicator (RSSI) of wireless signals as location fingerprint. Inspired by deep learning techniques for signal processing, we propose a deep neural network-based framework (DeepLoc) to implement Wi-Fi fingerprint positioning. In order to improve localization performance, we further design a network division based optimization algorithm. We first adopt greedy algorithm to locate the user in a sub-area, and then reconstruct a smaller fingerprint database, which is fed into the training model. Finally, we evaluate the proposed framework. Experimental results show that DeepLoc can improve the localization accuracy efficiently and obtain better performance.},
    author     = {Liu, Saining and Ren, Qianqian and Li, Jinbao and Xu, Hui},
    booktitle  = {2021 {{IEEE}} 23rd {{Int Conf}} on {{High Performance Computing}} {\&} {{Communications}}; 7th {{Int Conf}} on {{Data Science}} {\&} {{Systems}}; 19th {{Int Conf}} on {{Smart City}}; 7th {{Int Conf}} on {{Dependability}} in {{Sensor}}, {{Cloud}} {\&} {{Big Data Systems}} {\&} {{Application}} ({{HPCC}}/{{DSS}}/{{SmartCity}}/{{DependSys}})},
    doi        = {10.1109/HPCC-DSS-SmartCity-DependSys53884.2021.00255},
    keywords   = {deep learning,Deep learning,Fingerprint recognition,greedy algorithm,Greedy algorithms,Location awareness,positioning,Received signal strength indicator,Signal processing algorithms,sub-area,Training},
    month      = dec,
    pages      = {1735--1740},
    shorttitle = {{{DeepLoc}}},
    title      = {{{DeepLoc}}: {{A Deep Neural Network-based Indoor Positioning Framework}}},
    year       = {2021},
}


@article{Yu20221355,
    abstract   = {Advancing the quality of healthcare for senior citizens with chronic conditions is of great social relevance. To better manage chronic conditions, objective, convenient, and inexpensive wearable sensor- based information systems (IS) have been increasingly used by researchers and practitioners. However, existing models often focus on a single aspect of chronic conditions and are often ``black boxes with limited interpretability. In this research, we adopt the computational design science paradigm and propose a novel adversarial attention-based deep multisource multitask learning (AADMML) framework. Drawing upon deep learning, multitask learning, multisource learning, attention mechanism, and adversarial learning, AADMML addresses limitations with existing wearable sensor-based chronic condition severity assessment methods. Choosing Parkinsons disease (PD) as our test case because of its prevalence and societal significance, we conduct benchmark experiments to evaluate AADMML against state-of-the-art models on a large-scale dataset containing thousands of instances. We present three case studies to demonstrate the practical utility and economic benefits of AADMML and by applying it to detect early-stage PD. We discuss how our work is related to the IS knowledge base and its practical implications. This work can contribute to improved life quality for senior citizens and advance IS research in mobile health analytics.},
    author     = {Yu, Shuo and Chai, Yidong and Chen, Hsinchun and Sherman, Scott and Brown, Randall},
    doi        = {10.25300/MISQ/2022/15763},
    issn       = {02767783},
    journal    = {MIS Quarterly},
    month      = sep,
    number     = {3},
    pages      = {1355--1394},
    shorttitle = {Wearable {{Sensor-Based Chronic Condition Severity Assessment}}},
    title      = {Wearable {{Sensor-Based Chronic Condition Severity Assessment}}: {{An Adversarial Attention-Based Deep Multisource Multitask Learning Approach}}},
    volume     = {45},
    year       = {2022},
}


@article{Tan2022,
    author  = {Tan, Mingxing and Chen, Bo and Li, Peng},
    journal = {Journal of Machine Learning Research},
    number  = {103},
    pages   = {1--35},
    title   = {Optimization Techniques for Distributed Training of Large Language Models},
    volume  = {23},
    year    = {2022},
}

@article{Chen2022,
    author    = {Chen, J. and Zhang, X. and Luo, Y. and Wu, T. and Zhao, D.},
    journal   = {JACC: Advances},
    number    = {2},
    pages     = {100--112},
    publisher = {Elsevier},
    title     = {Deep learning-based electronic health record analysis for clinical decision support in cardiovascular medicine},
    volume    = {1},
    year      = {2022},
}

@article{Kanchanamala20232414,
    author    = {Kanchanamala, K. and Rao, P.V. and Guntuku, S.C.},
    journal   = {Expert Systems with Applications},
    pages     = {119611},
    publisher = {Elsevier},
    title     = {Exponential Chimp Optimization Algorithm for optimizing deep neuro-fuzzy networks in MapReduce frameworks for fake news detection},
    volume    = {217},
    year      = {2023},
}

@article{Liu20211735,
    author    = {Liu, Y. and Zhao, T. and Wang, W. and Liu, X.},
    journal   = {IEEE Internet of Things Journal},
    number    = {3},
    pages     = {1735--1747},
    publisher = {IEEE},
    title     = {Energy-efficient deep learning on edge devices: Hardware-aware optimization framework},
    volume    = {8},
    year      = {2021},
}

@article{Ahmed2023,
    author    = {Ahmed, R. and Khan, M.A. and Ali, S. and Kumar, N.},
    journal   = {Neural Computing and Applications},
    number    = {8},
    pages     = {5672--5688},
    publisher = {Springer},
    title     = {Cuckoo search optimization for hyperparameter tuning in deep learning security models},
    volume    = {35},
    year      = {2023},
}

@article{Rahman2022,
    author    = {Rahman, A. and Nasir, M. and Hasan, K. and Liu, J.},
    journal   = {Journal of Network and Computer Applications},
    pages     = {103217},
    publisher = {Elsevier},
    title     = {Feature selection with Cuckoo Search for malware classification in IoT environments},
    volume    = {194},
    year      = {2022},
}

@article{Gupta2020,
    author    = {Gupta, V. and Rani, R. and Kumar, V.},
    journal   = {Applied Intelligence},
    number    = {11},
    pages     = {4058--4080},
    publisher = {Springer},
    title     = {Neural architecture search using Cuckoo optimization for deep learning applications},
    volume    = {50},
    year      = {2020},
}

@article{Sharma2022,
    author    = {Sharma, A. and Sharma, D. and Panigrahi, B.K.},
    journal   = {Knowledge-Based Systems},
    pages     = {108120},
    publisher = {Elsevier},
    title     = {Solving combinatorial optimization problems with exponential chimp optimization algorithm},
    volume    = {240},
    year      = {2022},
}

@article{Heidari20191,
    author    = {Heidari, A.A. and Faris, H. and Mirjalili, S. and Aljarah, I.},
    journal   = {Cluster Computing},
    pages     = {10357--10373},
    publisher = {Springer},
    title     = {Whale Optimization Algorithm for clustering big data in MapReduce environments},
    volume    = {22},
    year      = {2019},
}

@article{Kumar2021,
    author    = {Kumar, R. and Sharma, R.K. and Vadhera, S.},
    journal   = {Journal of Big Data},
    number    = {1},
    pages     = {1--23},
    publisher = {Springer},
    title     = {Feature selection using whale optimization and deep neural networks for big data analytics},
    volume    = {8},
    year      = {2021},
}

@article{Aljarah2022,
    author    = {Aljarah, I. and Mafarja, M. and Heidari, A.A. and Faris, H.},
    journal   = {Knowledge-Based Systems},
    pages     = {108240},
    publisher = {Elsevier},
    title     = {Multi-objective whale optimization for large-scale feature selection problems},
    volume    = {241},
    year      = {2022},
}

@article{Chen20221,
    author    = {Chen, H. and Yang, J. and Li, C. and Wang, M.},
    journal   = {Applied Soft Computing},
    pages     = {108948},
    publisher = {Elsevier},
    title     = {Gravitational search algorithm for parameter optimization in deep reinforcement learning},
    volume    = {123},
    year      = {2022},
}

@article{Mirjalili2020,
    author    = {Mirjalili, S. and Gandomi, A.H. and Mirjalili, S.Z. and Saremi, S.},
    journal   = {Computer Methods in Applied Mechanics and Engineering},
    pages     = {112583},
    publisher = {Elsevier},
    title     = {Multi-objective gravitational search algorithm for engineering optimization problems},
    volume    = {357},
    year      = {2020},
}

@article{Das2022,
    author    = {Das, S. and Kar, S. and Srivastava, G. and Mafarja, M.},
    journal   = {Expert Systems with Applications},
    pages     = {117258},
    publisher = {Elsevier},
    title     = {Adaptive gravitational search algorithm for noisy optimization environments},
    volume    = {202},
    year      = {2022},
}

@article{Wang20232325,
    author    = {Wang, J. and Zhang, L. and Zhao, H. and Qian, Y.},
    journal   = {Information Sciences},
    pages     = {2325--2348},
    publisher = {Elsevier},
    title     = {Neural architecture search using genetic algorithms for deep learning model design},
    volume    = {615},
    year      = {2023},
}

@article{Liu2020,
    author    = {Liu, Y. and Sun, Y. and Wu, P.},
    journal   = {Neural Networks},
    pages     = {249--259},
    publisher = {Elsevier},
    title     = {Multi-objective genetic algorithm for hyperparameter optimization in deep learning models},
    volume    = {125},
    year      = {2020},
}

@article{Kim2021,
    author    = {Kim, S. and Kim, H. and Yoon, M.},
    journal   = {Applied Sciences},
    number    = {4},
    pages     = {1523},
    publisher = {MDPI},
    title     = {Ensemble model generation using genetic algorithms for deep learning},
    volume    = {11},
    year      = {2021},
}

@article{Rao2021,
    author    = {Rao, R.V. and Patel, V.},
    journal   = {Engineering Optimization},
    number    = {2},
    pages     = {319--337},
    publisher = {Taylor \& Francis},
    title     = {Teaching-learning-based optimization for constrained engineering design problems},
    volume    = {53},
    year      = {2021},
}

@article{Satapathy2022,
    author    = {Satapathy, S.C. and Naik, A. and Parvathi, K.},
    journal   = {Applied Soft Computing},
    pages     = {108422},
    publisher = {Elsevier},
    title     = {Improved teaching-learning-based optimization for multi-modal optimization problems},
    volume    = {118},
    year      = {2022},
}

@article{Singh2021,
    author    = {Singh, P. and Chaudhari, S. and Sharma, T.K.},
    journal   = {Neural Computing and Applications},
    pages     = {12631--12646},
    publisher = {Springer},
    title     = {Hyperparameter tuning using differential evolution for convolutional neural networks},
    volume    = {33},
    year      = {2021},
}

@article{Das2021,
    author    = {Das, P.K. and Behera, H.S. and Panigrahi, B.K.},
    journal   = {Applied Intelligence},
    pages     = {7978--7996},
    publisher = {Springer},
    title     = {Adaptive parameter control in differential evolution for neural network training},
    volume    = {51},
    year      = {2021},
}

@article{Wang2020,
    author    = {Wang, D. and Tan, D. and Liu, L.},
    journal   = {Information Sciences},
    number    = {20},
    pages     = {4514--4532},
    publisher = {Elsevier},
    title     = {Hybrid differential evolution and particle swarm optimization for complex optimization problems},
    volume    = {181},
    year      = {2020},
}

@article{Srivatsan20234723,
    author    = {Srivatsan, R. and Manimaran, J. and Thirumaran, M.},
    journal   = {Journal of Supercomputing},
    pages     = {4723--4744},
    publisher = {Springer},
    title     = {Feature selection for big data using particle swarm optimization variants},
    volume    = {79},
    year      = {2023},
}

@article{Kennedy2022,
    author    = {Kennedy, J. and Mendes, R. and Banks, A.},
    journal   = {Swarm Intelligence},
    pages     = {29--53},
    publisher = {Springer},
    title     = {Dynamic particle swarm optimization for time-varying objective functions},
    volume    = {16},
    year      = {2022},
}

@article{Zhang2020,
    author    = {Zhang, Y. and Wang, S. and Ji, G.},
    journal   = {Soft Computing},
    pages     = {11987--12007},
    publisher = {Springer},
    title     = {Adaptive particle swarm optimization for high-dimensional problems},
    volume    = {24},
    year      = {2020},
}

@article{Zhou20221,
    author    = {Zhou, A. and Wang, Y. and Hang, W. and Liu, S.},
    journal   = {IEEE Transactions on Neural Networks and Learning Systems},
    number    = {11},
    pages     = {6281--6292},
    publisher = {IEEE},
    title     = {Bayesian optimization for neural architecture search in high-cost evaluation scenarios},
    volume    = {33},
    year      = {2022},
}

@article{Snoek2021,
    author  = {Snoek, J. and Rippel, O. and Swersky, K. and Kiros, R. and Satish, N.},
    journal = {Advances in Neural Information Processing Systems},
    pages   = {12449--12460},
    title   = {Multi-fidelity Bayesian optimization for hyperparameter tuning},
    volume  = {34},
    year    = {2021},
}

@article{Frazier2022,
    author    = {Frazier, P.I. and Clark, S.C. and Molinaro, M. and Wang, J.},
    journal   = {Journal of Global Optimization},
    pages     = {389--415},
    publisher = {Springer},
    title     = {Parallel Bayesian optimization for expensive function evaluations},
    volume    = {82},
    year      = {2022},
}

@article{Li20212467,
    author    = {Li, K. and Malik, J. and Ren, W.},
    journal   = {Neural Networks},
    pages     = {167--178},
    publisher = {Elsevier},
    title     = {Learning to optimize: A meta-learning approach for gradient-based optimizers},
    volume    = {140},
    year      = {2021},
}

@article{Andrychowicz2021,
    author  = {Andrychowicz, M. and Denil, M. and Gomez, S. and Hoffman, M.W. and Pfau, D. and Schaul, T. and Shillingford, B. and de Freitas, N.},
    journal = {Advances in Neural Information Processing Systems},
    pages   = {3981--3989},
    title   = {Learning to learn by gradient descent by gradient descent},
    volume  = {34},
    year    = {2021},
}

@article{Chen2020,
    author  = {Chen, X. and Liu, S. and Sun, R. and Hong, M.},
    journal = {Proceedings of the 37th International Conference on Machine Learning},
    pages   = {1055--1064},
    title   = {Neural optimizers with hypergradients for tuning parameter-wise learning rates},
    year    = {2020},
}

@article{Ghahramani2015,
    author  = {Ghahramani, Zoubin},
    doi     = {10.1038/nature14541},
    journal = {Nature},
    number  = {7553},
    pages   = {452--459},
    title   = {Probabilistic machine learning and artificial intelligence},
    volume  = {521},
    year    = {2015},
}

@article{LeCun2015,
    author  = {LeCun, Yann and Bengio, Yoshua and Hinton, Geoffrey},
    doi     = {10.1038/nature14539},
    journal = {Nature},
    number  = {7553},
    pages   = {436--444},
    title   = {Deep learning},
    volume  = {521},
    year    = {2015},
}

@book{Back1996,
    author    = {B{\"a}ck, Thomas},
    doi       = {10.1093/oso/9780195099713.001.0001},
    publisher = {Oxford University Press},
    title     = {Evolutionary Algorithms in Theory and Practice},
    year      = {1996},
}

@article{Hinton2015,
    author  = {Hinton, Geoffrey and Vinyals, Oriol and Dean, Jeff},
    journal = {arXiv preprint arXiv:1503.02531},
    title   = {Distilling the Knowledge in a Neural Network},
    year    = {2015},
}

@article{Narayanan2021,
    author  = {Narayanan, Deepak and Shoeybi, Mohammad and Casper, Jared and LeGresley, Patrick and Patwary, Mostofa and Korthikanti, Vijay and Vainbrand, Dmitri and Kashinkunti, Prethvi and Bernauer, Julie and Catanzaro, Bryan},
    journal = {arXiv preprint arXiv:2104.04473},
    title   = {Efficient large-scale language model training on GPU clusters using Megatron-LM},
    year    = {2021},
}

@inproceedings{Alistarh2017,
    author    = {Alistarh, Dan and Grubic, Demjan and Li, Jerry and Tomioka, Ryota and Vojnovic, Milan},
    booktitle = {Advances in Neural Information Processing Systems},
    pages     = {1709--1720},
    title     = {QSGD: Communication-efficient SGD via gradient quantization and encoding},
    volume    = {30},
    year      = {2017},
}

@article{najafabadi2015deep,
    author    = {Najafabadi, Maryam Mohammadi and Villanustre, Flavio and Khoshgoftaar, Taghi M and Seliya, N and Wald, Richard and Muharemagic, Edin},
    journal   = {Journal of Big Data},
    number    = {1},
    pages     = {1-21},
    publisher = {Springer},
    title     = {Deep learning applications and challenges in big data analytics},
    volume    = {2},
    year      = {2015},
}

@article{furht2016deep,
  title={Deep learning techniques in big data analytics},
  author={Furht, Borko and Villanustre, Flavio and Najafabadi, Maryam M and Villanustre, Flavio and Khoshgoftaar, Taghi M and Seliya, Naeem and Wald, Randall and Muharemagc, Edin},
  journal={Big Data Technologies and Applications},
  pages={133--156},
  year={2016},
  publisher={Springer}
}

@article{choudhary2022recent,
  title={Recent advances and applications of deep learning methods in materials science},
  author={Choudhary, Kamal and DeCost, Brian and Chen, Chi and Jain, Anubhav and Tavazza, Francesca and Cohn, Ryan and Park, Cheol Woo and Choudhary, Alok and Agrawal, Ankit and Billinge, Simon JL and others},
  journal={npj Computational Materials},
  volume={8},
  number={1},
  pages={59},
  year={2022},
  publisher={Nature Publishing Group UK London}
}

@article{thompson2020computational,
  title={The computational limits of deep learning},
  author={Thompson Neil, C and Kristjan, Greenewald and Keeheon, Lee and Manso Gabriel, F},
  journal={ArXiv, Cornell University, juillet},
  year={2020}
}

@article{mayer2020scalable,
  title={Scalable deep learning on distributed infrastructures: Challenges, techniques, and tools},
  author={Mayer, Ruben and Jacobsen, Hans-Arno},
  journal={ACM Computing Surveys (CSUR)},
  volume={53},
  number={1},
  pages={1--37},
  year={2020},
  publisher={ACM New York, NY, USA}
}

@article{capra2020hardware,
  title={Hardware and software optimizations for accelerating deep neural networks: Survey of current trends, challenges, and the road ahead},
  author={Capra, Maurizio and Bussolino, Beatrice and Marchisio, Alberto and Masera, Guido and Martina, Maurizio and Shafique, Muhammad},
  journal={IEEE Access},
  volume={8},
  pages={225134--225180},
  year={2020},
  publisher={IEEE}
}

@book{yan2023computational,
    author    = {Yan, Wei Qi},
    publisher = {Springer Nature},
    title     = {Computational Methods for Deep Learning: Theory, Algorithms, and Implementations},
    year      = {2023},
}

@article{zhang2023distributed,
    author    = {Zhang, Hongming and Dehghani, M and Yazdanparast, Z},
    journal   = {Journal of Big Data},
    number    = {1},
    pages     = {158},
    publisher = {Springer},
    title     = {From distributed machine to distributed deep learning: a comprehensive survey},
    volume    = {10},
    year      = {2023},
}

@article{li2019federated,
    author    = {Li, Tian and Sahu, Abhishek Kumar and Talwalkar, Ameet and Smith, Virginia},
    journal   = {IEEE Signal Processing Magazine},
    number    = {3},
    pages     = {50-60},
    publisher = {IEEE},
    title     = {Federated learning: Challenges, methods, and future directions},
    volume    = {37},
    year      = {2019},
}

@article{li2020survey,
    author    = {Li, Xia and Liu, Yang and Li, Tian and Qin, Hong},
    journal   = {Journal of Big Data},
    number    = {1},
    pages     = {1-41},
    publisher = {Springer},
    title     = {A survey on scalable deep learning techniques},
    volume    = {7},
    year      = {2020},
}

@article{ben2019demystifying,
    author    = {Ben, Simon and Waller, Jenna},
    journal   = {Artificial Intelligence Review},
    number    = {4},
    pages     = {3197-3225},
    publisher = {Springer},
    title     = {Demystifying deep learning optimization in big data contexts},
    volume    = {53},
    year      = {2019},
}

@incollection{bengio2012practical,
    author    = {Bengio, Yoshua},
    booktitle = {Neural networks: Tricks of the trade: Second edition},
    pages     = {437--478},
    publisher = {Springer},
    title     = {Practical recommendations for gradient-based training of deep architectures},
    year      = {2012},
}

@article{krizhevsky2012imagenet,
    author  = {Krizhevsky, Alex and Sutskever, Ilya and Hinton, Geoffrey E},
    journal = {Advances in neural information processing systems},
    title   = {Imagenet classification with deep convolutional neural networks},
    volume  = {25},
    year    = {2012},
}

@article{dean2012large,
    author  = {Dean, Jeffrey and Corrado, Greg and Monga, Rajat and Chen, Kai and Devin, Matthieu and Mao, Mark and Ranzato, Marc'aurelio and Senior, Andrew and Tucker, Paul and Yang, Ke and others},
    journal = {Advances in neural information processing systems},
    title   = {Large scale distributed deep networks},
    volume  = {25},
    year    = {2012},
}

@article{shazeer2017outrageously,
    author  = {Shazeer, Noam and Mirhoseini, Azalia and Maziarz, Krzysztof and Davis, Andy and Le, Quoc and Hinton, Geoffrey and Dean, Jeff},
    journal = {arXiv preprint arXiv:1701.06538},
    title   = {Outrageously large neural networks: The sparsely-gated mixture-of-experts layer},
    year    = {2017},
}

@article{you2019large,
    author  = {You, Yang and Li, Jing and Reddi, Sashank and Hseu, Jonathan and Kumar, Sanjiv and Bhojanapalli, Srinadh and Song, Xiaodan and Demmel, James and Keutzer, Kurt and Hsieh, Cho-Jui},
    journal = {arXiv preprint arXiv:1904.00962},
    title   = {Large batch optimization for deep learning: Training bert in 76 minutes},
    year    = {2019},
}

@article{kitchenham2004procedures,
    author    = {Kitchenham, Barbara},
    journal   = {Keele, UK, Keele University},
    number    = {2004},
    pages     = {1--26},
    publisher = {Citeseer},
    title     = {Procedures for performing systematic reviews},
    volume    = {33},
    year      = {2004},
}

@article{cooper1988organizing,
    author    = {Cooper, Harris M},
    journal   = {Knowledge in society},
    number    = {1},
    pages     = {104},
    publisher = {Springer},
    title     = {Organizing knowledge syntheses: A taxonomy of literature reviews},
    volume    = {1},
    year      = {1988},
}

@article{singh2013critical,
    author    = {Singh, Jatinder},
    journal   = {Journal of pharmacology and Pharmacotherapeutics},
    number    = {1},
    pages     = {76--77},
    publisher = {SAGE Publications Sage India: New Delhi, India},
    title     = {Critical appraisal skills programme},
    volume    = {4},
    year      = {2013},
}

@article{diebold2012origin,
    author    = {Diebold, Francis X},
    publisher = {PIER Working Paper},
    title     = {On the Origin (s) and Development of the Term'Big Data'},
    year      = {2012},
}

@article{kitchin2016makes,
    author    = {Kitchin, Rob and McArdle, Gavin},
    journal   = {Big data \& society},
    number    = {1},
    pages     = {2053951716631130},
    publisher = {SAGE Publications Sage UK: London, England},
    title     = {What makes Big Data, Big Data? Exploring the ontological characteristics of 26 datasets},
    volume    = {3},
    year      = {2016},
}

@article{zhang2021distributed,
  title={Distributed deep learning on data systems: a comparative analysis of approaches},
  author={Zhang, Yuhao and Mcquillan, Frank and Jayaram, Nandish and Kak, Nikhil and Khanna, Ekta and Kislal, Orhan and Valdano, Domino and Kumar, Arun},
  journal={Proceedings of the VLDB Endowment},
  volume={14},
  number={10},
  year={2021}
}

@article{thoppil2022bayesian,
  title={Bayesian optimization LSTM/bi-LSTM network with self-optimized structure and hyperparameters for remaining useful life estimation of lathe spindle unit},
  author={Thoppil, Nikhil M and Vasu, Velagapudi and Rao, CSP},
  journal={Journal of Computing and Information Science in Engineering},
  volume={22},
  number={2},
  pages={021012},
  year={2022},
  publisher={American Society of Mechanical Engineers}
}