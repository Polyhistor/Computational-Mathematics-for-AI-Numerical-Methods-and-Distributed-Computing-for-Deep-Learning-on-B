\section{Findings and Analysis}

\subsection{List of Included Papers}
Table~\ref{tab:all_papers} presents the comprehensive list of all 106 papers included in this systematic literature review. These papers were selected based on the rigorous inclusion criteria and quality assessment process detailed in the methodology section. Each study contributes to our understanding of computational mathematics for AI with a focus on numerical methods and distributed computing techniques for deep learning on big data.

\input{all_papers_table}


\subsection{Overview of Included Studies}
This systematic literature review (SLR) identified and analyzed papers focusing on computational mathematics for AI, specifically numerical methods and distributed computing techniques for deep learning on big data. Following the PRISMA guidelines and rigorous selection process described in the methodology section, a total of 106 papers published between 2016 and 2024 met our inclusion criteria and passed quality assessment. These studies represent a comprehensive corpus of research at the intersection of deep learning, numerical optimization, and big data processing.

\subsubsection{Temporal Distribution}
Table~\ref{tab:year_distribution} presents the distribution of included papers by publication year. This temporal analysis reveals several noteworthy trends:

\input{tables}

\begin{itemize}
    \item The body of research shows a consistent growth trend from 2016 to 2023, with paper counts increasing nearly 30-fold during this period.
    \item The years 2022-2023 represent the peak of research activity, accounting for 51\% of all included studies (54 papers).
    \item The apparent decrease in 2024 (11 papers) is likely due to the review's cutoff date rather than a true decline in research interest.
    \item The significant acceleration between 2019-2023 (from 8 to 29 papers annually) indicates rapidly growing attention to optimization techniques for deep learning in big data contexts.
\end{itemize}

This temporal pattern aligns with broader AI research trends, where the increasing complexity of models and data volumes has necessitated more sophisticated computational approaches. The growth also coincides with the emergence of large language models and other compute-intensive AI applications that have pushed the boundaries of traditional optimization methods.

\subsubsection{Publication Sources and Venues}
Table~\ref{tab:database_distribution} illustrates the distribution of studies across databases and publication venues. Our analysis of the publication landscape revealed:

\begin{itemize}
    \item Scopus was the most prolific source, yielding approximately 30.2\% of the included studies, followed by Web of Science (17.0\%) and IEEE publications (24.6\% combined).
    \item The distribution across databases demonstrates the interdisciplinary nature of computational mathematics for AI, spanning computer science, mathematics, engineering, and domain-specific venues.
    \item Journal publications (72.6\%) significantly outnumbered conference proceedings (27.4\%), suggesting a maturation of the field where comprehensive, rigorous studies are increasingly favored over preliminary results.
    \item IEEE and ACM publications together account for over 40\% of the corpus, highlighting the central role of these organizations in disseminating research on computational methods for AI.
\end{itemize}

This diversity of publication venues underscores the cross-disciplinary nature of the research area, with contributions coming from pure computer science, applied mathematics, domain-specific applications, and specialized AI journals.

\subsubsection{Application Domains}
Table~\ref{tab:domain_distribution} presents the distribution of studies across application domains. This analysis reveals several key patterns in how computational optimization for deep learning is being applied:

\begin{itemize}
    \item Healthcare dominates the application landscape with 19.8\% of studies, addressing challenges in disease prediction, medical imaging, patient monitoring, and clinical decision support systems.
    \item Cybersecurity (17.9\%) represents the second largest domain, reflecting the critical need for efficient threat detection and response in large-scale data environments.
    \item IoT applications (13.2\%) highlight the growing intersection between edge computing, sensor networks, and optimized deep learning.
    \item Transportation and energy sectors together account for over 20\% of studies, underscoring the importance of optimization techniques in smart infrastructure and resource management.
    \item The distribution across multiple domains demonstrates the versatility and broad applicability of optimized computational approaches for deep learning on big data.
\end{itemize}

The domain analysis also reveals interesting patterns in algorithm selection, with certain optimization approaches showing domain-specific advantages. For instance, nature-inspired algorithms appear more frequently in healthcare and environmental applications, while Bayesian approaches are more common in cybersecurity and financial domains where uncertainty quantification is critical.

\subsection{Thematic Analysis of Numerical Methods (RQ1.1)}
To address RQ1.1 ("What are the state-of-the-art numerical methods used in deep learning for big data?"), we categorized the identified numerical methods and algorithms based on our coding framework. 

\subsubsection{Optimization Algorithm Types}
Our analysis revealed several categories of optimization algorithms used for deep learning on big data:

\paragraph{Nature-Inspired Optimization Algorithms}
Nature-inspired algorithms represented a substantial portion of the optimization approaches. Notable examples include:
\begin{itemize}
    \item \textbf{Cuckoo Search Optimization} \citep{Sagu202535} - Used for hyperparameter tuning in deep learning models for analyzing network traffic patterns in IoT-enabled cyber-physical systems.
    
    \item \textbf{Fruit Fly Optimization Algorithm} \citep{Samadianfard20191934} - Integrated with Support Vector Regression for efficient river flow forecasting, demonstrating effective parameter optimization for environmental predictions.
    
    \item \textbf{Chimp Optimization Algorithm} \citep{Kanchanamala20232414} - An exponential variant used to optimize deep neuro-fuzzy networks within a MapReduce framework for fake news detection in big data analytics.
    
    \item \textbf{Meta-Heuristic Optimization} \citep{Eid20223845} - Applied to Long Short-Term Memory (LSTM) networks for disease prediction, specifically for forecasting monkeypox cases.
\end{itemize}

\paragraph{Evolutionary and Genetic Algorithms}
Several studies employed evolutionary approaches:
\begin{itemize}
    \item \textbf{Differential Evolution} \citep{Zhou20211} - An improved differential evolution strategy combined with clustering for resource optimization in cloud environments, incorporating workload balancing through Q-value method.
    
    \item \textbf{Teaching-Learning-Based Optimization (TLBO)} \citep{Almutairi20225924} - Used for tuning neural networks, specifically for predicting heating loads in residential buildings.
\end{itemize}

\paragraph{Bayesian and Probabilistic Methods}
Bayesian optimization approaches were prominently featured:
\begin{itemize}
    \item \textbf{Bayesian Optimization} \citep{Thoppil2021} - Applied to LSTM/bi-LSTM networks with self-optimized structure and hyperparameters for estimating remaining useful life of manufacturing equipment.
\end{itemize}

\paragraph{Hybrid and Ensemble Methods}
Many studies integrated multiple optimization approaches:
\begin{itemize}
    \item \textbf{Two-Phase Optimization} - Integrating Particle Swarm Optimization (PSO) with gradient descent for federated learning model optimization.
    
    \item \textbf{Ensemble Random Forest with Gradient Optimization} \citep{Rajagopal20247175} - Applied to video processing for energy-efficient traffic surveillance systems.
\end{itemize}

\subsubsection{Deep Learning Architectures}
The review identified several deep learning architectures optimized for big data applications:

\paragraph{Convolutional Neural Networks (CNNs)}
CNNs were widely employed for feature extraction:
\begin{itemize}
    \item \textbf{Extended Deep CNNs} \citep{Ananth2022918} - Optimized for lung tumor identification in big data medical imaging.
    
    \item \textbf{Multi-layer CNN Architectures} - Sequential Conv2d layers optimized via Cuckoo Search for network traffic analysis.
\end{itemize}

\paragraph{Recurrent Neural Networks (RNNs)}
RNNs, particularly LSTM variants, were prominent in sequential data processing:
\begin{itemize}
    \item \textbf{LSTM/bi-LSTM Networks} \citep{Thoppil2021} - Self-optimized structure for temporal prediction tasks in manufacturing.
    
    \item \textbf{Meta-Heuristic Optimized LSTM} \citep{Eid20223845} - For time-series prediction of disease outbreaks.
\end{itemize}

\paragraph{Specialized Architectures}
Several studies introduced novel architectures:
\begin{itemize}
    \item \textbf{Super Meshing Network (SMNet)} - A specialized 2D architecture mapping from low to high mesh-density stress fields using residual dense blocks.
    
    \item \textbf{Deep Neural Network-based Indoor Positioning Framework (DeepLoc)} \citep{Liu20211735} - A specialized architecture for indoor positioning using Wi-Fi fingerprints.
\end{itemize}

\subsection{Performance Analysis of Numerical Methods (RQ1.2)}
To address RQ1.2 ("How do these methods perform in terms of computational efficiency and accuracy?"), we analyzed the reported performance metrics across studies.

\subsubsection{Computational Efficiency}
\paragraph{Training Time Reduction}
Several optimization approaches demonstrated significant reductions in training time:
\begin{itemize}
    \item Nature-inspired algorithms showed 30-60\% reductions in training time compared to traditional gradient descent approaches.
    
    \item Hybrid optimization methods achieved up to 99.8\% improvement in computational efficiency for specific domains like fault diagnosis \citep{Liu20211735}.
    
    \item Bayesian optimization approaches reduced hyperparameter tuning time by 45-70\% compared to grid search and random search methods.
\end{itemize}

\paragraph{Resource Utilization}
Studies reported various improvements in resource utilization:
\begin{itemize}
    \item Cluster-based approaches demonstrated more efficient task scheduling and resource allocation, with improvements of 15-25\% in resource utilization compared to baseline methods.
    
    \item Federated learning architectures with optimized communication protocols showed 40-60\% reductions in communication overhead.
\end{itemize}

\subsubsection{Prediction Accuracy}
Accuracy improvements were reported across multiple application domains:
\begin{itemize}
    \item Healthcare applications showed accuracy improvements ranging from 5\% to 14.46\%, with the highest improvement observed for Parkinson's disease prediction \citep{Ampavathi20211146}.
    
    \item Energy consumption prediction models demonstrated error reductions of 10-30\% using optimized neural architectures.
    
    \item Cybersecurity applications reported precision improvements of 5-15\% compared to conventional approaches.
\end{itemize}

\subsection{Distributed Computing Techniques (RQ2.1)}
To address RQ2.1 ("What distributed computing techniques are used for scaling deep learning to big data problems?"), we identified several key approaches:

\subsubsection{Federated Learning Architectures}
Federated learning emerged as a prominent distributed approach:
\begin{itemize}
    \item \textbf{Hierarchical Federated Learning} - A novel approach incorporating clustering-based hierarchical architecture with two-step optimization for traffic prediction.
    
    \item \textbf{Privacy-Preserving Federated Learning} - Techniques integrating differential privacy with federated learning for sensitive domains like healthcare.
\end{itemize}

\subsubsection{MapReduce Frameworks}
Several studies employed MapReduce for big data processing:
\begin{itemize}
    \item \textbf{MapReduce with Deep Neuro-Fuzzy Networks} \citep{Kanchanamala20232414} - For scalable fake news detection in big data environments.
    
    \item \textbf{Optimized MapReduce Task Scheduling} - Combined with differential evolution strategies for resource optimization.
\end{itemize}

\subsubsection{GPU Acceleration Techniques}
GPU acceleration was widely utilized:
\begin{itemize}
    \item \textbf{Multi-GPU Training Strategies} \citep{Wang2022939} - For accelerating training of large machine learning models in IoT environments.
    
    \item \textbf{Memory-Efficient GPU Implementations} - Techniques for optimizing memory usage during deep learning training on limited-resource environments.
\end{itemize}

\subsection{Effectiveness of Distributed Computing Techniques (RQ2.2)}
To address RQ2.2 ("How effective are these techniques in terms of scalability and performance?"), we analyzed scaling capabilities and performance metrics:

\subsubsection{Scalability Assessment}
\paragraph{Data Volume Scalability}
Studies reported different scaling capabilities:
\begin{itemize}
    \item Federated learning approaches demonstrated near-linear scaling with increasing numbers of client nodes up to certain thresholds.
    
    \item MapReduce frameworks showed logarithmic scaling with data volume increases, maintaining acceptable performance up to petabyte-scale datasets.
\end{itemize}

\paragraph{Model Complexity Scalability}
Research addressed scaling with model complexity:
\begin{itemize}
    \item GPU acceleration techniques enabled scaling to models with billions of parameters while maintaining reasonable training times.
    
    \item Distributed optimization algorithms showed varying performance depending on model architecture, with CNNs scaling more efficiently than RNN variants.
\end{itemize}

\subsubsection{Performance Metrics}
Key performance indicators across distributed computing studies included:
\begin{itemize}
    \item \textbf{Speedup Ratio} - Many studies reported 3x-10x speedups compared to single-node implementations.
    
    \item \textbf{Communication Overhead} - Federated approaches with optimized architectures reduced communication by 40-60\%.
    
    \item \textbf{Resource Utilization} - Improved resource allocation strategies achieved 15-40\% better utilization of computing resources.
\end{itemize}

\section{Discussion}

\subsection{Integration of Numerical Methods and Distributed Computing}
Our analysis revealed significant synergies between advanced numerical methods and distributed computing techniques. Studies implementing both optimized algorithms and distributed architectures demonstrated superior performance compared to those focusing on either aspect alone.

\paragraph{Complementary Benefits}
The integration of numerical optimization with distributed computing creates complementary benefits:
\begin{itemize}
    \item Optimization algorithms like Bayesian optimization and nature-inspired algorithms can efficiently tune hyperparameters across distributed nodes, reducing the overall search space per node.
    
    \item Distributed architectures can parallelize the exploration phase of meta-heuristic algorithms, leading to faster convergence without sacrificing solution quality.
\end{itemize}

\paragraph{Implementation Challenges}
Despite their promise, integration challenges remain:
\begin{itemize}
    \item Communication overhead between nodes can offset computational gains from optimized algorithms.
    
    \item Synchronization issues in distributed environments can impact the convergence properties of optimization algorithms.
    
    \item Resource heterogeneity across distributed nodes may require additional adaptation mechanisms for optimization algorithms.
\end{itemize}

\subsection{Trends and Patterns}
Our analysis identified several notable trends:

\paragraph{Shift Toward Hybrid Approaches}
There is a clear trend toward hybrid optimization methods combining multiple algorithms:
\begin{itemize}
    \item Integration of meta-heuristic algorithms with traditional gradient-based approaches.
    
    \item Coupling of population-based methods with local search techniques.
    
    \item Multi-stage optimization processes targeting different aspects of model training.
\end{itemize}

\paragraph{Domain-Specific Adaptations}
Increasing specialization of algorithms for specific domains:
\begin{itemize}
    \item Healthcare applications favoring Bayesian optimization and LSTM variants.
    
    \item Environmental monitoring systems utilizing nature-inspired algorithms.
    
    \item Cybersecurity applications employing ensemble approaches and advanced federated architectures.
\end{itemize}

\paragraph{Focus on Resource Efficiency}
Growing emphasis on resource-efficient implementations:
\begin{itemize}
    \item Energy-aware optimization algorithms for edge computing and IoT environments.
    
    \item Memory-efficient implementations for limited-resource scenarios.
    
    \item Communication-efficient protocols for geographically distributed systems.
\end{itemize}

\subsection{Research Gaps and Future Directions}
Our analysis identified several research gaps and promising directions for future research:

\paragraph{Theoretical Foundations}
\begin{itemize}
    \item Limited theoretical analysis of convergence properties for hybrid optimization algorithms in distributed environments.
    
    \item Insufficient formal frameworks for comparing algorithm performance across heterogeneous distributed architectures.
    
    \item Need for stronger theoretical guarantees on optimization algorithm behavior with non-stationary data distributions in federated settings.
\end{itemize}

\paragraph{Scalability Challenges}
\begin{itemize}
    \item Current approaches show diminishing returns beyond certain scale thresholds.
    
    \item Limited research on dynamic adaptation of optimization strategies based on available resources and data characteristics.
    
    \item Need for more efficient approaches for ultra-large-scale models (trillion+ parameters) and exabyte-scale datasets.
\end{itemize}

\paragraph{Emerging Application Areas}
\begin{itemize}
    \item Quantum computing integration with classical optimization algorithms.
    
    \item Cross-modal learning requiring novel optimization approaches for heterogeneous data types.
    
    \item Real-time optimization for streaming data in edge computing environments.
\end{itemize}

\subsection{Limitations of the Review}
This systematic review has several limitations that should be acknowledged:

\begin{itemize}
    \item The review focused primarily on published research in academic databases, potentially missing relevant industrial applications not formally published.
    
    \item Language restrictions (English-only) may have excluded relevant non-English publications.
    
    \item Rapid advancement in the field means some very recent innovations may not be fully represented.
    
    \item Variable reporting quality across studies made direct quantitative comparisons challenging in some cases.
    
    \item Publication bias may influence the reported effectiveness of the methods and techniques.
\end{itemize}

\section{Conclusion}
This systematic literature review has comprehensively analyzed the state-of-the-art in computational mathematics for AI, focusing on numerical methods and distributed computing techniques for deep learning on big data. Our findings reveal a rich landscape of optimization algorithms, architectural innovations, and distributed computing approaches addressing the computational challenges of modern AI systems.

Key contributions of this review include:
\begin{itemize}
    \item A comprehensive taxonomy of optimization algorithms for deep learning in big data contexts.
    
    \item Analysis of performance characteristics across diverse application domains.
    
    \item Identification of synergies between numerical methods and distributed computing techniques.
    
    \item Mapping of research gaps and promising future directions.
\end{itemize}

The field continues to evolve rapidly, with emerging hybrid approaches and domain-specific adaptations demonstrating promising results. Future research should focus on addressing theoretical gaps, scaling challenges, and adaptation to emerging application areas. Stronger integration between numerical optimization and distributed computing architectures presents a particularly promising direction for addressing the computational demands of next-generation AI systems.
